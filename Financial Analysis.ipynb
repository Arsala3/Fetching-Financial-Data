{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents in VGT: 320\n",
      "Processed: AVGO\n",
      "Processed: NVDA\n",
      "Processed: AMAT\n",
      "Processed: ORCL\n",
      "Processed: AMD\n",
      "Processed: MSFT\n",
      "Processed: ADBE\n",
      "Processed: AAPL\n",
      "Processed: QCOM\n",
      "Processed: CRM\n",
      "Processed: CSCO\n",
      "Processed: ACN\n",
      "Processed: INTU\n",
      "Processed: IBM\n",
      "Processed: NOW\n",
      "Processed: TXN\n",
      "Processed: MU\n",
      "Processed: LRCX\n",
      "Processed: ADI\n",
      "Processed: INTC\n",
      "Processed: PANW\n",
      "Processed: KLAC\n",
      "Processed: ANET\n",
      "Processed: SNPS\n",
      "Processed: CRWD\n",
      "Processed: NXPI\n",
      "Processed: CDNS\n",
      "Processed: APH\n",
      "Processed: MRVL\n",
      "Processed: MSI\n",
      "Processed: ROP\n",
      "Processed: ADSK\n",
      "Processed: MCHP\n",
      "Processed: PLTR\n",
      "Processed: TEL\n",
      "Processed: WDAY\n",
      "Processed: SMCI\n",
      "Processed: FTNT\n",
      "Processed: SNOW\n",
      "Processed: MPWR\n",
      "Processed: FICO\n",
      "Processed: DELL\n",
      "Processed: DDOG\n",
      "Processed: IT\n",
      "Processed: HPQ\n",
      "Processed: CTSH\n",
      "Processed: CDW\n",
      "Processed: GLW\n",
      "Processed: ON\n",
      "Processed: HPE\n",
      "Processed: HUBS\n",
      "Processed: ANSS\n",
      "Processed: NTAP\n",
      "Processed: TEAM\n",
      "Processed: NET\n",
      "Processed: WDC\n",
      "Processed: TER\n",
      "Processed: MSTR\n",
      "Processed: KEYS\n",
      "Processed: FSLR\n",
      "Processed: TYL\n",
      "Processed: PTC\n",
      "Processed: STX\n",
      "Processed: ENTG\n",
      "Processed: PSTG\n",
      "Processed: GDDY\n",
      "Processed: ZS\n",
      "Processed: TDY\n",
      "Processed: APP\n",
      "Processed: SWKS\n",
      "Processed: MDB\n",
      "Processed: VRSN\n",
      "Processed: ZBRA\n",
      "Processed: MANH\n",
      "Processed: NLOK\n",
      "Processed: OKTA\n",
      "Processed: NTNX\n",
      "Processed: ZM\n",
      "Processed: TRMB\n",
      "Processed: AKAM\n",
      "Processed: COHR\n",
      "Processed: ENPH\n",
      "Processed: FLEX\n",
      "Processed: JBL\n",
      "Processed: JNPR\n",
      "Processed: QRVO\n",
      "Processed: GWRE\n",
      "Processed: DT\n",
      "Processed: FN\n",
      "Processed: ONTO\n",
      "Processed: OLED\n",
      "Processed: EPAM\n",
      "Processed: DOCU\n",
      "Processed: ESTC\n",
      "Processed: BSY\n",
      "Processed: FFIV\n",
      "Processed: CRUS\n",
      "Processed: TWLO\n",
      "Processed: SNX\n",
      "Processed: CGNX\n",
      "Processed: MKSI\n",
      "Processed: CRDO\n",
      "Processed: KD\n",
      "Processed: SPSC\n",
      "Processed: CIEN\n",
      "Processed: MTSI\n",
      "Processed: ACLS\n",
      "Processed: FORM\n",
      "Processed: LFUS\n",
      "Processed: LSCC\n",
      "Processed: CVLT\n",
      "Processed: RMBS\n",
      "Processed: ALTR\n",
      "Processed: SMAR\n",
      "Processed: AMKR\n",
      "Processed: ARW\n",
      "Processed: IOT\n",
      "Processed: NOVT\n",
      "Processed: PCOR\n",
      "Processed: HCP\n",
      "Processed: MARA\n",
      "Processed: VRNS\n",
      "Processed: CFLT\n",
      "Processed: NSIT\n",
      "Processed: VNT\n",
      "Processed: APPF\n",
      "Processed: BMI\n",
      "Processed: AZPN\n",
      "Processed: S\n",
      "Processed: ACIW\n",
      "Processed: DBX\n",
      "Processed: ZETA\n",
      "Processed: TENB\n",
      "Processed: PI\n",
      "Processed: AEIS\n",
      "Processed: QLYS\n",
      "Processed: BILL\n",
      "Processed: AVT\n",
      "Processed: AI\n",
      "Processed: DXC\n",
      "Processed: GTLB\n",
      "Processed: ITRI\n",
      "Processed: FROG\n",
      "Processed: PRFT\n",
      "Processed: QTWO\n",
      "Processed: DLB\n",
      "Processed: BDC\n",
      "Processed: VECO\n",
      "Processed: LITE\n",
      "Processed: POWI\n",
      "Processed: SANM\n",
      "Processed: IDCC\n",
      "Processed: BOX\n",
      "Processed: TDC\n",
      "Processed: AGYS\n",
      "Processed: ASGN\n",
      "Processed: SYNA\n",
      "Processed: PATH\n",
      "Processed: RPD\n",
      "Processed: CCCS\n",
      "Processed: SQSP\n",
      "Processed: DIOD\n",
      "Processed: CWAN\n",
      "Processed: DV\n",
      "Processed: PLXS\n",
      "Processed: U\n",
      "Processed: BLKB\n",
      "Processed: CR\n",
      "Processed: KLIC\n",
      "Processed: CLSK\n",
      "Processed: UCTT\n",
      "Processed: SLAB\n",
      "Processed: VSH\n",
      "Processed: WK\n",
      "Processed: ALRM\n",
      "Processed: PRGS\n",
      "Processed: PEGA\n",
      "Processed: SITM\n",
      "Processed: ALGM\n",
      "Processed: AMBA\n",
      "Processed: CALX\n",
      "Processed: FIVN\n",
      "Processed: WOLF\n",
      "Processed: IPGP\n",
      "Processed: ENV\n",
      "Processed: VERX\n",
      "Processed: BL\n",
      "Processed: OSIS\n",
      "Processed: PD\n",
      "Processed: ROG\n",
      "Processed: AUR\n",
      "Processed: VRNT\n",
      "Processed: INFA\n",
      "Processed: NCNO\n",
      "Processed: TTMI\n",
      "Processed: BRZE\n",
      "Processed: FRSH\n",
      "Processed: RAMP\n",
      "Processed: NSSC\n",
      "Processed: SMTC\n",
      "Processed: DOCN\n",
      "Processed: MIR\n",
      "Processed: PLUS\n",
      "Processed: RIOT\n",
      "Processed: SPT\n",
      "Processed: RNG\n",
      "Processed: EXTR\n",
      "Processed: NCR\n",
      "Processed: YOU\n",
      "Processed: INTA\n",
      "Processed: PAR\n",
      "Processed: COHU\n",
      "Processed: MXL\n",
      "Processed: PLAB\n",
      "Processed: KN\n",
      "Processed: VIAV\n",
      "Processed: CTS\n",
      "Processed: KVYO\n",
      "Processed: BHE\n",
      "Processed: ALKT\n",
      "Processed: EVBG\n",
      "Processed: XRX\n",
      "Processed: NTCT\n",
      "Processed: PWSC\n",
      "Processed: ZUO\n",
      "Processed: HLIT\n",
      "Processed: ICHR\n",
      "Processed: INFN\n",
      "Processed: IONQ\n",
      "Processed: ADEA\n",
      "Processed: MTTR\n",
      "Processed: HUT.TO\n",
      "Processed: ARLO\n",
      "Processed: ASAN\n",
      "Processed: SGH\n",
      "Processed: CXM\n",
      "Processed: NABL\n",
      "Processed: PDFS\n",
      "Processed: SEDG\n",
      "Processed: PRO\n",
      "Processed: AVPT\n",
      "Processed: APPN\n",
      "Processed: SCSC\n",
      "Processed: ACMR\n",
      "Processed: SOUN\n",
      "Processed: WULF\n",
      "Processed: ATEN\n",
      "Processed: INDI\n",
      "Processed: AOSL\n",
      "Processed: DGII\n",
      "Processed: FSLY\n",
      "Processed: JAMF\n",
      "Processed: VSAT\n",
      "Processed: CNXN\n",
      "Processed: BASE\n",
      "Processed: CIFR\n",
      "Processed: ETWO\n",
      "Processed: AMPL\n",
      "Processed: BELFB\n",
      "Processed: GDYN\n",
      "Processed: SWI\n",
      "Processed: APLD\n",
      "Processed: HCKT\n",
      "Processed: KE\n",
      "Processed: BIGC\n",
      "Processed: CLFD\n",
      "Processed: CRSR\n",
      "Processed: YEXT\n",
      "Processed: MITK\n",
      "Processed: DBD\n",
      "Processed: NVTS\n",
      "Processed: CEVA\n",
      "Processed: LASR\n",
      "Processed: MLNK\n",
      "Processed: DMRC\n",
      "Processed: NTGR\n",
      "Processed: OLO\n",
      "Processed: SMRT\n",
      "Processed: OSPN\n",
      "Processed: ADTN\n",
      "Processed: BLND\n",
      "Processed: SEMR\n",
      "Processed: MEI\n",
      "Processed: AEHR\n",
      "Processed: CCSI\n",
      "Processed: LWLG\n",
      "Processed: VPG\n",
      "Processed: ENFN\n",
      "Processed: FARO\n",
      "Processed: OUST\n",
      "Processed: RBBN\n",
      "Processed: TWKS\n",
      "Processed: WEAV\n",
      "Processed: XPER\n",
      "Processed: AMSWA\n",
      "Processed: EVLV\n",
      "Processed: COMM\n",
      "Processed: NN\n",
      "Processed: BELFA\n",
      "Processed: DOMO\n",
      "Processed: EGHT\n",
      "Processed: TLS\n",
      "Processed: MVIS\n",
      "Processed: MX\n",
      "Processed: UIS\n",
      "Processed: TCX\n",
      "Processed: APPS\n",
      "Processed: LAW\n",
      "Processed: ONTF\n",
      "Processed: RMNI\n",
      "Processed: RXT\n",
      "Processed: CRNC\n",
      "Processed: MASS\n",
      "Processed: PMTS\n",
      "Processed: EXFY\n",
      "Processed: SCWX\n",
      "Processed: AEVA\n",
      "Processed: LPSN\n",
      "Processed: FCUV\n",
      "Processed: VERI\n",
      "Data saved to F:\\VGT_employee_count_2022_2023.csv\n",
      "Total companies with data: 320\n",
      "\n",
      "Data Summary:\n",
      "       employee_count_2022  employee_count_2023\n",
      "count             6.000000           253.000000\n",
      "mean           3968.500000         11124.494071\n",
      "std            4706.406942         54512.031509\n",
      "min               0.000000             0.000000\n",
      "25%             978.750000             0.000000\n",
      "50%            1454.500000          1321.000000\n",
      "75%            7775.000000          3900.000000\n",
      "max           10200.000000        733000.000000\n",
      "\n",
      "Companies with missing data for both 2022 and 2023:\n",
      "NVDA, ORCL, CRM, CRWD, MRVL, ADSK, MCHP, WDAY, SNOW, DELL, NTAP, PSTG, MDB, NLOK, OKTA, ZM, FLEX, QRVO, DT, DOCU, ESTC, CRUS, CRDO, KD, CVLT, SMAR, IOT, HCP, S, AI, DXC, GTLB, BOX, AGYS, PATH, ALGM, AMBA, PD, VRNT, NCNO, TTMI, BRZE, RAMP, SMTC, PLUS, KVYO, NTCT, ZUO, HUT.TO, ASAN, CXM, VSAT, BASE, ETWO, YEXT, MEI, AMSWA, DOMO, EGHT, APPS, SCWX\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import os\n",
    "\n",
    "# Your API Key\n",
    "API_KEY = 'D7KXZhPjt6caA9dwwAliN6CP3Oofacu5'\n",
    "\n",
    "# Specify the save location\n",
    "SAVE_LOCATION = \"F:\\\\\"\n",
    "\n",
    "def get_etf_constituents(etf_symbol):\n",
    "    url = f\"https://financialmodelingprep.com/api/v3/etf-holder/{etf_symbol}?apikey={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return [{'symbol': holding['asset'], 'name': holding['name']} for holding in data]\n",
    "\n",
    "def get_employee_count(company):\n",
    "    symbol = company['symbol']\n",
    "    name = company['name']\n",
    "    url = f\"https://financialmodelingprep.com/api/v4/employee_count?symbol={symbol}&apikey={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    employee_count_2022 = None\n",
    "    employee_count_2023 = None\n",
    "    \n",
    "    for item in data:\n",
    "        if item['periodOfReport'].startswith('2022'):\n",
    "            employee_count_2022 = item['employeeCount']\n",
    "        elif item['periodOfReport'].startswith('2023'):\n",
    "            employee_count_2023 = item['employeeCount']\n",
    "    \n",
    "    return {\n",
    "        'symbol': symbol,\n",
    "        'name': name,\n",
    "        'employee_count_2022': employee_count_2022,\n",
    "        'employee_count_2023': employee_count_2023\n",
    "    }\n",
    "\n",
    "# Get VGT ETF constituents\n",
    "vgt_constituents = get_etf_constituents('VGT')\n",
    "print(f\"Total constituents in VGT: {len(vgt_constituents)}\")\n",
    "\n",
    "# Fetch employee count data for all companies using ThreadPoolExecutor\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    future_to_company = {executor.submit(get_employee_count, company): company for company in vgt_constituents}\n",
    "    for future in as_completed(future_to_company):\n",
    "        company = future_to_company[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "            print(f\"Processed: {result['symbol']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {company['symbol']}: {str(e)}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Save to CSV in the specified location\n",
    "csv_path = os.path.join(SAVE_LOCATION, 'VGT_employee_count_2022_2023.csv')\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"Data saved to {csv_path}\")\n",
    "print(f\"Total companies with data: {len(results)}\")\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nData Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Print companies with missing data for both years\n",
    "missing_data = df[(df['employee_count_2022'].isnull()) & (df['employee_count_2023'].isnull())]\n",
    "if not missing_data.empty:\n",
    "    print(\"\\nCompanies with missing data for both 2022 and 2023:\")\n",
    "    print(\", \".join(missing_data['symbol']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents in VGT: 320\n",
      "Processed: AMAT\n",
      "Processed: ORCL\n",
      "Processed: AAPL\n",
      "Processed: ADBE\n",
      "Processed: NVDA\n",
      "Processed: MSFT\n",
      "Processed: AMD\n",
      "Processed: QCOM\n",
      "Processed: AVGO\n",
      "Processed: CRM\n",
      "Processed: CSCO\n",
      "Processed: ACN\n",
      "Processed: IBM\n",
      "Processed: NOW\n",
      "Processed: TXN\n",
      "Processed: INTU\n",
      "Processed: MU\n",
      "Processed: LRCX\n",
      "Processed: ADI\n",
      "Processed: INTC\n",
      "Processed: KLAC\n",
      "Processed: PANW\n",
      "Processed: ANET\n",
      "Processed: SNPS\n",
      "Processed: CDNS\n",
      "Processed: MRVL\n",
      "Processed: APH\n",
      "Processed: NXPI\n",
      "Processed: CRWD\n",
      "Processed: MSI\n",
      "Processed: ROP\n",
      "Processed: ADSK\n",
      "Processed: MCHP\n",
      "Processed: PLTR\n",
      "Processed: TEL\n",
      "Processed: SMCI\n",
      "Processed: SNOW\n",
      "Processed: FTNT\n",
      "Processed: MPWR\n",
      "Processed: FICO\n",
      "Processed: DELL\n",
      "Processed: WDAY\n",
      "Processed: DDOG\n",
      "Processed: IT\n",
      "Processed: HPQ\n",
      "Processed: CTSH\n",
      "Processed: ON\n",
      "Processed: GLW\n",
      "Processed: CDW\n",
      "Processed: HPE\n",
      "Processed: ANSS\n",
      "Processed: HUBS\n",
      "Processed: NTAP\n",
      "Processed: TEAM\n",
      "Processed: NET\n",
      "Processed: WDC\n",
      "Processed: TER\n",
      "Processed: FSLR\n",
      "Processed: KEYS\n",
      "Processed: MSTR\n",
      "Processed: TYL\n",
      "Processed: PTC\n",
      "Processed: ENTG\n",
      "Processed: STX\n",
      "Processed: PSTG\n",
      "Processed: GDDY\n",
      "Processed: TDY\n",
      "Processed: SWKS\n",
      "Processed: APP\n",
      "Processed: ZS\n",
      "Processed: MDB\n",
      "Processed: VRSN\n",
      "Processed: MANH\n",
      "Processed: ZBRA\n",
      "Processed: NLOK\n",
      "Processed: OKTA\n",
      "Processed: ZM\n",
      "Processed: NTNX\n",
      "Processed: TRMB\n",
      "Processed: AKAM\n",
      "Processed: COHR\n",
      "Processed: ENPH\n",
      "Processed: JBL\n",
      "Processed: FLEX\n",
      "Processed: QRVO\n",
      "Processed: JNPR\n",
      "Processed: GWRE\n",
      "Processed: ONTO\n",
      "Processed: FN\n",
      "Processed: DT\n",
      "Processed: OLED\n",
      "Processed: EPAM\n",
      "Processed: BSY\n",
      "Processed: DOCU\n",
      "Processed: ESTC\n",
      "Processed: FFIV\n",
      "Processed: CRUS\n",
      "Processed: TWLO\n",
      "Processed: MKSI\n",
      "Processed: CRDO\n",
      "Processed: SNX\n",
      "Processed: CGNX\n",
      "Processed: KD\n",
      "Processed: SPSC\n",
      "Processed: MTSI\n",
      "Processed: CIEN\n",
      "Processed: FORM\n",
      "Processed: ACLS\n",
      "Processed: LFUS\n",
      "Processed: RMBS\n",
      "Processed: LSCC\n",
      "Processed: CVLT\n",
      "Processed: SMAR\n",
      "Processed: ALTR\n",
      "Processed: AMKR\n",
      "Processed: ARW\n",
      "Processed: IOT\n",
      "Processed: NOVT\n",
      "Processed: PCOR\n",
      "Processed: HCP\n",
      "Processed: VRNS\n",
      "Processed: MARA\n",
      "Processed: CFLT\n",
      "Processed: NSIT\n",
      "Processed: VNT\n",
      "Processed: AZPN\n",
      "Processed: ACIW\n",
      "Processed: BMI\n",
      "Processed: APPF\n",
      "Processed: DBX\n",
      "Processed: PI\n",
      "Processed: S\n",
      "Processed: QLYS\n",
      "Processed: TENB\n",
      "Processed: ZETA\n",
      "Processed: AEIS\n",
      "Processed: AVT\n",
      "Processed: BILL\n",
      "Processed: AI\n",
      "Processed: GTLB\n",
      "Processed: DXC\n",
      "Processed: ITRI\n",
      "Processed: DLB\n",
      "Processed: BDC\n",
      "Processed: FROG\n",
      "Processed: PRFT\n",
      "Processed: QTWO\n",
      "Processed: VECO\n",
      "Processed: LITE\n",
      "Processed: POWI\n",
      "Processed: SANM\n",
      "Processed: IDCC\n",
      "Processed: TDC\n",
      "Processed: BOX\n",
      "Processed: AGYS\n",
      "Processed: SYNA\n",
      "Processed: ASGN\n",
      "Processed: PATH\n",
      "Processed: RPD\n",
      "Processed: DIOD\n",
      "Processed: SQSP\n",
      "Processed: CCCS\n",
      "Processed: DV\n",
      "Processed: CWAN\n",
      "Processed: PLXS\n",
      "Processed: U\n",
      "Processed: BLKB\n",
      "Processed: CR\n",
      "Processed: KLIC\n",
      "Processed: CLSK\n",
      "Processed: SLAB\n",
      "Processed: UCTT\n",
      "Processed: VSH\n",
      "Processed: WK\n",
      "Processed: ALRM\n",
      "Processed: PRGS\n",
      "Processed: ALGM\n",
      "Processed: AMBA\n",
      "Processed: CALX\n",
      "Processed: SITM\n",
      "Processed: PEGA\n",
      "Processed: FIVN\n",
      "Processed: IPGP\n",
      "Processed: WOLF\n",
      "Processed: ENV\n",
      "Processed: VERX\n",
      "Processed: BL\n",
      "Processed: OSIS\n",
      "Processed: PD\n",
      "Processed: VRNT\n",
      "Processed: ROG\n",
      "Processed: AUR\n",
      "Processed: INFA\n",
      "Processed: NCNO\n",
      "Processed: TTMI\n",
      "Processed: BRZE\n",
      "Processed: FRSH\n",
      "Processed: NSSC\n",
      "Processed: RAMP\n",
      "Processed: SMTC\n",
      "Processed: DOCN\n",
      "Processed: MIR\n",
      "Processed: PLUS\n",
      "Processed: SPT\n",
      "Processed: RIOT\n",
      "Processed: RNG\n",
      "Processed: EXTR\n",
      "Processed: NCR\n",
      "Processed: YOU\n",
      "Processed: INTA\n",
      "Processed: PAR\n",
      "Processed: COHU\n",
      "Processed: MXL\n",
      "Processed: PLAB\n",
      "Processed: KN\n",
      "Processed: VIAV\n",
      "Processed: CTS\n",
      "Processed: KVYO\n",
      "Processed: BHE\n",
      "Processed: ALKT\n",
      "Processed: EVBG\n",
      "Processed: XRX\n",
      "Processed: NTCT\n",
      "Processed: ZUO\n",
      "Processed: PWSC\n",
      "Processed: HLIT\n",
      "Processed: ICHR\n",
      "Processed: INFN\n",
      "Processed: IONQ\n",
      "Processed: MTTR\n",
      "Processed: ADEA\n",
      "Processed: HUT.TO\n",
      "Processed: ARLO\n",
      "Processed: CXM\n",
      "Processed: ASAN\n",
      "Processed: SGH\n",
      "Processed: AVPT\n",
      "Processed: NABL\n",
      "Processed: PDFS\n",
      "Processed: SEDG\n",
      "Processed: PRO\n",
      "Processed: APPN\n",
      "Processed: SCSC\n",
      "Processed: ACMR\n",
      "Processed: WULF\n",
      "Processed: SOUN\n",
      "Processed: INDI\n",
      "Processed: ATEN\n",
      "Processed: AOSL\n",
      "Processed: FSLY\n",
      "Processed: DGII\n",
      "Processed: JAMF\n",
      "Processed: VSAT\n",
      "Processed: CIFR\n",
      "Processed: ETWO\n",
      "Processed: CNXN\n",
      "Processed: AMPL\n",
      "Processed: BASE\n",
      "Processed: GDYN\n",
      "Processed: BELFB\n",
      "Processed: SWI\n",
      "Processed: HCKT\n",
      "Processed: YEXT\n",
      "Processed: KE\n",
      "Processed: BIGC\n",
      "Processed: CLFD\n",
      "Processed: CRSR\n",
      "Processed: APLD\n",
      "Processed: MITK\n",
      "Processed: DBD\n",
      "Processed: NVTS\n",
      "Processed: CEVA\n",
      "Processed: DMRC\n",
      "Processed: MLNK\n",
      "Processed: LASR\n",
      "Processed: NTGR\n",
      "Processed: OLO\n",
      "Processed: OSPN\n",
      "Processed: SMRT\n",
      "Processed: ADTN\n",
      "Processed: BLND\n",
      "Processed: SEMR\n",
      "Processed: VPG\n",
      "Processed: LWLG\n",
      "Processed: MEI\n",
      "Processed: AEHR\n",
      "Processed: CCSI\n",
      "Processed: ENFN\n",
      "Processed: FARO\n",
      "Processed: OUST\n",
      "Processed: RBBN\n",
      "Processed: TWKS\n",
      "Processed: WEAV\n",
      "Processed: XPER\n",
      "Processed: AMSWA\n",
      "Processed: COMM\n",
      "Processed: EVLV\n",
      "Processed: NN\n",
      "Processed: UIS\n",
      "Processed: BELFA\n",
      "Processed: DOMO\n",
      "Processed: EGHT\n",
      "Processed: TLS\n",
      "Processed: MX\n",
      "Processed: MVIS\n",
      "Processed: TCX\n",
      "Processed: APPS\n",
      "Processed: LAW\n",
      "Processed: ONTF\n",
      "Processed: RMNI\n",
      "Processed: CRNC\n",
      "Processed: RXT\n",
      "Processed: PMTS\n",
      "Processed: MASS\n",
      "Processed: EXFY\n",
      "Processed: SCWX\n",
      "Processed: AEVA\n",
      "Processed: LPSN\n",
      "Processed: FCUV\n",
      "Processed: VERI\n",
      "Data saved to F:\\VGT_employee_count_2022.csv\n",
      "Total companies with data: 320\n",
      "\n",
      "Data Summary:\n",
      "       employee_count_2022\n",
      "count             6.000000\n",
      "mean           3968.500000\n",
      "std            4706.406942\n",
      "min               0.000000\n",
      "25%             978.750000\n",
      "50%            1454.500000\n",
      "75%            7775.000000\n",
      "max           10200.000000\n",
      "\n",
      "Companies with missing data for 2022:\n",
      "AMAT, ORCL, AAPL, ADBE, NVDA, MSFT, AMD, QCOM, AVGO, CRM, CSCO, ACN, IBM, NOW, TXN, INTU, MU, LRCX, ADI, INTC, KLAC, PANW, ANET, SNPS, MRVL, APH, NXPI, CRWD, MSI, ROP, ADSK, MCHP, PLTR, TEL, SMCI, SNOW, FTNT, MPWR, FICO, DELL, WDAY, DDOG, IT, HPQ, CTSH, ON, GLW, CDW, HPE, ANSS, HUBS, NTAP, TEAM, NET, WDC, TER, FSLR, KEYS, MSTR, TYL, PTC, ENTG, STX, PSTG, GDDY, TDY, SWKS, APP, ZS, MDB, VRSN, MANH, ZBRA, NLOK, OKTA, ZM, NTNX, TRMB, COHR, ENPH, JBL, FLEX, QRVO, JNPR, GWRE, ONTO, FN, DT, OLED, EPAM, BSY, DOCU, ESTC, FFIV, CRUS, TWLO, MKSI, CRDO, SNX, CGNX, KD, SPSC, MTSI, CIEN, FORM, ACLS, LFUS, RMBS, LSCC, CVLT, SMAR, ALTR, AMKR, ARW, IOT, NOVT, PCOR, HCP, VRNS, MARA, CFLT, NSIT, VNT, AZPN, ACIW, BMI, APPF, DBX, PI, S, QLYS, TENB, ZETA, AEIS, AVT, BILL, AI, GTLB, DXC, ITRI, DLB, BDC, FROG, PRFT, QTWO, VECO, LITE, POWI, SANM, IDCC, TDC, BOX, AGYS, SYNA, ASGN, PATH, RPD, DIOD, SQSP, CCCS, CWAN, PLXS, U, BLKB, CR, KLIC, CLSK, SLAB, UCTT, VSH, WK, ALRM, PRGS, ALGM, AMBA, CALX, SITM, PEGA, FIVN, IPGP, WOLF, ENV, VERX, BL, OSIS, PD, VRNT, ROG, INFA, NCNO, TTMI, BRZE, FRSH, NSSC, RAMP, SMTC, DOCN, MIR, PLUS, SPT, RIOT, RNG, EXTR, NCR, YOU, INTA, PAR, COHU, MXL, PLAB, KN, VIAV, CTS, KVYO, BHE, ALKT, EVBG, XRX, NTCT, ZUO, PWSC, HLIT, ICHR, INFN, MTTR, ADEA, HUT.TO, ARLO, CXM, ASAN, SGH, AVPT, NABL, PDFS, SEDG, PRO, APPN, SCSC, WULF, SOUN, INDI, ATEN, AOSL, FSLY, DGII, JAMF, VSAT, CIFR, ETWO, CNXN, AMPL, BASE, GDYN, BELFB, SWI, HCKT, YEXT, KE, BIGC, CLFD, CRSR, APLD, MITK, DBD, NVTS, CEVA, DMRC, MLNK, LASR, NTGR, OLO, OSPN, SMRT, ADTN, BLND, SEMR, VPG, LWLG, MEI, AEHR, CCSI, ENFN, FARO, OUST, RBBN, TWKS, WEAV, XPER, AMSWA, COMM, EVLV, NN, UIS, BELFA, DOMO, EGHT, TLS, MX, MVIS, TCX, APPS, LAW, ONTF, RMNI, CRNC, RXT, PMTS, MASS, EXFY, SCWX, AEVA, LPSN, FCUV, VERI\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import os\n",
    "\n",
    "# Your API Key\n",
    "API_KEY = 'D7KXZhPjt6caA9dwwAliN6CP3Oofacu5'\n",
    "\n",
    "# Specify the save location\n",
    "SAVE_LOCATION = \"F:\\\\\"\n",
    "\n",
    "def get_etf_constituents(etf_symbol):\n",
    "    url = f\"https://financialmodelingprep.com/api/v3/etf-holder/{etf_symbol}?apikey={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return [{'symbol': holding['asset'], 'name': holding['name']} for holding in data]\n",
    "\n",
    "def get_employee_count_2022(company):\n",
    "    symbol = company['symbol']\n",
    "    name = company['name']\n",
    "    url = f\"https://financialmodelingprep.com/api/v4/employee_count?symbol={symbol}&apikey={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    employee_count_2022 = None\n",
    "    report_date = None\n",
    "    \n",
    "    for item in data:\n",
    "        if item['periodOfReport'].startswith('2022'):\n",
    "            employee_count_2022 = item['employeeCount']\n",
    "            report_date = item['periodOfReport']\n",
    "            break  # We'll take the first 2022 entry\n",
    "    \n",
    "    return {\n",
    "        'symbol': symbol,\n",
    "        'name': name,\n",
    "        'employee_count_2022': employee_count_2022,\n",
    "        'report_date': report_date\n",
    "    }\n",
    "\n",
    "# Get VGT ETF constituents\n",
    "vgt_constituents = get_etf_constituents('VGT')\n",
    "print(f\"Total constituents in VGT: {len(vgt_constituents)}\")\n",
    "\n",
    "# Fetch employee count data for all companies using ThreadPoolExecutor\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    future_to_company = {executor.submit(get_employee_count_2022, company): company for company in vgt_constituents}\n",
    "    for future in as_completed(future_to_company):\n",
    "        company = future_to_company[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "            print(f\"Processed: {result['symbol']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {company['symbol']}: {str(e)}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Save to CSV in the specified location\n",
    "csv_path = os.path.join(SAVE_LOCATION, 'VGT_employee_count_2022.csv')\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"Data saved to {csv_path}\")\n",
    "print(f\"Total companies with data: {len(results)}\")\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nData Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Print companies with missing data\n",
    "missing_data = df[df['employee_count_2022'].isnull()]\n",
    "if not missing_data.empty:\n",
    "    print(\"\\nCompanies with missing data for 2022:\")\n",
    "    print(\", \".join(missing_data['symbol']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics for ^GSPC from 2019-07-28 to 2024-07-26:\n",
      "Total Return: 78.73%\n",
      "Annualized Return: 18.37%\n",
      "Annualized Volatility: 21.27%\n",
      "Data and chart saved to F: drive\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Your API Key\n",
    "API_KEY = 'D7KXZhPjt6caA9dwwAliN6CP3Oofacu5'\n",
    "\n",
    "def get_index_performance(symbol, start_date, end_date):\n",
    "    url = f\"https://financialmodelingprep.com/api/v3/historical-price-full/{symbol}?from={start_date}&to={end_date}&apikey={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    if 'historical' in data:\n",
    "        df = pd.DataFrame(data['historical'])\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df.sort_values('date')\n",
    "        \n",
    "        # Calculate daily returns\n",
    "        df['daily_return'] = df['close'].pct_change()\n",
    "        \n",
    "        # Calculate cumulative returns\n",
    "        df['cumulative_return'] = (1 + df['daily_return']).cumprod() - 1\n",
    "        \n",
    "        # Calculate other metrics\n",
    "        total_return = df['cumulative_return'].iloc[-1]\n",
    "        annualized_return = (1 + total_return) ** (365 / len(df)) - 1\n",
    "        volatility = df['daily_return'].std() * (252 ** 0.5)  # Annualized volatility\n",
    "        \n",
    "        return df, total_return, annualized_return, volatility\n",
    "    else:\n",
    "        print(f\"Error fetching data for {symbol}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "# Set the date range (e.g., last 5 years)\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "start_date = (datetime.now() - timedelta(days=5*365)).strftime('%Y-%m-%d')\n",
    "\n",
    "# Fetch data for S&P 500 (you can change the symbol for other indexes)\n",
    "symbol = '^GSPC'  # S&P 500\n",
    "df, total_return, annualized_return, volatility = get_index_performance(symbol, start_date, end_date)\n",
    "\n",
    "if df is not None:\n",
    "    # Print performance metrics\n",
    "    print(f\"Performance metrics for {symbol} from {start_date} to {end_date}:\")\n",
    "    print(f\"Total Return: {total_return:.2%}\")\n",
    "    print(f\"Annualized Return: {annualized_return:.2%}\")\n",
    "    print(f\"Annualized Volatility: {volatility:.2%}\")\n",
    "\n",
    "    # Plot the cumulative returns\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df['date'], df['cumulative_return'])\n",
    "    plt.title(f'{symbol} Cumulative Returns')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Cumulative Return')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('F:\\\\index_performance.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Save the data to CSV\n",
    "    df.to_csv('F:\\\\index_performance_data.csv', index=False)\n",
    "    print(\"Data and chart saved to F: drive\")\n",
    "else:\n",
    "    print(\"Failed to fetch index data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total S&P 500 constituents: 503\n",
      "Processed: SOLV\n",
      "Processed: SW\n",
      "Processed: GEV\n",
      "Processed: SMCI\n",
      "Processed: CRWD\n",
      "Processed: DECK\n",
      "Processed: VST\n",
      "Processed: GDDY\n",
      "Processed: KKR\n",
      "Processed: BLDR\n",
      "Processed: LULU\n",
      "Processed: HUBB\n",
      "Processed: PANW\n",
      "Processed: VLTO\n",
      "Processed: UBER\n",
      "Processed: ABNB\n",
      "Processed: BX\n",
      "Processed: AXON\n",
      "Processed: JBL\n",
      "Processed: KVUE\n",
      "Processed: FICO\n",
      "Processed: PODD\n",
      "Processed: GEHC\n",
      "Processed: TRGP\n",
      "Processed: ACGL\n",
      "Processed: FSLR\n",
      "Processed: STLD\n",
      "Processed: EQT\n",
      "Processed: BG\n",
      "Processed: PCG\n",
      "Processed: INVH\n",
      "Processed: ON\n",
      "Processed: KDP\n",
      "Processed: WBD\n",
      "Processed: VICI\n",
      "Processed: CPT\n",
      "Processed: MOH\n",
      "Processed: NDSN\n",
      "Processed: CSGP\n",
      "Processed: EPAM\n",
      "Processed: BRO\n",
      "Processed: DAY\n",
      "Processed: FDS\n",
      "Processed: MTCH\n",
      "Processed: TECH\n",
      "Processed: MRNA\n",
      "Processed: CEG\n",
      "Processed: CRL\n",
      "Processed: PTC\n",
      "Processed: GNRC\n",
      "Processed: MPWR\n",
      "Processed: TRMB\n",
      "Processed: NXPI\n",
      "Processed: ENPH\n",
      "Processed: TSLA\n",
      "Processed: POOL\n",
      "Processed: CZR\n",
      "Processed: CTLT\n",
      "Processed: TER\n",
      "Processed: ETSY\n",
      "Processed: TYL\n",
      "Processed: TDY\n",
      "Processed: BIO\n",
      "Processed: WST\n",
      "Processed: DPZ\n",
      "Processed: DXCM\n",
      "Processed: CARR\n",
      "Processed: OTIS\n",
      "Processed: PAYC\n",
      "Processed: IR\n",
      "Processed: LYV\n",
      "Processed: ZBRA\n",
      "Processed: STE\n",
      "Processed: ODFL\n",
      "Processed: WRB\n",
      "Processed: LVS\n",
      "Processed: NVR\n",
      "Processed: NOW\n",
      "Processed: CDW\n",
      "Processed: IEX\n",
      "Processed: TROW\n",
      "Processed: LDOS\n",
      "Processed: TMUS\n",
      "Processed: MKTX\n",
      "Processed: AMCR\n",
      "Processed: CTVA\n",
      "Processed: DD\n",
      "Processed: DOW\n",
      "Processed: FOX\n",
      "Processed: WAB\n",
      "Processed: ATO\n",
      "Processed: FOXA\n",
      "Processed: TFX\n",
      "Processed: FANG\n",
      "Processed: CE\n",
      "Processed: JKHY\n",
      "Processed: FTNT\n",
      "Processed: ROL\n",
      "Processed: KEYS\n",
      "Processed: ANET\n",
      "Processed: CPAY\n",
      "Processed: CPRT\n",
      "Processed: LW\n",
      "Processed: BR\n",
      "Processed: EVRG\n",
      "Processed: MSCI\n",
      "Processed: TTWO\n",
      "Processed: HII\n",
      "Processed: NCLH\n",
      "Processed: CDNS\n",
      "Processed: SBAC\n",
      "Processed: IQV\n",
      "Processed: AOS\n",
      "Processed: MGM\n",
      "Processed: PKG\n",
      "Processed: RMD\n",
      "Processed: BKR\n",
      "Processed: ALGN\n",
      "Processed: ANSS\n",
      "Processed: EG\n",
      "Processed: HLT\n",
      "Processed: IT\n",
      "Processed: AMD\n",
      "Processed: RJF\n",
      "Processed: ARE\n",
      "Processed: SNPS\n",
      "Processed: SRE\n",
      "Processed: REG\n",
      "Processed: INCY\n",
      "Processed: CBOE\n",
      "Processed: IDXX\n",
      "Processed: MAA\n",
      "Processed: D\n",
      "Processed: COO\n",
      "Processed: HWM\n",
      "Processed: CHTR\n",
      "Processed: MTD\n",
      "Processed: ALB\n",
      "Processed: FTV\n",
      "Processed: LNT\n",
      "Processed: TDG\n",
      "Processed: LKQ\n",
      "Processed: DLR\n",
      "Processed: AJG\n",
      "Processed: GPN\n",
      "Processed: ULTA\n",
      "Processed: CNC\n",
      "Processed: HOLX\n",
      "Processed: UDR\n",
      "Processed: AWK\n",
      "Processed: FRT\n",
      "Processed: CFG\n",
      "Processed: EXR\n",
      "Processed: WTW\n",
      "Processed: CHD\n",
      "Processed: HPE\n",
      "Processed: SYF\n",
      "Processed: VRSK\n",
      "Processed: NWS\n",
      "Processed: UAL\n",
      "Processed: KHC\n",
      "Processed: JBHT\n",
      "Processed: QRVO\n",
      "Processed: PYPL\n",
      "Processed: O\n",
      "Processed: AAL\n",
      "Processed: EQIX\n",
      "Processed: HSIC\n",
      "Processed: SWKS\n",
      "Processed: HCA\n",
      "Processed: RCL\n",
      "Processed: UHS\n",
      "Processed: MLM\n",
      "Processed: URI\n",
      "Processed: ESS\n",
      "Processed: AVGO\n",
      "Processed: GOOGL\n",
      "Processed: META\n",
      "Processed: MHK\n",
      "Processed: TSCO\n",
      "Processed: ALLE\n",
      "Processed: AME\n",
      "Processed: VRTX\n",
      "Processed: DAL\n",
      "Processed: ZTS\n",
      "Processed: GM\n",
      "Processed: REGN\n",
      "Processed: ABBV\n",
      "Processed: APTV\n",
      "Processed: HUM\n",
      "Processed: NWSA\n",
      "Processed: DG\n",
      "Processed: MDLZ\n",
      "Processed: PNR\n",
      "Processed: LYB\n",
      "Processed: GRMN\n",
      "Processed: STX\n",
      "Processed: LRCX\n",
      "Processed: MNST\n",
      "Processed: KMI\n",
      "Processed: PSX\n",
      "Processed: CCI\n",
      "Processed: BWA\n",
      "Processed: DLTR\n",
      "Processed: TEL\n",
      "Processed: MOS\n",
      "Processed: ACN\n",
      "Processed: XYL\n",
      "Processed: FCX\n",
      "Processed: MPC\n",
      "Processed: CMG\n",
      "Processed: BLK\n",
      "Processed: EW\n",
      "Processed: FFIV\n",
      "Processed: NFLX\n",
      "Processed: TT\n",
      "Processed: JCI\n",
      "Processed: KMX\n",
      "Processed: CB\n",
      "Processed: OKE\n",
      "Processed: BRK.B\n",
      "Processed: NRG\n",
      "Processed: ROP\n",
      "Processed: V\n",
      "Processed: ROST\n",
      "Processed: BKNG\n",
      "Processed: ES\n",
      "Processed: PWR\n",
      "Processed: WDC\n",
      "Processed: ORLY\n",
      "Processed: HRL\n",
      "Processed: VTR\n",
      "Processed: WELL\n",
      "Processed: FMC\n",
      "Processed: IRM\n",
      "Processed: RSG\n",
      "Processed: WYNN\n",
      "Processed: SJM\n",
      "Processed: WEC\n",
      "Processed: NDAQ\n",
      "Processed: LHX\n",
      "Processed: APH\n",
      "Processed: CRM\n",
      "Processed: FAST\n",
      "Processed: CF\n",
      "Processed: IVZ\n",
      "Processed: MA\n",
      "Processed: DVA\n",
      "Processed: CTRA\n",
      "Processed: ISRG\n",
      "Processed: PM\n",
      "Processed: DOC\n",
      "Processed: AMT\n",
      "Processed: J\n",
      "Processed: EXPD\n",
      "Processed: EXPE\n",
      "Processed: ICE\n",
      "Processed: MCHP\n",
      "Processed: AKAM\n",
      "Processed: DFS\n",
      "Processed: HST\n",
      "Processed: AIZ\n",
      "Processed: CHRW\n",
      "Processed: AVB\n",
      "Processed: RL\n",
      "Processed: CTSH\n",
      "Processed: FIS\n",
      "Processed: CBRE\n",
      "Processed: CME\n",
      "Processed: JNPR\n",
      "Processed: KIM\n",
      "Processed: BXP\n",
      "Processed: GOOG\n",
      "Processed: VRSN\n",
      "Processed: EL\n",
      "Processed: AMZN\n",
      "Processed: AMP\n",
      "Processed: LEN\n",
      "Processed: PSA\n",
      "Processed: TSN\n",
      "Processed: DHI\n",
      "Processed: STZ\n",
      "Processed: LH\n",
      "Processed: TPR\n",
      "Processed: TMO\n",
      "Processed: GILD\n",
      "Processed: MTB\n",
      "Processed: BIIB\n",
      "Processed: PLD\n",
      "Processed: GEN\n",
      "Processed: VTRS\n",
      "Processed: MKC\n",
      "Processed: STT\n",
      "Processed: VLO\n",
      "Processed: DGX\n",
      "Processed: CMCSA\n",
      "Processed: TRV\n",
      "Processed: ELV\n",
      "Processed: EA\n",
      "Processed: GS\n",
      "Processed: PFG\n",
      "Processed: EBAY\n",
      "Processed: PRU\n",
      "Processed: SPG\n",
      "Processed: UPS\n",
      "Processed: WAT\n",
      "Processed: EQR\n",
      "Processed: NVDA\n",
      "Processed: PPL\n",
      "Processed: COR\n",
      "Processed: ZBH\n",
      "Processed: FI\n",
      "Processed: TXN\n",
      "Processed: MET\n",
      "Processed: SYK\n",
      "Processed: CTAS\n",
      "Processed: INTU\n",
      "Processed: EOG\n",
      "Processed: NI\n",
      "Processed: SBUX\n",
      "Processed: A\n",
      "Processed: DVN\n",
      "Processed: ROK\n",
      "Processed: USB\n",
      "Processed: PNW\n",
      "Processed: ADI\n",
      "Processed: QCOM\n",
      "Processed: VMC\n",
      "Processed: BBY\n",
      "Processed: NTAP\n",
      "Processed: AFL\n",
      "Processed: MCK\n",
      "Processed: CCL\n",
      "Processed: DHR\n",
      "Processed: AES\n",
      "Processed: WM\n",
      "Processed: PAYX\n",
      "Processed: RF\n",
      "Processed: COF\n",
      "Processed: MCO\n",
      "Processed: BEN\n",
      "Processed: NTRS\n",
      "Processed: OMC\n",
      "Processed: CINF\n",
      "Processed: TFC\n",
      "Processed: YUM\n",
      "Processed: KLAC\n",
      "Processed: FE\n",
      "Processed: MAR\n",
      "Processed: PGR\n",
      "Processed: HBAN\n",
      "Processed: APA\n",
      "Processed: EFX\n",
      "Processed: SCHW\n",
      "Processed: CAH\n",
      "Processed: AZO\n",
      "Processed: ADBE\n",
      "Processed: AON\n",
      "Processed: FITB\n",
      "Processed: ALL\n",
      "Processed: L\n",
      "Processed: DRI\n",
      "Processed: BK\n",
      "Processed: AMAT\n",
      "Processed: GLW\n",
      "Processed: BSX\n",
      "Processed: PARA\n",
      "Processed: MU\n",
      "Processed: LUV\n",
      "Processed: KEY\n",
      "Processed: MSFT\n",
      "Processed: EMN\n",
      "Processed: CSCO\n",
      "Processed: COST\n",
      "Processed: MS\n",
      "Processed: IPG\n",
      "Processed: UNH\n",
      "Processed: LIN\n",
      "Processed: AMGN\n",
      "Processed: ADSK\n",
      "Processed: K\n",
      "Processed: GL\n",
      "Processed: ORCL\n",
      "Processed: C\n",
      "Processed: PNC\n",
      "Processed: ECL\n",
      "Processed: HD\n",
      "Processed: NKE\n",
      "Processed: AVY\n",
      "Processed: AEE\n",
      "Processed: MMC\n",
      "Processed: SYY\n",
      "Processed: MDT\n",
      "Processed: ITW\n",
      "Processed: PH\n",
      "Processed: DOV\n",
      "Processed: TJX\n",
      "Processed: RVTY\n",
      "Processed: CNP\n",
      "Processed: NUE\n",
      "Processed: APD\n",
      "Processed: HAS\n",
      "Processed: BALL\n",
      "Processed: HES\n",
      "Processed: PHM\n",
      "Processed: LOW\n",
      "Processed: T\n",
      "Processed: VZ\n",
      "Processed: CAG\n",
      "Processed: BBWI\n",
      "Processed: AAPL\n",
      "Processed: BF.B\n",
      "Processed: SNA\n",
      "Processed: SWK\n",
      "Processed: WMT\n",
      "Processed: MAS\n",
      "Processed: GWW\n",
      "Processed: ADP\n",
      "Processed: FDX\n",
      "Processed: AIG\n",
      "Processed: PCAR\n",
      "Processed: WBA\n",
      "Processed: WY\n",
      "Processed: TXT\n",
      "Processed: INTC\n",
      "Processed: TGT\n",
      "Processed: AXP\n",
      "Processed: BAC\n",
      "Processed: CI\n",
      "Processed: DUK\n",
      "Processed: DIS\n",
      "Processed: NEE\n",
      "Processed: TAP\n",
      "Processed: WFC\n",
      "Processed: IFF\n",
      "Processed: JPM\n",
      "Processed: WMB\n",
      "Processed: HPQ\n",
      "Processed: GPC\n",
      "Processed: JNJ\n",
      "Processed: BAX\n",
      "Processed: LLY\n",
      "Processed: MCD\n",
      "Processed: NEM\n",
      "Processed: CLX\n",
      "Processed: BDX\n",
      "Processed: CMI\n",
      "Processed: EMR\n",
      "Processed: SHW\n",
      "Processed: ABT\n",
      "Processed: ADM\n",
      "Processed: AEP\n",
      "Processed: BA\n",
      "Processed: BMY\n",
      "Processed: CMS\n",
      "Processed: CL\n",
      "Processed: CAT\n",
      "Processed: COP\n",
      "Processed: CPB\n",
      "Processed: CVX\n",
      "Processed: CVS\n",
      "Processed: DE\n",
      "Processed: CSX\n",
      "Processed: DTE\n",
      "Processed: EIX\n",
      "Processed: ED\n",
      "Processed: ETN\n",
      "Processed: ETR\n",
      "Processed: EXC\n",
      "Processed: F\n",
      "Processed: GE\n",
      "Processed: GD\n",
      "Processed: GIS\n",
      "Processed: HAL\n",
      "Processed: HIG\n",
      "Processed: HSY\n",
      "Processed: IP\n",
      "Processed: HON\n",
      "Processed: IBM\n",
      "Processed: KMB\n",
      "Processed: KO\n",
      "Processed: KR\n",
      "Processed: MMM\n",
      "Processed: LMT\n",
      "Processed: MO\n",
      "Processed: MRK\n",
      "Processed: MSI\n",
      "Processed: MRO\n",
      "Processed: NOC\n",
      "Processed: NSC\n",
      "Processed: PEG\n",
      "Processed: OXY\n",
      "Processed: PEP\n",
      "Processed: PFE\n",
      "Processed: PG\n",
      "Processed: PPG\n",
      "Processed: SLB\n",
      "Processed: RTX\n",
      "Processed: SO\n",
      "Processed: SPGI\n",
      "Processed: UNP\n",
      "Processed: XEL\n",
      "Processed: XOM\n",
      "Data saved to F:\\SP500_market_cap_2023_2024.csv\n",
      "\n",
      "Data Summary:\n",
      "       jan_2023_market_cap  latest_2024_market_cap  market_cap_change  \\\n",
      "count         4.960000e+02            5.020000e+02       4.960000e+02   \n",
      "mean          7.411339e+10            9.674782e+10       2.352652e+10   \n",
      "std           1.736543e+11            2.940569e+11       1.475958e+11   \n",
      "min           3.853742e+09            0.000000e+00      -1.733732e+11   \n",
      "25%           1.744340e+10            1.832807e+10      -2.565319e+09   \n",
      "50%           3.185987e+10            3.576033e+10       1.900115e+09   \n",
      "75%           6.394661e+10            7.262005e+10       1.179328e+10   \n",
      "max           2.277928e+12            3.350620e+12       2.281696e+12   \n",
      "\n",
      "       market_cap_change_percent  \n",
      "count                 496.000000  \n",
      "mean                   17.225887  \n",
      "std                    59.214364  \n",
      "min                   -71.411919  \n",
      "25%                    -8.754675  \n",
      "50%                     7.914925  \n",
      "75%                    31.145681  \n",
      "max                   919.441818  \n",
      "\n",
      "Companies with missing data:\n",
      "SOLV, SW, GEV, VLTO, KVUE, BRK.B, BF.B\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datetime import datetime\n",
    "\n",
    "# Your API Key\n",
    "API_KEY = 'D7KXZhPjt6caA9dwwAliN6CP3Oofacu5'\n",
    "\n",
    "def get_sp500_constituents():\n",
    "    url = f'https://financialmodelingprep.com/api/v3/sp500_constituent?apikey={API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return [company['symbol'] for company in data]\n",
    "\n",
    "def get_market_cap(symbol):\n",
    "    url = f'https://financialmodelingprep.com/api/v3/historical-market-capitalization/{symbol}?limit=1000&apikey={API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    jan_2023 = None\n",
    "    latest_2024 = None\n",
    "    \n",
    "    for item in data:\n",
    "        date = datetime.strptime(item['date'], '%Y-%m-%d')\n",
    "        if date.year == 2023 and date.month == 1:\n",
    "            if jan_2023 is None or date > datetime.strptime(jan_2023['date'], '%Y-%m-%d'):\n",
    "                jan_2023 = item\n",
    "        elif date.year == 2024:\n",
    "            if latest_2024 is None or date > datetime.strptime(latest_2024['date'], '%Y-%m-%d'):\n",
    "                latest_2024 = item\n",
    "    \n",
    "    return {\n",
    "        'symbol': symbol,\n",
    "        'jan_2023_date': jan_2023['date'] if jan_2023 else None,\n",
    "        'jan_2023_market_cap': jan_2023['marketCap'] if jan_2023 else None,\n",
    "        'latest_2024_date': latest_2024['date'] if latest_2024 else None,\n",
    "        'latest_2024_market_cap': latest_2024['marketCap'] if latest_2024 else None\n",
    "    }\n",
    "\n",
    "# Get S&P 500 constituents\n",
    "sp500_symbols = get_sp500_constituents()\n",
    "print(f\"Total S&P 500 constituents: {len(sp500_symbols)}\")\n",
    "\n",
    "# Fetch market cap data for all companies using ThreadPoolExecutor\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    future_to_symbol = {executor.submit(get_market_cap, symbol): symbol for symbol in sp500_symbols}\n",
    "    for future in as_completed(future_to_symbol):\n",
    "        symbol = future_to_symbol[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "            print(f\"Processed: {symbol}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {symbol}: {str(e)}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Calculate market cap change\n",
    "df['market_cap_change'] = df['latest_2024_market_cap'] - df['jan_2023_market_cap']\n",
    "df['market_cap_change_percent'] = (df['market_cap_change'] / df['jan_2023_market_cap']) * 100\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = 'F:\\\\SP500_market_cap_2023_2024.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"Data saved to {csv_path}\")\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nData Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Print companies with missing data\n",
    "missing_data = df[(df['jan_2023_market_cap'].isnull()) | (df['latest_2024_market_cap'].isnull())]\n",
    "if not missing_data.empty:\n",
    "    print(\"\\nCompanies with missing data:\")\n",
    "    print(\", \".join(missing_data['symbol']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total S&P 500 constituents: 503\n",
      "Processed: GDDY\n",
      "Processed: GEV\n",
      "Processed: SMCI\n",
      "Processed: VST\n",
      "Processed: BLDR\n",
      "Processed: CRWD\n",
      "Processed: SW\n",
      "Processed: DECK\n",
      "Processed: KKR\n",
      "Processed: SOLV\n",
      "Processed: JBL\n",
      "Processed: UBER\n",
      "Processed: HUBB\n",
      "Processed: ABNB\n",
      "Processed: KVUE\n",
      "Processed: AXON\n",
      "Processed: VLTO\n",
      "Processed: LULU\n",
      "Processed: PANW\n",
      "Processed: BX\n",
      "Processed: BG\n",
      "Processed: FICO\n",
      "Processed: PODD\n",
      "Processed: PCG\n",
      "Processed: STLD\n",
      "Processed: TRGP\n",
      "Processed: ACGL\n",
      "Processed: EQT\n",
      "Processed: GEHC\n",
      "Processed: CSGP\n",
      "Processed: INVH\n",
      "Processed: KDP\n",
      "Processed: VICI\n",
      "Processed: WBD\n",
      "Processed: ON\n",
      "Processed: CPT\n",
      "Processed: MOH\n",
      "Processed: FSLR\n",
      "Processed: NDSN\n",
      "Processed: CEG\n",
      "Processed: FDS\n",
      "Processed: EPAM\n",
      "Processed: BRO\n",
      "Processed: DAY\n",
      "Processed: MTCH\n",
      "Processed: TECH\n",
      "Processed: MRNA\n",
      "Processed: CRL\n",
      "Processed: PTC\n",
      "Processed: CZR\n",
      "Processed: GNRC\n",
      "Processed: NXPI\n",
      "Processed: MPWR\n",
      "Processed: TRMB\n",
      "Processed: ENPH\n",
      "Processed: TSLA\n",
      "Processed: POOL\n",
      "Processed: TER\n",
      "Processed: CTLT\n",
      "Processed: BIO\n",
      "Processed: TDY\n",
      "Processed: ETSY\n",
      "Processed: TYL\n",
      "Processed: WST\n",
      "Processed: DPZ\n",
      "Processed: CARR\n",
      "Processed: DXCM\n",
      "Processed: PAYC\n",
      "Processed: LYV\n",
      "Processed: STE\n",
      "Processed: OTIS\n",
      "Processed: IR\n",
      "Processed: ZBRA\n",
      "Processed: ODFL\n",
      "Processed: WRB\n",
      "Processed: NOW\n",
      "Processed: LVS\n",
      "Processed: NVR\n",
      "Processed: CDW\n",
      "Processed: IEX\n",
      "Processed: LDOS\n",
      "Processed: TROW\n",
      "Processed: TMUS\n",
      "Processed: MKTX\n",
      "Processed: AMCR\n",
      "Processed: CTVA\n",
      "Processed: DD\n",
      "Processed: DOW\n",
      "Processed: FOX\n",
      "Processed: FOXA\n",
      "Processed: WAB\n",
      "Processed: TFX\n",
      "Processed: ATO\n",
      "Processed: CE\n",
      "Processed: FANG\n",
      "Processed: LW\n",
      "Processed: JKHY\n",
      "Processed: KEYS\n",
      "Processed: FTNT\n",
      "Processed: ROL\n",
      "Processed: CPRT\n",
      "Processed: CPAY\n",
      "Processed: MSCI\n",
      "Processed: HII\n",
      "Processed: NCLH\n",
      "Processed: CDNS\n",
      "Processed: EVRG\n",
      "Processed: ANET\n",
      "Processed: BR\n",
      "Processed: SBAC\n",
      "Processed: IQV\n",
      "Processed: AOS\n",
      "Processed: TTWO\n",
      "Processed: MGM\n",
      "Processed: PKG\n",
      "Processed: BKR\n",
      "Processed: ALGN\n",
      "Processed: ANSS\n",
      "Processed: HLT\n",
      "Processed: EG\n",
      "Processed: IT\n",
      "Processed: RMD\n",
      "Processed: AMD\n",
      "Processed: ARE\n",
      "Processed: RJF\n",
      "Processed: SRE\n",
      "Processed: REG\n",
      "Processed: INCY\n",
      "Processed: IDXX\n",
      "Processed: MAA\n",
      "Processed: HWM\n",
      "Processed: CHTR\n",
      "Processed: D\n",
      "Processed: COO\n",
      "Processed: SNPS\n",
      "Processed: CBOE\n",
      "Processed: ALB\n",
      "Processed: MTD\n",
      "Processed: LNT\n",
      "Processed: TDG\n",
      "Processed: AJG\n",
      "Processed: LKQ\n",
      "Processed: DLR\n",
      "Processed: GPN\n",
      "Processed: ULTA\n",
      "Processed: FTV\n",
      "Processed: CNC\n",
      "Processed: HOLX\n",
      "Processed: UDR\n",
      "Processed: AWK\n",
      "Processed: FRT\n",
      "Processed: CFG\n",
      "Processed: EXR\n",
      "Processed: WTW\n",
      "Processed: CHD\n",
      "Processed: SYF\n",
      "Processed: HPE\n",
      "Processed: NWS\n",
      "Processed: VRSK\n",
      "Processed: UAL\n",
      "Processed: PYPL\n",
      "Processed: KHC\n",
      "Processed: O\n",
      "Processed: JBHT\n",
      "Processed: EQIX\n",
      "Processed: AAL\n",
      "Processed: HSIC\n",
      "Processed: HCA\n",
      "Processed: QRVO\n",
      "Processed: SWKS\n",
      "Processed: RCL\n",
      "Processed: UHS\n",
      "Processed: URI\n",
      "Processed: MLM\n",
      "Processed: AVGO\n",
      "Processed: GOOGL\n",
      "Processed: ESS\n",
      "Processed: TSCO\n",
      "Processed: META\n",
      "Processed: ALLE\n",
      "Processed: MHK\n",
      "Processed: AME\n",
      "Processed: VRTX\n",
      "Processed: DAL\n",
      "Processed: NWSA\n",
      "Processed: ZTS\n",
      "Processed: GM\n",
      "Processed: REGN\n",
      "Processed: ABBV\n",
      "Processed: GRMN\n",
      "Processed: APTV\n",
      "Processed: HUM\n",
      "Processed: MDLZ\n",
      "Processed: DG\n",
      "Processed: PNR\n",
      "Processed: LYB\n",
      "Processed: STX\n",
      "Processed: LRCX\n",
      "Processed: MNST\n",
      "Processed: CCI\n",
      "Processed: PSX\n",
      "Processed: KMI\n",
      "Processed: BWA\n",
      "Processed: DLTR\n",
      "Processed: XYL\n",
      "Processed: TEL\n",
      "Processed: MOS\n",
      "Processed: ACN\n",
      "Processed: CMG\n",
      "Processed: BLK\n",
      "Processed: MPC\n",
      "Processed: FFIV\n",
      "Processed: EW\n",
      "Processed: NFLX\n",
      "Processed: TT\n",
      "Processed: JCI\n",
      "Processed: FCX\n",
      "Processed: CB\n",
      "Processed: OKE\n",
      "Processed: BRK.B\n",
      "Processed: KMX\n",
      "Processed: ROP\n",
      "Processed: NRG\n",
      "Processed: ROST\n",
      "Processed: V\n",
      "Processed: BKNG\n",
      "Processed: FMC\n",
      "Processed: ES\n",
      "Processed: ORLY\n",
      "Processed: PWR\n",
      "Processed: WDC\n",
      "Processed: HRL\n",
      "Processed: WELL\n",
      "Processed: VTR\n",
      "Processed: IRM\n",
      "Processed: RSG\n",
      "Processed: WYNN\n",
      "Processed: SJM\n",
      "Processed: APH\n",
      "Processed: NDAQ\n",
      "Processed: WEC\n",
      "Processed: LHX\n",
      "Processed: CRM\n",
      "Processed: FAST\n",
      "Processed: CF\n",
      "Processed: IVZ\n",
      "Processed: DVA\n",
      "Processed: MA\n",
      "Processed: CTRA\n",
      "Processed: ISRG\n",
      "Processed: DOC\n",
      "Processed: PM\n",
      "Processed: AMT\n",
      "Processed: J\n",
      "Processed: EXPD\n",
      "Processed: EXPE\n",
      "Processed: ICE\n",
      "Processed: MCHP\n",
      "Processed: AIZ\n",
      "Processed: DFS\n",
      "Processed: AKAM\n",
      "Processed: HST\n",
      "Processed: CHRW\n",
      "Processed: RL\n",
      "Processed: AVB\n",
      "Processed: CTSH\n",
      "Processed: FIS\n",
      "Processed: JNPR\n",
      "Processed: CME\n",
      "Processed: KIM\n",
      "Processed: VRSN\n",
      "Processed: BXP\n",
      "Processed: CBRE\n",
      "Processed: GOOG\n",
      "Processed: AMZN\n",
      "Processed: EL\n",
      "Processed: LEN\n",
      "Processed: AMP\n",
      "Processed: PSA\n",
      "Processed: TSN\n",
      "Processed: STZ\n",
      "Processed: LH\n",
      "Processed: TPR\n",
      "Processed: DHI\n",
      "Processed: TMO\n",
      "Processed: GILD\n",
      "Processed: VTRS\n",
      "Processed: MTB\n",
      "Processed: PLD\n",
      "Processed: BIIB\n",
      "Processed: GEN\n",
      "Processed: MKC\n",
      "Processed: STT\n",
      "Processed: VLO\n",
      "Processed: DGX\n",
      "Processed: CMCSA\n",
      "Processed: TRV\n",
      "Processed: ELV\n",
      "Processed: EA\n",
      "Processed: EBAY\n",
      "Processed: GS\n",
      "Processed: PRU\n",
      "Processed: PFG\n",
      "Processed: UPS\n",
      "Processed: SPG\n",
      "Processed: EQR\n",
      "Processed: PPL\n",
      "Processed: WAT\n",
      "Processed: COR\n",
      "Processed: NVDA\n",
      "Processed: FI\n",
      "Processed: ZBH\n",
      "Processed: TXN\n",
      "Processed: SYK\n",
      "Processed: MET\n",
      "Processed: CTAS\n",
      "Processed: INTU\n",
      "Processed: DVN\n",
      "Processed: EOG\n",
      "Processed: SBUX\n",
      "Processed: NI\n",
      "Processed: A\n",
      "Processed: USB\n",
      "Processed: ROK\n",
      "Processed: ADI\n",
      "Processed: PNW\n",
      "Processed: QCOM\n",
      "Processed: VMC\n",
      "Processed: BBY\n",
      "Processed: MCK\n",
      "Processed: NTAP\n",
      "Processed: AFL\n",
      "Processed: CCL\n",
      "Processed: DHR\n",
      "Processed: AES\n",
      "Processed: PAYX\n",
      "Processed: WM\n",
      "Processed: RF\n",
      "Processed: COF\n",
      "Processed: MCO\n",
      "Processed: NTRS\n",
      "Processed: MAR\n",
      "Processed: BEN\n",
      "Processed: CINF\n",
      "Processed: TFC\n",
      "Processed: OMC\n",
      "Processed: FE\n",
      "Processed: YUM\n",
      "Processed: KLAC\n",
      "Processed: HBAN\n",
      "Processed: APA\n",
      "Processed: PGR\n",
      "Processed: EFX\n",
      "Processed: SCHW\n",
      "Processed: CAH\n",
      "Processed: ADBE\n",
      "Processed: AZO\n",
      "Processed: FITB\n",
      "Processed: ALL\n",
      "Processed: L\n",
      "Processed: DRI\n",
      "Processed: AON\n",
      "Processed: AMAT\n",
      "Processed: BK\n",
      "Processed: GLW\n",
      "Processed: BSX\n",
      "Processed: PARA\n",
      "Processed: MU\n",
      "Processed: LUV\n",
      "Processed: MSFT\n",
      "Processed: UNH\n",
      "Processed: KEY\n",
      "Processed: EMN\n",
      "Processed: CSCO\n",
      "Processed: COST\n",
      "Processed: MS\n",
      "Processed: LIN\n",
      "Processed: AMGN\n",
      "Processed: AEE\n",
      "Processed: ADSK\n",
      "Processed: IPG\n",
      "Processed: K\n",
      "Processed: ORCL\n",
      "Processed: GL\n",
      "Processed: ECL\n",
      "Processed: NKE\n",
      "Processed: C\n",
      "Processed: PNC\n",
      "Processed: HD\n",
      "Processed: AVY\n",
      "Processed: MMC\n",
      "Processed: SYY\n",
      "Processed: PH\n",
      "Processed: MDT\n",
      "Processed: ITW\n",
      "Processed: DOV\n",
      "Processed: TJX\n",
      "Processed: RVTY\n",
      "Processed: APD\n",
      "Processed: NUE\n",
      "Processed: BALL\n",
      "Processed: HES\n",
      "Processed: PHM\n",
      "Processed: HAS\n",
      "Processed: LOW\n",
      "Processed: CNP\n",
      "Processed: T\n",
      "Processed: VZ\n",
      "Processed: BBWI\n",
      "Processed: CAG\n",
      "Processed: AAPL\n",
      "Processed: BF.B\n",
      "Processed: SNA\n",
      "Processed: WMT\n",
      "Processed: GWW\n",
      "Processed: SWK\n",
      "Processed: MAS\n",
      "Processed: ADP\n",
      "Processed: PCAR\n",
      "Processed: FDX\n",
      "Processed: WBA\n",
      "Processed: AIG\n",
      "Processed: WY\n",
      "Processed: TXT\n",
      "Processed: INTC\n",
      "Processed: TGT\n",
      "Processed: AXP\n",
      "Processed: BAC\n",
      "Processed: CI\n",
      "Processed: DIS\n",
      "Processed: NEE\n",
      "Processed: DUK\n",
      "Processed: WFC\n",
      "Processed: IFF\n",
      "Processed: JPM\n",
      "Processed: WMB\n",
      "Processed: TAP\n",
      "Processed: HPQ\n",
      "Processed: GPC\n",
      "Processed: JNJ\n",
      "Processed: BAX\n",
      "Processed: BDX\n",
      "Processed: LLY\n",
      "Processed: MCD\n",
      "Processed: NEM\n",
      "Processed: CLX\n",
      "Processed: CMI\n",
      "Processed: EMR\n",
      "Processed: SHW\n",
      "Processed: ABT\n",
      "Processed: ADM\n",
      "Processed: AEP\n",
      "Processed: BA\n",
      "Processed: BMY\n",
      "Processed: CL\n",
      "Processed: CAT\n",
      "Processed: CMS\n",
      "Processed: COP\n",
      "Processed: CSX\n",
      "Processed: CPB\n",
      "Processed: CVS\n",
      "Processed: CVX\n",
      "Processed: DE\n",
      "Processed: DTE\n",
      "Processed: EIX\n",
      "Processed: ED\n",
      "Processed: ETR\n",
      "Processed: ETN\n",
      "Processed: EXC\n",
      "Processed: F\n",
      "Processed: GD\n",
      "Processed: GE\n",
      "Processed: GIS\n",
      "Processed: HAL\n",
      "Processed: HIG\n",
      "Processed: HON\n",
      "Processed: HSY\n",
      "Processed: IBM\n",
      "Processed: KMB\n",
      "Processed: IP\n",
      "Processed: LMT\n",
      "Processed: KR\n",
      "Processed: KO\n",
      "Processed: MMM\n",
      "Processed: MO\n",
      "Processed: MRK\n",
      "Processed: MRO\n",
      "Processed: MSI\n",
      "Processed: NOC\n",
      "Processed: NSC\n",
      "Processed: OXY\n",
      "Processed: PEG\n",
      "Processed: PEP\n",
      "Processed: PFE\n",
      "Processed: PG\n",
      "Processed: PPG\n",
      "Processed: SLB\n",
      "Processed: RTX\n",
      "Processed: SO\n",
      "Processed: SPGI\n",
      "Processed: XEL\n",
      "Processed: UNP\n",
      "Processed: XOM\n",
      "Data saved to F:\\SP500_market_cap_2023_202411.csv\n",
      "\n",
      "Data Summary:\n",
      "       jan_2023_market_cap  latest_2024_market_cap  market_cap_change  \\\n",
      "count         4.960000e+02            5.020000e+02       4.960000e+02   \n",
      "mean          7.411339e+10            9.674782e+10       2.352652e+10   \n",
      "std           1.736543e+11            2.940569e+11       1.475958e+11   \n",
      "min           3.853742e+09            0.000000e+00      -1.733732e+11   \n",
      "25%           1.744340e+10            1.832807e+10      -2.565319e+09   \n",
      "50%           3.185987e+10            3.576033e+10       1.900115e+09   \n",
      "75%           6.394661e+10            7.262005e+10       1.179328e+10   \n",
      "max           2.277928e+12            3.350620e+12       2.281696e+12   \n",
      "\n",
      "       market_cap_change_percent  \n",
      "count                 496.000000  \n",
      "mean                   17.225887  \n",
      "std                    59.214364  \n",
      "min                   -71.411919  \n",
      "25%                    -8.754675  \n",
      "50%                     7.914925  \n",
      "75%                    31.145681  \n",
      "max                   919.441818  \n",
      "\n",
      "Companies with missing data:\n",
      "GEV (GE Vernova)\n",
      "SW (Smurfit WestRock PLC)\n",
      "SOLV (Solventum)\n",
      "KVUE (Kenvue)\n",
      "VLTO (Veralto)\n",
      "BRK.B (Berkshire Hathaway)\n",
      "BF.B (Brown–Forman)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datetime import datetime\n",
    "\n",
    "# Your API Key\n",
    "API_KEY = 'D7KXZhPjt6caA9dwwAliN6CP3Oofacu5'\n",
    "\n",
    "def get_sp500_constituents():\n",
    "    url = f'https://financialmodelingprep.com/api/v3/sp500_constituent?apikey={API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return {company['symbol']: company['name'] for company in data}\n",
    "\n",
    "def get_market_cap(symbol, name):\n",
    "    url = f'https://financialmodelingprep.com/api/v3/historical-market-capitalization/{symbol}?limit=1000&apikey={API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    jan_2023 = None\n",
    "    latest_2024 = None\n",
    "    \n",
    "    for item in data:\n",
    "        date = datetime.strptime(item['date'], '%Y-%m-%d')\n",
    "        if date.year == 2023 and date.month == 1:\n",
    "            if jan_2023 is None or date > datetime.strptime(jan_2023['date'], '%Y-%m-%d'):\n",
    "                jan_2023 = item\n",
    "        elif date.year == 2024:\n",
    "            if latest_2024 is None or date > datetime.strptime(latest_2024['date'], '%Y-%m-%d'):\n",
    "                latest_2024 = item\n",
    "    \n",
    "    return {\n",
    "        'symbol': symbol,\n",
    "        'name': name,\n",
    "        'jan_2023_date': jan_2023['date'] if jan_2023 else None,\n",
    "        'jan_2023_market_cap': jan_2023['marketCap'] if jan_2023 else None,\n",
    "        'latest_2024_date': latest_2024['date'] if latest_2024 else None,\n",
    "        'latest_2024_market_cap': latest_2024['marketCap'] if latest_2024 else None\n",
    "    }\n",
    "\n",
    "# Get S&P 500 constituents\n",
    "sp500_companies = get_sp500_constituents()\n",
    "print(f\"Total S&P 500 constituents: {len(sp500_companies)}\")\n",
    "\n",
    "# Fetch market cap data for all companies using ThreadPoolExecutor\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    future_to_company = {executor.submit(get_market_cap, symbol, name): symbol for symbol, name in sp500_companies.items()}\n",
    "    for future in as_completed(future_to_company):\n",
    "        symbol = future_to_company[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "            print(f\"Processed: {symbol}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {symbol}: {str(e)}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Calculate market cap change\n",
    "df['market_cap_change'] = df['latest_2024_market_cap'] - df['jan_2023_market_cap']\n",
    "df['market_cap_change_percent'] = (df['market_cap_change'] / df['jan_2023_market_cap']) * 100\n",
    "\n",
    "# Reorder columns\n",
    "df = df[['symbol', 'name', 'jan_2023_date', 'jan_2023_market_cap', 'latest_2024_date', 'latest_2024_market_cap', 'market_cap_change', 'market_cap_change_percent']]\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = 'F:\\\\SP500_market_cap_2023_202411.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"Data saved to {csv_path}\")\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nData Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Print companies with missing data\n",
    "missing_data = df[(df['jan_2023_market_cap'].isnull()) | (df['latest_2024_market_cap'].isnull())]\n",
    "if not missing_data.empty:\n",
    "    print(\"\\nCompanies with missing data:\")\n",
    "    for _, row in missing_data.iterrows():\n",
    "        print(f\"{row['symbol']} ({row['name']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total S&P 500 constituents: 503\n",
      "Processed: CRWD\n",
      "Processed: DECK\n",
      "Processed: GEV\n",
      "Processed: SMCI\n",
      "Processed: GDDY\n",
      "Processed: SOLV\n",
      "Processed: KKR\n",
      "Processed: VST\n",
      "Processed: BLDR\n",
      "Processed: SW\n",
      "Processed: JBL\n",
      "Processed: VLTO\n",
      "Processed: UBER\n",
      "Processed: BX\n",
      "Processed: HUBB\n",
      "Processed: KVUE\n",
      "Processed: ABNB\n",
      "Processed: AXON\n",
      "Processed: LULU\n",
      "Processed: PANW\n",
      "Processed: FICO\n",
      "Processed: BG\n",
      "Processed: PODD\n",
      "Processed: GEHC\n",
      "Processed: STLD\n",
      "Processed: ACGL\n",
      "Processed: EQT\n",
      "Processed: PCG\n",
      "Processed: FSLR\n",
      "Processed: TRGP\n",
      "Processed: CSGP\n",
      "Processed: INVH\n",
      "Processed: KDP\n",
      "Processed: ON\n",
      "Processed: VICI\n",
      "Processed: MOH\n",
      "Processed: WBD\n",
      "Processed: CPT\n",
      "Processed: NDSN\n",
      "Processed: CEG\n",
      "Processed: FDS\n",
      "Processed: EPAM\n",
      "Processed: DAY\n",
      "Processed: BRO\n",
      "Processed: MTCH\n",
      "Processed: TECH\n",
      "Processed: MRNA\n",
      "Processed: CRL\n",
      "Processed: PTC\n",
      "Processed: CZR\n",
      "Processed: GNRC\n",
      "Processed: NXPI\n",
      "Processed: MPWR\n",
      "Processed: TRMB\n",
      "Processed: ENPH\n",
      "Processed: TSLA\n",
      "Processed: POOL\n",
      "Processed: CTLT\n",
      "Processed: ETSY\n",
      "Processed: TER\n",
      "Processed: BIO\n",
      "Processed: TYL\n",
      "Processed: TDY\n",
      "Processed: WST\n",
      "Processed: DPZ\n",
      "Processed: DXCM\n",
      "Processed: CARR\n",
      "Processed: OTIS\n",
      "Processed: IR\n",
      "Processed: PAYC\n",
      "Processed: LYV\n",
      "Processed: STE\n",
      "Processed: ZBRA\n",
      "Processed: ODFL\n",
      "Processed: WRB\n",
      "Processed: NOW\n",
      "Processed: LVS\n",
      "Processed: NVR\n",
      "Processed: CDW\n",
      "Processed: IEX\n",
      "Processed: LDOS\n",
      "Processed: TROW\n",
      "Processed: TMUS\n",
      "Processed: AMCR\n",
      "Processed: MKTX\n",
      "Processed: CTVA\n",
      "Processed: DD\n",
      "Processed: DOW\n",
      "Processed: FOX\n",
      "Processed: FOXA\n",
      "Processed: ATO\n",
      "Processed: WAB\n",
      "Processed: TFX\n",
      "Processed: CE\n",
      "Processed: FANG\n",
      "Processed: LW\n",
      "Processed: JKHY\n",
      "Processed: KEYS\n",
      "Processed: FTNT\n",
      "Processed: ROL\n",
      "Processed: ANET\n",
      "Processed: CPRT\n",
      "Processed: CPAY\n",
      "Processed: BR\n",
      "Processed: EVRG\n",
      "Processed: MSCI\n",
      "Processed: TTWO\n",
      "Processed: HII\n",
      "Processed: NCLH\n",
      "Processed: CDNS\n",
      "Processed: SBAC\n",
      "Processed: AOS\n",
      "Processed: IQV\n",
      "Processed: MGM\n",
      "Processed: PKG\n",
      "Processed: BKR\n",
      "Processed: RMD\n",
      "Processed: ALGN\n",
      "Processed: ANSS\n",
      "Processed: EG\n",
      "Processed: HLT\n",
      "Processed: IT\n",
      "Processed: AMD\n",
      "Processed: ARE\n",
      "Processed: RJF\n",
      "Processed: SRE\n",
      "Processed: SNPS\n",
      "Processed: REG\n",
      "Processed: CBOE\n",
      "Processed: INCY\n",
      "Processed: IDXX\n",
      "Processed: MAA\n",
      "Processed: HWM\n",
      "Processed: D\n",
      "Processed: COO\n",
      "Processed: CHTR\n",
      "Processed: MTD\n",
      "Processed: ALB\n",
      "Processed: FTV\n",
      "Processed: LNT\n",
      "Processed: TDG\n",
      "Processed: AJG\n",
      "Processed: LKQ\n",
      "Processed: DLR\n",
      "Processed: GPN\n",
      "Processed: ULTA\n",
      "Processed: HOLX\n",
      "Processed: CNC\n",
      "Processed: UDR\n",
      "Processed: AWK\n",
      "Processed: FRT\n",
      "Processed: CFG\n",
      "Processed: EXR\n",
      "Processed: WTW\n",
      "Processed: CHD\n",
      "Processed: SYF\n",
      "Processed: VRSK\n",
      "Processed: HPE\n",
      "Processed: NWS\n",
      "Processed: UAL\n",
      "Processed: PYPL\n",
      "Processed: KHC\n",
      "Processed: JBHT\n",
      "Processed: QRVO\n",
      "Processed: AAL\n",
      "Processed: O\n",
      "Processed: HSIC\n",
      "Processed: EQIX\n",
      "Processed: SWKS\n",
      "Processed: HCA\n",
      "Processed: RCL\n",
      "Processed: UHS\n",
      "Processed: MLM\n",
      "Processed: URI\n",
      "Processed: GOOGL\n",
      "Processed: AVGO\n",
      "Processed: ESS\n",
      "Processed: TSCO\n",
      "Processed: META\n",
      "Processed: MHK\n",
      "Processed: ALLE\n",
      "Processed: AME\n",
      "Processed: DAL\n",
      "Processed: VRTX\n",
      "Processed: NWSA\n",
      "Processed: ZTS\n",
      "Processed: GM\n",
      "Processed: REGN\n",
      "Processed: ABBV\n",
      "Processed: APTV\n",
      "Processed: GRMN\n",
      "Processed: HUM\n",
      "Processed: DG\n",
      "Processed: MDLZ\n",
      "Processed: LYB\n",
      "Processed: PNR\n",
      "Processed: STX\n",
      "Processed: LRCX\n",
      "Processed: MNST\n",
      "Processed: KMI\n",
      "Processed: PSX\n",
      "Processed: CCI\n",
      "Processed: BWA\n",
      "Processed: DLTR\n",
      "Processed: XYL\n",
      "Processed: TEL\n",
      "Processed: MOS\n",
      "Processed: FCX\n",
      "Processed: MPC\n",
      "Processed: CMG\n",
      "Processed: ACN\n",
      "Processed: BLK\n",
      "Processed: FFIV\n",
      "Processed: NFLX\n",
      "Processed: CB\n",
      "Processed: JCI\n",
      "Processed: EW\n",
      "Processed: KMX\n",
      "Processed: TT\n",
      "Processed: OKE\n",
      "Processed: BRK.B\n",
      "Processed: NRG\n",
      "Processed: ROP\n",
      "Processed: ROST\n",
      "Processed: V\n",
      "Processed: BKNG\n",
      "Processed: FMC\n",
      "Processed: ES\n",
      "Processed: PWR\n",
      "Processed: WDC\n",
      "Processed: ORLY\n",
      "Processed: HRL\n",
      "Processed: VTR\n",
      "Processed: WELL\n",
      "Processed: IRM\n",
      "Processed: RSG\n",
      "Processed: WYNN\n",
      "Processed: SJM\n",
      "Processed: WEC\n",
      "Processed: NDAQ\n",
      "Processed: APH\n",
      "Processed: LHX\n",
      "Processed: FAST\n",
      "Processed: CF\n",
      "Processed: IVZ\n",
      "Processed: CRM\n",
      "Processed: DVA\n",
      "Processed: MA\n",
      "Processed: CTRA\n",
      "Processed: ISRG\n",
      "Processed: PM\n",
      "Processed: J\n",
      "Processed: DOC\n",
      "Processed: EXPD\n",
      "Processed: MCHP\n",
      "Processed: ICE\n",
      "Processed: AKAM\n",
      "Processed: AMT\n",
      "Processed: EXPE\n",
      "Processed: AIZ\n",
      "Processed: DFS\n",
      "Processed: CHRW\n",
      "Processed: RL\n",
      "Processed: HST\n",
      "Processed: AVB\n",
      "Processed: CTSH\n",
      "Processed: CBRE\n",
      "Processed: CME\n",
      "Processed: FIS\n",
      "Processed: BXP\n",
      "Processed: VRSN\n",
      "Processed: JNPR\n",
      "Processed: GOOG\n",
      "Processed: KIM\n",
      "Processed: EL\n",
      "Processed: AMZN\n",
      "Processed: LEN\n",
      "Processed: AMP\n",
      "Processed: PSA\n",
      "Processed: TSN\n",
      "Processed: STZ\n",
      "Processed: DHI\n",
      "Processed: TPR\n",
      "Processed: LH\n",
      "Processed: TMO\n",
      "Processed: GILD\n",
      "Processed: VTRS\n",
      "Processed: MTB\n",
      "Processed: BIIB\n",
      "Processed: PLD\n",
      "Processed: MKC\n",
      "Processed: GEN\n",
      "Processed: STT\n",
      "Processed: VLO\n",
      "Processed: DGX\n",
      "Processed: CMCSA\n",
      "Processed: TRV\n",
      "Processed: ELV\n",
      "Processed: EA\n",
      "Processed: EBAY\n",
      "Processed: PFG\n",
      "Processed: GS\n",
      "Processed: PRU\n",
      "Processed: UPS\n",
      "Processed: SPG\n",
      "Processed: WAT\n",
      "Processed: NVDA\n",
      "Processed: EQR\n",
      "Processed: PPL\n",
      "Processed: COR\n",
      "Processed: ZBH\n",
      "Processed: CTAS\n",
      "Processed: FI\n",
      "Processed: TXN\n",
      "Processed: SYK\n",
      "Processed: MET\n",
      "Processed: INTU\n",
      "Processed: EOG\n",
      "Processed: NI\n",
      "Processed: DVN\n",
      "Processed: SBUX\n",
      "Processed: A\n",
      "Processed: USB\n",
      "Processed: ROK\n",
      "Processed: ADI\n",
      "Processed: QCOM\n",
      "Processed: PNW\n",
      "Processed: VMC\n",
      "Processed: BBY\n",
      "Processed: AFL\n",
      "Processed: NTAP\n",
      "Processed: MCK\n",
      "Processed: CCL\n",
      "Processed: DHR\n",
      "Processed: AES\n",
      "Processed: PAYX\n",
      "Processed: WM\n",
      "Processed: RF\n",
      "Processed: COF\n",
      "Processed: MCO\n",
      "Processed: MAR\n",
      "Processed: BEN\n",
      "Processed: NTRS\n",
      "Processed: OMC\n",
      "Processed: CINF\n",
      "Processed: TFC\n",
      "Processed: FE\n",
      "Processed: KLAC\n",
      "Processed: YUM\n",
      "Processed: HBAN\n",
      "Processed: PGR\n",
      "Processed: APA\n",
      "Processed: EFX\n",
      "Processed: SCHW\n",
      "Processed: CAH\n",
      "Processed: ADBE\n",
      "Processed: AZO\n",
      "Processed: FITB\n",
      "Processed: AON\n",
      "Processed: ALL\n",
      "Processed: DRI\n",
      "Processed: L\n",
      "Processed: BK\n",
      "Processed: AMAT\n",
      "Processed: GLW\n",
      "Processed: BSX\n",
      "Processed: PARA\n",
      "Processed: MU\n",
      "Processed: LUV\n",
      "Processed: UNH\n",
      "Processed: MSFT\n",
      "Processed: KEY\n",
      "Processed: EMN\n",
      "Processed: CSCO\n",
      "Processed: COST\n",
      "Processed: MS\n",
      "Processed: IPG\n",
      "Processed: LIN\n",
      "Processed: AMGN\n",
      "Processed: AEE\n",
      "Processed: K\n",
      "Processed: ORCL\n",
      "Processed: GL\n",
      "Processed: ADSK\n",
      "Processed: ECL\n",
      "Processed: NKE\n",
      "Processed: C\n",
      "Processed: HD\n",
      "Processed: PNC\n",
      "Processed: AVY\n",
      "Processed: MMC\n",
      "Processed: SYY\n",
      "Processed: MDT\n",
      "Processed: ITW\n",
      "Processed: PH\n",
      "Processed: DOV\n",
      "Processed: RVTY\n",
      "Processed: TJX\n",
      "Processed: CNP\n",
      "Processed: APD\n",
      "Processed: NUE\n",
      "Processed: BALL\n",
      "Processed: HAS\n",
      "Processed: PHM\n",
      "Processed: HES\n",
      "Processed: LOW\n",
      "Processed: T\n",
      "Processed: VZ\n",
      "Processed: BBWI\n",
      "Processed: CAG\n",
      "Processed: BF.B\n",
      "Processed: AAPL\n",
      "Processed: SNA\n",
      "Processed: SWK\n",
      "Processed: WMT\n",
      "Processed: GWW\n",
      "Processed: MAS\n",
      "Processed: ADP\n",
      "Processed: FDX\n",
      "Processed: PCAR\n",
      "Processed: WBA\n",
      "Processed: WY\n",
      "Processed: AIG\n",
      "Processed: INTC\n",
      "Processed: TGT\n",
      "Processed: AXP\n",
      "Processed: TXT\n",
      "Processed: BAC\n",
      "Processed: CI\n",
      "Processed: DIS\n",
      "Processed: DUK\n",
      "Processed: WFC\n",
      "Processed: NEE\n",
      "Processed: TAP\n",
      "Processed: IFF\n",
      "Processed: JPM\n",
      "Processed: HPQ\n",
      "Processed: WMB\n",
      "Processed: GPC\n",
      "Processed: BAX\n",
      "Processed: LLY\n",
      "Processed: BDX\n",
      "Processed: JNJ\n",
      "Processed: CLX\n",
      "Processed: NEM\n",
      "Processed: CMI\n",
      "Processed: EMR\n",
      "Processed: ABT\n",
      "Processed: SHW\n",
      "Processed: MCD\n",
      "Processed: ADM\n",
      "Processed: AEP\n",
      "Processed: BMY\n",
      "Processed: CAT\n",
      "Processed: BA\n",
      "Processed: CL\n",
      "Processed: CMS\n",
      "Processed: COP\n",
      "Processed: CPB\n",
      "Processed: CSX\n",
      "Processed: CVX\n",
      "Processed: DE\n",
      "Processed: CVS\n",
      "Processed: ED\n",
      "Processed: DTE\n",
      "Processed: ETN\n",
      "Processed: EIX\n",
      "Processed: EXC\n",
      "Processed: ETR\n",
      "Processed: F\n",
      "Processed: GD\n",
      "Processed: GIS\n",
      "Processed: HAL\n",
      "Processed: GE\n",
      "Processed: HIG\n",
      "Processed: HON\n",
      "Processed: HSY\n",
      "Processed: KMB\n",
      "Processed: IBM\n",
      "Processed: KO\n",
      "Processed: IP\n",
      "Processed: KR\n",
      "Processed: LMT\n",
      "Processed: MMM\n",
      "Processed: MO\n",
      "Processed: MRK\n",
      "Processed: MRO\n",
      "Processed: MSI\n",
      "Processed: NOC\n",
      "Processed: NSC\n",
      "Processed: PEG\n",
      "Processed: PEP\n",
      "Processed: OXY\n",
      "Processed: PG\n",
      "Processed: PFE\n",
      "Processed: PPG\n",
      "Processed: RTX\n",
      "Processed: SLB\n",
      "Processed: SO\n",
      "Processed: SPGI\n",
      "Processed: UNP\n",
      "Processed: XEL\n",
      "Processed: XOM\n",
      "Data saved to F:\\SP500_market_cap_ev_revenue_2023_2024.csv\n",
      "\n",
      "Data Summary:\n",
      "       latest_market_cap  latest_enterprise_value  annual_revenue_2023\n",
      "count       4.990000e+02             4.990000e+02         4.650000e+02\n",
      "mean        8.617117e+10             9.892482e+10         3.194856e+10\n",
      "std         2.337467e+11             2.397331e+11         5.983044e+10\n",
      "min         6.588500e+09            -4.530178e+10         7.508980e+08\n",
      "25%         1.754555e+10             2.181313e+10         6.531897e+09\n",
      "50%         3.397528e+10             4.095570e+10         1.335600e+10\n",
      "75%         7.092513e+10             8.358914e+10         2.811400e+10\n",
      "max         2.695570e+12             2.787960e+12         5.747850e+11\n",
      "\n",
      "Companies with missing data:\n",
      "CRWD (CrowdStrike)\n",
      "DECK (Deckers Brands)\n",
      "SW (Smurfit WestRock PLC)\n",
      "STE (Steris)\n",
      "LW (Lamb Weston)\n",
      "TTWO (Take-Two Interactive)\n",
      "QRVO (Qorvo)\n",
      "STX (Seagate Technology)\n",
      "KMX (CarMax)\n",
      "BRK.B (Berkshire Hathaway)\n",
      "ORLY (O'Reilly Auto Parts)\n",
      "SJM (J.M. Smucker Company (The))\n",
      "CRM (Salesforce)\n",
      "MCHP (Microchip Technology)\n",
      "RL (Ralph Lauren Corporation)\n",
      "JNPR (Juniper Networks)\n",
      "STZ (Constellation Brands)\n",
      "GEN (Gen Digital)\n",
      "EA (Electronic Arts)\n",
      "NVDA (Nvidia)\n",
      "CTAS (Cintas)\n",
      "BBY (Best Buy)\n",
      "NTAP (NetApp)\n",
      "MCK (McKesson Corporation)\n",
      "AES (AES Corporation)\n",
      "PAYX (Paychex)\n",
      "KLAC (KLA Corporation)\n",
      "DRI (Darden Restaurants)\n",
      "ORCL (Oracle Corporation)\n",
      "ADSK (Autodesk)\n",
      "NKE (Nike, Inc.)\n",
      "SYY (Sysco)\n",
      "MDT (Medtronic)\n",
      "TJX (TJX Companies)\n",
      "NUE (Nucor)\n",
      "CAG (Conagra Brands)\n",
      "BF.B (Brown–Forman)\n",
      "WMT (Walmart)\n",
      "FDX (FedEx)\n",
      "GIS (General Mills)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datetime import datetime\n",
    "\n",
    "# Your API Key\n",
    "API_KEY = 'D7KXZhPjt6caA9dwwAliN6CP3Oofacu5'\n",
    "\n",
    "def get_sp500_constituents():\n",
    "    url = f'https://financialmodelingprep.com/api/v3/sp500_constituent?apikey={API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return {company['symbol']: company['name'] for company in data}\n",
    "\n",
    "def get_company_data(symbol, name):\n",
    "    # Get latest market cap and enterprise value\n",
    "    url = f'https://financialmodelingprep.com/api/v3/enterprise-value/{symbol}?limit=1&apikey={API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    ev_data = response.json()\n",
    "    \n",
    "    # Get annual revenue for 2023\n",
    "    income_url = f'https://financialmodelingprep.com/api/v3/income-statement/{symbol}?limit=1&apikey={API_KEY}'\n",
    "    income_response = requests.get(income_url)\n",
    "    income_data = income_response.json()\n",
    "    \n",
    "    latest_data = ev_data[0] if ev_data else {}\n",
    "    revenue_2023 = income_data[0]['revenue'] if income_data and income_data[0]['calendarYear'] == '2023' else None\n",
    "    \n",
    "    return {\n",
    "        'symbol': symbol,\n",
    "        'name': name,\n",
    "        'latest_date': latest_data.get('date'),\n",
    "        'latest_market_cap': latest_data.get('marketCapitalization'),\n",
    "        'latest_enterprise_value': latest_data.get('enterpriseValue'),\n",
    "        'annual_revenue_2023': revenue_2023\n",
    "    }\n",
    "\n",
    "# Get S&P 500 constituents\n",
    "sp500_companies = get_sp500_constituents()\n",
    "print(f\"Total S&P 500 constituents: {len(sp500_companies)}\")\n",
    "\n",
    "# Fetch data for all companies using ThreadPoolExecutor\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    future_to_company = {executor.submit(get_company_data, symbol, name): symbol for symbol, name in sp500_companies.items()}\n",
    "    for future in as_completed(future_to_company):\n",
    "        symbol = future_to_company[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "            print(f\"Processed: {symbol}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {symbol}: {str(e)}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Reorder columns\n",
    "df = df[['symbol', 'name', 'latest_date', 'latest_market_cap', 'latest_enterprise_value', 'annual_revenue_2023']]\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = 'F:\\\\SP500_market_cap_ev_revenue_2023_2024.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"Data saved to {csv_path}\")\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nData Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Print companies with missing data\n",
    "missing_data = df[(df['latest_market_cap'].isnull()) | (df['latest_enterprise_value'].isnull()) | (df['annual_revenue_2023'].isnull())]\n",
    "if not missing_data.empty:\n",
    "    print(\"\\nCompanies with missing data:\")\n",
    "    for _, row in missing_data.iterrows():\n",
    "        print(f\"{row['symbol']} ({row['name']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: KMX\n",
      "Processed: DECK\n",
      "Processed: ORLY\n",
      "Processed: STX\n",
      "Processed: CRWD\n",
      "Processed: SW\n",
      "Processed: STE\n",
      "Processed: TTWO\n",
      "Processed: QRVO\n",
      "Processed: LW\n",
      "Processed: MCHP\n",
      "Processed: SJM\n",
      "Processed: CRM\n",
      "Processed: CTAS\n",
      "Processed: BBY\n",
      "Processed: GEN\n",
      "Processed: EA\n",
      "Processed: STZ\n",
      "Processed: RL\n",
      "Processed: NVDA\n",
      "Processed: NTAP\n",
      "Processed: AES\n",
      "Processed: MCK\n",
      "Processed: KLAC\n",
      "Processed: DRI\n",
      "Processed: NKE\n",
      "Processed: SYY\n",
      "Processed: ORCL\n",
      "Processed: ADSK\n",
      "Processed: PAYX\n",
      "Processed: MDT\n",
      "Processed: TJX\n",
      "Processed: NUE\n",
      "Processed: WMT\n",
      "Processed: BF.B\n",
      "Processed: GIS\n",
      "Processed: CAG\n",
      "Processed: FDX\n",
      "Data saved to F:\\specified_companies_annual_revenue_2023.csv\n",
      "\n",
      "Data Summary:\n",
      "       symbol fiscal_year annual_revenue report_date\n",
      "count      38           0              0           0\n",
      "unique     38           0              0           0\n",
      "top       KMX         NaN            NaN         NaN\n",
      "freq        1         NaN            NaN         NaN\n",
      "\n",
      "Companies with missing data:\n",
      "KMX\n",
      "DECK\n",
      "ORLY\n",
      "STX\n",
      "CRWD\n",
      "SW\n",
      "STE\n",
      "TTWO\n",
      "QRVO\n",
      "LW\n",
      "MCHP\n",
      "SJM\n",
      "CRM\n",
      "CTAS\n",
      "BBY\n",
      "GEN\n",
      "EA\n",
      "STZ\n",
      "RL\n",
      "NVDA\n",
      "NTAP\n",
      "AES\n",
      "MCK\n",
      "KLAC\n",
      "DRI\n",
      "NKE\n",
      "SYY\n",
      "ORCL\n",
      "ADSK\n",
      "PAYX\n",
      "MDT\n",
      "TJX\n",
      "NUE\n",
      "WMT\n",
      "BF.B\n",
      "GIS\n",
      "CAG\n",
      "FDX\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Your API Key\n",
    "API_KEY = 'D7KXZhPjt6caA9dwwAliN6CP3Oofacu5'\n",
    "\n",
    "# List of companies you specified\n",
    "companies = [\n",
    "    \"CRWD\", \"DECK\", \"SW\", \"STE\", \"LW\", \"TTWO\", \"QRVO\", \"STX\", \"KMX\", \"ORLY\", \n",
    "    \"SJM\", \"CRM\", \"MCHP\", \"RL\", \"STZ\", \"GEN\", \"EA\", \"NVDA\", \"CTAS\", \"BBY\", \n",
    "    \"NTAP\", \"MCK\", \"AES\", \"PAYX\", \"KLAC\", \"DRI\", \"ORCL\", \"ADSK\", \"NKE\", \"SYY\", \n",
    "    \"MDT\", \"TJX\", \"NUE\", \"CAG\", \"BF.B\", \"WMT\", \"FDX\", \"GIS\"\n",
    "]\n",
    "\n",
    "def get_annual_revenue(symbol):\n",
    "    url = f'https://financialmodelingprep.com/api/v3/income-statement/{symbol}?limit=1&apikey={API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    if data and data[0]['calendarYear'] == '2023':\n",
    "        return {\n",
    "            'symbol': symbol,\n",
    "            'fiscal_year': data[0]['calendarYear'],\n",
    "            'annual_revenue': data[0]['revenue'],\n",
    "            'report_date': data[0]['date']\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'symbol': symbol,\n",
    "            'fiscal_year': None,\n",
    "            'annual_revenue': None,\n",
    "            'report_date': None\n",
    "        }\n",
    "\n",
    "# Fetch data for all companies using ThreadPoolExecutor\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    future_to_company = {executor.submit(get_annual_revenue, symbol): symbol for symbol in companies}\n",
    "    for future in as_completed(future_to_company):\n",
    "        symbol = future_to_company[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "            print(f\"Processed: {symbol}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {symbol}: {str(e)}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = 'F:\\\\specified_companies_annual_revenue_2023.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"Data saved to {csv_path}\")\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nData Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Print companies with missing data\n",
    "missing_data = df[df['annual_revenue'].isnull()]\n",
    "if not missing_data.empty:\n",
    "    print(\"\\nCompanies with missing data:\")\n",
    "    for _, row in missing_data.iterrows():\n",
    "        print(f\"{row['symbol']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total S&P 500 constituents: 503\n",
      "Processed: SW\n",
      "Processed: BLDR\n",
      "Processed: GEV\n",
      "Processed: DECK\n",
      "Processed: KKR\n",
      "Processed: GDDY\n",
      "Processed: CRWD\n",
      "Processed: VST\n",
      "Processed: SOLV\n",
      "Processed: SMCI\n",
      "Processed: JBL\n",
      "Processed: HUBB\n",
      "Processed: VLTO\n",
      "Processed: LULU\n",
      "Processed: ABNB\n",
      "Processed: KVUE\n",
      "Processed: UBER\n",
      "Processed: PANW\n",
      "Processed: AXON\n",
      "Processed: BX\n",
      "Processed: FICO\n",
      "Processed: PODD\n",
      "Processed: FSLR\n",
      "Processed: BG\n",
      "Processed: ACGL\n",
      "Processed: STLD\n",
      "Processed: GEHC\n",
      "Processed: EQT\n",
      "Processed: TRGP\n",
      "Processed: PCG\n",
      "Processed: INVH\n",
      "Processed: KDP\n",
      "Processed: CSGP\n",
      "Processed: VICI\n",
      "Processed: ON\n",
      "Processed: MOH\n",
      "Processed: NDSN\n",
      "Processed: WBD\n",
      "Processed: CEG\n",
      "Processed: BRO\n",
      "Processed: CPT\n",
      "Processed: EPAM\n",
      "Processed: FDS\n",
      "Processed: MTCH\n",
      "Processed: TECH\n",
      "Processed: MRNA\n",
      "Processed: CRL\n",
      "Processed: PTC\n",
      "Processed: DAY\n",
      "Processed: GNRC\n",
      "Processed: TRMB\n",
      "Processed: MPWR\n",
      "Processed: NXPI\n",
      "Processed: ENPH\n",
      "Processed: TSLA\n",
      "Processed: CZR\n",
      "Processed: POOL\n",
      "Processed: CTLT\n",
      "Processed: ETSY\n",
      "Processed: TER\n",
      "Processed: BIO\n",
      "Processed: TDY\n",
      "Processed: TYL\n",
      "Processed: DPZ\n",
      "Processed: DXCM\n",
      "Processed: CARR\n",
      "Processed: WST\n",
      "Processed: OTIS\n",
      "Processed: IR\n",
      "Processed: PAYC\n",
      "Processed: LYV\n",
      "Processed: STE\n",
      "Processed: ZBRA\n",
      "Processed: ODFL\n",
      "Processed: WRB\n",
      "Processed: NVR\n",
      "Processed: CDW\n",
      "Processed: NOW\n",
      "Processed: LVS\n",
      "Processed: LDOS\n",
      "Processed: TROW\n",
      "Processed: IEX\n",
      "Processed: MKTX\n",
      "Processed: CTVA\n",
      "Processed: AMCR\n",
      "Processed: DD\n",
      "Processed: TMUS\n",
      "Processed: DOW\n",
      "Processed: FOX\n",
      "Processed: FOXA\n",
      "Processed: WAB\n",
      "Processed: ATO\n",
      "Processed: TFX\n",
      "Processed: FANG\n",
      "Processed: LW\n",
      "Processed: JKHY\n",
      "Processed: KEYS\n",
      "Processed: CE\n",
      "Processed: FTNT\n",
      "Processed: ROL\n",
      "Processed: ANET\n",
      "Processed: CPRT\n",
      "Processed: CPAY\n",
      "Processed: BR\n",
      "Processed: EVRG\n",
      "Processed: MSCI\n",
      "Processed: TTWO\n",
      "Processed: HII\n",
      "Processed: NCLH\n",
      "Processed: CDNS\n",
      "Processed: IQV\n",
      "Processed: AOS\n",
      "Processed: RMD\n",
      "Processed: SBAC\n",
      "Processed: MGM\n",
      "Processed: BKR\n",
      "Processed: ALGN\n",
      "Processed: PKG\n",
      "Processed: HLT\n",
      "Processed: EG\n",
      "Processed: IT\n",
      "Processed: AMD\n",
      "Processed: ARE\n",
      "Processed: ANSS\n",
      "Processed: RJF\n",
      "Processed: SRE\n",
      "Processed: REG\n",
      "Processed: SNPS\n",
      "Processed: MAA\n",
      "Processed: IDXX\n",
      "Processed: INCY\n",
      "Processed: CBOE\n",
      "Processed: COO\n",
      "Processed: MTD\n",
      "Processed: HWM\n",
      "Processed: ALB\n",
      "Processed: FTV\n",
      "Processed: D\n",
      "Processed: CHTR\n",
      "Processed: TDG\n",
      "Processed: LNT\n",
      "Processed: LKQ\n",
      "Processed: AJG\n",
      "Processed: DLR\n",
      "Processed: GPN\n",
      "Processed: ULTA\n",
      "Processed: CNC\n",
      "Processed: HOLX\n",
      "Processed: UDR\n",
      "Processed: FRT\n",
      "Processed: EXR\n",
      "Processed: CHD\n",
      "Processed: CFG\n",
      "Processed: WTW\n",
      "Processed: AWK\n",
      "Processed: HPE\n",
      "Processed: NWS\n",
      "Processed: SYF\n",
      "Processed: VRSK\n",
      "Processed: UAL\n",
      "Processed: KHC\n",
      "Processed: QRVO\n",
      "Processed: O\n",
      "Processed: EQIX\n",
      "Processed: HSIC\n",
      "Processed: AAL\n",
      "Processed: JBHT\n",
      "Processed: SWKS\n",
      "Processed: PYPL\n",
      "Processed: RCL\n",
      "Processed: HCA\n",
      "Processed: URI\n",
      "Processed: MLM\n",
      "Processed: UHS\n",
      "Processed: AVGO\n",
      "Processed: TSCO\n",
      "Processed: GOOGL\n",
      "Processed: META\n",
      "Processed: ALLE\n",
      "Processed: MHK\n",
      "Processed: ESS\n",
      "Processed: VRTX\n",
      "Processed: AME\n",
      "Processed: DAL\n",
      "Processed: REGN\n",
      "Processed: NWSA\n",
      "Processed: GM\n",
      "Processed: ZTS\n",
      "Processed: GRMN\n",
      "Processed: ABBV\n",
      "Processed: APTV\n",
      "Processed: MDLZ\n",
      "Processed: HUM\n",
      "Processed: DG\n",
      "Processed: LYB\n",
      "Processed: LRCX\n",
      "Processed: STX\n",
      "Processed: PNR\n",
      "Processed: MNST\n",
      "Processed: PSX\n",
      "Processed: KMI\n",
      "Processed: CCI\n",
      "Processed: BWA\n",
      "Processed: TEL\n",
      "Processed: MOS\n",
      "Processed: ACN\n",
      "Processed: XYL\n",
      "Processed: DLTR\n",
      "Processed: FCX\n",
      "Processed: MPC\n",
      "Processed: CMG\n",
      "Processed: BLK\n",
      "Processed: CB\n",
      "Processed: TT\n",
      "Processed: FFIV\n",
      "Processed: KMX\n",
      "Processed: OKE\n",
      "Processed: JCI\n",
      "Processed: EW\n",
      "Processed: NFLX\n",
      "Processed: BRK-B\n",
      "Processed: NRG\n",
      "Processed: V\n",
      "Processed: FMC\n",
      "Processed: BKNG\n",
      "Processed: ROP\n",
      "Processed: ROST\n",
      "Processed: PWR\n",
      "Processed: ORLY\n",
      "Processed: WDC\n",
      "Processed: HRL\n",
      "Processed: RSG\n",
      "Processed: ES\n",
      "Processed: IRM\n",
      "Processed: SJM\n",
      "Processed: WEC\n",
      "Processed: VTR\n",
      "Processed: WYNN\n",
      "Processed: WELL\n",
      "Processed: NDAQ\n",
      "Processed: LHX\n",
      "Processed: IVZ\n",
      "Processed: FAST\n",
      "Processed: CF\n",
      "Processed: CTRA\n",
      "Processed: MA\n",
      "Processed: CRM\n",
      "Processed: APH\n",
      "Processed: DVA\n",
      "Processed: AMT\n",
      "Processed: DOC\n",
      "Processed: ISRG\n",
      "Processed: PM\n",
      "Processed: J\n",
      "Processed: MCHP\n",
      "Processed: AKAM\n",
      "Processed: EXPD\n",
      "Processed: ICE\n",
      "Processed: EXPE\n",
      "Processed: CHRW\n",
      "Processed: DFS\n",
      "Processed: AIZ\n",
      "Processed: HST\n",
      "Processed: CBRE\n",
      "Processed: CTSH\n",
      "Processed: RL\n",
      "Processed: FIS\n",
      "Processed: AVB\n",
      "Processed: CME\n",
      "Processed: KIM\n",
      "Processed: BXP\n",
      "Processed: EL\n",
      "Processed: JNPR\n",
      "Processed: VRSN\n",
      "Processed: AMP\n",
      "Processed: GOOG\n",
      "Processed: AMZN\n",
      "Processed: PSA\n",
      "Processed: LEN\n",
      "Processed: STZ\n",
      "Processed: LH\n",
      "Processed: TPR\n",
      "Processed: DHI\n",
      "Processed: TMO\n",
      "Processed: TSN\n",
      "Processed: GILD\n",
      "Processed: VTRS\n",
      "Processed: MTB\n",
      "Processed: PLD\n",
      "Processed: BIIB\n",
      "Processed: VLO\n",
      "Processed: STT\n",
      "Processed: GEN\n",
      "Processed: MKC\n",
      "Processed: ELV\n",
      "Processed: DGX\n",
      "Processed: CMCSA\n",
      "Processed: TRV\n",
      "Processed: EA\n",
      "Processed: PFG\n",
      "Processed: SPG\n",
      "Processed: PRU\n",
      "Processed: EQR\n",
      "Processed: UPS\n",
      "Processed: NVDA\n",
      "Processed: WAT\n",
      "Processed: EBAY\n",
      "Processed: GS\n",
      "Processed: PPL\n",
      "Processed: COR\n",
      "Processed: FI\n",
      "Processed: ZBH\n",
      "Processed: SYK\n",
      "Processed: MET\n",
      "Processed: TXN\n",
      "Processed: CTAS\n",
      "Processed: INTU\n",
      "Processed: EOG\n",
      "Processed: DVN\n",
      "Processed: NI\n",
      "Processed: ROK\n",
      "Processed: A\n",
      "Processed: QCOM\n",
      "Processed: SBUX\n",
      "Processed: VMC\n",
      "Processed: PNW\n",
      "Processed: BBY\n",
      "Processed: ADI\n",
      "Processed: NTAP\n",
      "Processed: AFL\n",
      "Processed: USB\n",
      "Processed: MCK\n",
      "Processed: PAYX\n",
      "Processed: DHR\n",
      "Processed: MAR\n",
      "Processed: COF\n",
      "Processed: RF\n",
      "Processed: CCL\n",
      "Processed: BEN\n",
      "Processed: AES\n",
      "Processed: MCO\n",
      "Processed: NTRS\n",
      "Processed: CINF\n",
      "Processed: WM\n",
      "Processed: FE\n",
      "Processed: HBAN\n",
      "Processed: KLAC\n",
      "Processed: TFC\n",
      "Processed: YUM\n",
      "Processed: APA\n",
      "Processed: OMC\n",
      "Processed: PGR\n",
      "Processed: EFX\n",
      "Processed: SCHW\n",
      "Processed: ADBE\n",
      "Processed: AZO\n",
      "Processed: AON\n",
      "Processed: CAH\n",
      "Processed: FITB\n",
      "Processed: DRI\n",
      "Processed: L\n",
      "Processed: ALL\n",
      "Processed: BK\n",
      "Processed: GLW\n",
      "Processed: PARA\n",
      "Processed: LUV\n",
      "Processed: MU\n",
      "Processed: AMAT\n",
      "Processed: MSFT\n",
      "Processed: UNH\n",
      "Processed: KEY\n",
      "Processed: EMN\n",
      "Processed: CSCO\n",
      "Processed: BSX\n",
      "Processed: MS\n",
      "Processed: IPG\n",
      "Processed: LIN\n",
      "Processed: AMGN\n",
      "Processed: ADSK\n",
      "Processed: COST\n",
      "Processed: K\n",
      "Processed: ORCL\n",
      "Processed: ECL\n",
      "Processed: NKE\n",
      "Processed: AEE\n",
      "Processed: C\n",
      "Processed: GL\n",
      "Processed: AVY\n",
      "Processed: HD\n",
      "Processed: PNC\n",
      "Processed: MMC\n",
      "Processed: PH\n",
      "Processed: SYY\n",
      "Processed: ITW\n",
      "Processed: DOV\n",
      "Processed: MDT\n",
      "Processed: TJX\n",
      "Processed: RVTY\n",
      "Processed: CNP\n",
      "Processed: APD\n",
      "Processed: BALL\n",
      "Processed: HES\n",
      "Processed: HAS\n",
      "Processed: NUE\n",
      "Processed: LOW\n",
      "Processed: BBWI\n",
      "Processed: T\n",
      "Processed: CAG\n",
      "Processed: PHM\n",
      "Processed: VZ\n",
      "Processed: WMT\n",
      "Processed: BF-B\n",
      "Processed: GWW\n",
      "Processed: AAPL\n",
      "Processed: MAS\n",
      "Processed: SWK\n",
      "Processed: SNA\n",
      "Processed: FDX\n",
      "Processed: PCAR\n",
      "Processed: ADP\n",
      "Processed: AIG\n",
      "Processed: WY\n",
      "Processed: WBA\n",
      "Processed: INTC\n",
      "Processed: TXT\n",
      "Processed: TGT\n",
      "Processed: BAC\n",
      "Processed: AXP\n",
      "Processed: CI\n",
      "Processed: NEE\n",
      "Processed: TAP\n",
      "Processed: DUK\n",
      "Processed: DIS\n",
      "Processed: IFF\n",
      "Processed: GPC\n",
      "Processed: WMB\n",
      "Processed: WFC\n",
      "Processed: JNJ\n",
      "Processed: BAX\n",
      "Processed: BDX\n",
      "Processed: HPQ\n",
      "Processed: JPM\n",
      "Processed: NEM\n",
      "Processed: MCD\n",
      "Processed: SHW\n",
      "Processed: CMI\n",
      "Processed: LLY\n",
      "Processed: ABT\n",
      "Processed: ADM\n",
      "Processed: EMR\n",
      "Processed: CLX\n",
      "Processed: AEP\n",
      "Processed: CL\n",
      "Processed: BMY\n",
      "Processed: CAT\n",
      "Processed: COP\n",
      "Processed: BA\n",
      "Processed: CSX\n",
      "Processed: CMS\n",
      "Processed: DTE\n",
      "Processed: ED\n",
      "Processed: CPB\n",
      "Processed: DE\n",
      "Processed: CVX\n",
      "Processed: CVS\n",
      "Processed: ETN\n",
      "Processed: EIX\n",
      "Processed: GD\n",
      "Processed: EXC\n",
      "Processed: ETR\n",
      "Processed: GE\n",
      "Processed: HAL\n",
      "Processed: F\n",
      "Processed: HIG\n",
      "Processed: GIS\n",
      "Processed: KO\n",
      "Processed: HON\n",
      "Processed: KMB\n",
      "Processed: HSY\n",
      "Processed: IBM\n",
      "Processed: IP\n",
      "Processed: LMT\n",
      "Processed: MSI\n",
      "Processed: MMM\n",
      "Processed: NSC\n",
      "Processed: MO\n",
      "Processed: MRK\n",
      "Processed: OXY\n",
      "Processed: NOC\n",
      "Processed: KR\n",
      "Processed: MRO\n",
      "Processed: PEG\n",
      "Processed: PPG\n",
      "Processed: SPGI\n",
      "Processed: PG\n",
      "Processed: SO\n",
      "Processed: PEP\n",
      "Processed: PFE\n",
      "Processed: SLB\n",
      "Processed: UNP\n",
      "Processed: XOM\n",
      "Processed: XEL\n",
      "Processed: RTX\n",
      "Data saved to F:\\SP500_estimated_revenue_2025_market_cap_ev.csv\n",
      "\n",
      "Data Summary:\n",
      "       estimated_revenue_2025  latest_market_cap  latest_enterprise_value\n",
      "count            3.690000e+02       5.020000e+02             5.020000e+02\n",
      "mean             3.349611e+10       8.904549e+10             1.018002e+11\n",
      "std              6.767058e+10       2.553127e+11             2.606025e+11\n",
      "min              5.806820e+08       6.588500e+09            -4.530178e+10\n",
      "25%              6.843897e+09       1.753279e+10             2.180716e+10\n",
      "50%              1.417052e+10       3.396117e+10             4.093476e+10\n",
      "75%              2.794668e+10       7.092608e+10             8.363761e+10\n",
      "max              7.100818e+11       3.393961e+12             3.393961e+12\n",
      "\n",
      "Companies with missing data:\n",
      "SW (Smurfit WestRock PLC)\n",
      "DECK (Deckers Brands)\n",
      "CRWD (CrowdStrike)\n",
      "SMCI (Supermicro)\n",
      "JBL (Jabil)\n",
      "LULU (Lululemon Athletica)\n",
      "PANW (Palo Alto Networks)\n",
      "FICO (Fair Isaac)\n",
      "NDSN (Nordson Corporation)\n",
      "FDS (FactSet)\n",
      "TECH (Bio-Techne)\n",
      "CRL (Charles River Laboratories)\n",
      "PTC (PTC)\n",
      "TRMB (Trimble Inc.)\n",
      "CTLT (Catalent)\n",
      "STE (Steris)\n",
      "LDOS (Leidos)\n",
      "AMCR (Amcor)\n",
      "FOX (Fox Corporation (Class B))\n",
      "FOXA (Fox Corporation (Class A))\n",
      "ATO (Atmos Energy)\n",
      "LW (Lamb Weston)\n",
      "JKHY (Jack Henry & Associates)\n",
      "KEYS (Keysight)\n",
      "CPRT (Copart)\n",
      "BR (Broadridge Financial Solutions)\n",
      "TTWO (Take-Two Interactive)\n",
      "RMD (ResMed)\n",
      "AMD (Advanced Micro Devices)\n",
      "RJF (Raymond James)\n",
      "SNPS (Synopsys)\n",
      "COO (CooperCompanies)\n",
      "TDG (TransDigm Group)\n",
      "ULTA (Ulta Beauty)\n",
      "HOLX (Hologic)\n",
      "HPE (Hewlett Packard Enterprise)\n",
      "NWS (News Corp (Class B))\n",
      "KHC (Kraft Heinz)\n",
      "QRVO (Qorvo)\n",
      "HSIC (Henry Schein)\n",
      "SWKS (Skyworks Solutions)\n",
      "AVGO (Broadcom Inc.)\n",
      "TSCO (Tractor Supply)\n",
      "NWSA (News Corp (Class A))\n",
      "GRMN (Garmin)\n",
      "DG (Dollar General)\n",
      "LRCX (Lam Research)\n",
      "STX (Seagate Technology)\n",
      "TEL (TE Connectivity)\n",
      "ACN (Accenture)\n",
      "DLTR (Dollar Tree)\n",
      "FFIV (F5, Inc.)\n",
      "KMX (CarMax)\n",
      "JCI (Johnson Controls)\n",
      "V (Visa Inc.)\n",
      "ROST (Ross Stores)\n",
      "ORLY (O'Reilly Auto Parts)\n",
      "WDC (Western Digital)\n",
      "HRL (Hormel Foods)\n",
      "SJM (J.M. Smucker Company (The))\n",
      "LHX (L3Harris)\n",
      "CRM (Salesforce)\n",
      "J (Jacobs Solutions)\n",
      "MCHP (Microchip Technology)\n",
      "RL (Ralph Lauren Corporation)\n",
      "EL (Estée Lauder Companies (The))\n",
      "LEN (Lennar)\n",
      "STZ (Constellation Brands)\n",
      "TPR (Tapestry, Inc.)\n",
      "DHI (DR Horton)\n",
      "TSN (Tyson Foods)\n",
      "GEN (Gen Digital)\n",
      "MKC (McCormick & Company)\n",
      "EA (Electronic Arts)\n",
      "NVDA (Nvidia)\n",
      "COR (Cencora)\n",
      "CTAS (Cintas)\n",
      "INTU (Intuit)\n",
      "ROK (Rockwell Automation)\n",
      "A (Agilent Technologies)\n",
      "QCOM (Qualcomm)\n",
      "SBUX (Starbucks)\n",
      "BBY (Best Buy)\n",
      "ADI (Analog Devices)\n",
      "NTAP (NetApp)\n",
      "MCK (McKesson Corporation)\n",
      "CCL (Carnival)\n",
      "BEN (Franklin Templeton)\n",
      "KLAC (KLA Corporation)\n",
      "ADBE (Adobe Inc.)\n",
      "AZO (AutoZone)\n",
      "CAH (Cardinal Health)\n",
      "DRI (Darden Restaurants)\n",
      "MU (Micron Technology)\n",
      "AMAT (Applied Materials)\n",
      "MSFT (Microsoft)\n",
      "CSCO (Cisco)\n",
      "ADSK (Autodesk)\n",
      "COST (Costco)\n",
      "K (Kellanova)\n",
      "ORCL (Oracle Corporation)\n",
      "NKE (Nike, Inc.)\n",
      "AVY (Avery Dennison)\n",
      "HD (Home Depot (The))\n",
      "PH (Parker Hannifin)\n",
      "SYY (Sysco)\n",
      "MDT (Medtronic)\n",
      "TJX (TJX Companies)\n",
      "APD (Air Products and Chemicals)\n",
      "LOW (Lowe's)\n",
      "BBWI (Bath & Body Works, Inc.)\n",
      "CAG (Conagra Brands)\n",
      "WMT (Walmart)\n",
      "BF-B (Brown–Forman)\n",
      "AAPL (Apple Inc.)\n",
      "SWK (Stanley Black & Decker)\n",
      "SNA (Snap-on)\n",
      "FDX (FedEx)\n",
      "ADP (Automatic Data Processing)\n",
      "WBA (Walgreens Boots Alliance)\n",
      "INTC (Intel)\n",
      "TXT (Textron)\n",
      "TGT (Target Corporation)\n",
      "DIS (Walt Disney Company (The))\n",
      "BDX (Becton Dickinson)\n",
      "HPQ (HP Inc.)\n",
      "EMR (Emerson Electric)\n",
      "CLX (Clorox)\n",
      "CPB (Campbell Soup Company)\n",
      "DE (John Deere)\n",
      "GIS (General Mills)\n",
      "KR (Kroger)\n",
      "PG (Procter & Gamble)\n",
      "PEP (PepsiCo)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Your API Key\n",
    "API_KEY = 'D7KXZhPjt6caA9dwwAliN6CP3Oofacu5'\n",
    "\n",
    "def get_sp500_constituents():\n",
    "    url = f'https://financialmodelingprep.com/api/v3/sp500_constituent?apikey={API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return {company['symbol']: company['name'] for company in data}\n",
    "\n",
    "def get_company_data(symbol, name):\n",
    "    # Get analyst estimates\n",
    "    estimates_url = f'https://financialmodelingprep.com/api/v3/analyst-estimates/{symbol}?apikey={API_KEY}'\n",
    "    estimates_response = requests.get(estimates_url)\n",
    "    estimates_data = estimates_response.json()\n",
    "    \n",
    "    # Get latest market cap and enterprise value\n",
    "    ev_url = f'https://financialmodelingprep.com/api/v3/enterprise-value/{symbol}?limit=1&apikey={API_KEY}'\n",
    "    ev_response = requests.get(ev_url)\n",
    "    ev_data = ev_response.json()\n",
    "    \n",
    "    estimated_revenue_2025 = None\n",
    "    for estimate in estimates_data:\n",
    "        if estimate['date'] == '2025-12-31':\n",
    "            estimated_revenue_2025 = estimate.get('estimatedRevenueAvg')\n",
    "            break\n",
    "    \n",
    "    latest_data = ev_data[0] if ev_data else {}\n",
    "    \n",
    "    return {\n",
    "        'symbol': symbol,\n",
    "        'name': name,\n",
    "        'estimated_revenue_2025': estimated_revenue_2025,\n",
    "        'latest_date': latest_data.get('date'),\n",
    "        'latest_market_cap': latest_data.get('marketCapitalization'),\n",
    "        'latest_enterprise_value': latest_data.get('enterpriseValue')\n",
    "    }\n",
    "\n",
    "# Get S&P 500 constituents\n",
    "sp500_companies = get_sp500_constituents()\n",
    "print(f\"Total S&P 500 constituents: {len(sp500_companies)}\")\n",
    "\n",
    "# Fetch data for all companies using ThreadPoolExecutor\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    future_to_company = {executor.submit(get_company_data, symbol, name): symbol for symbol, name in sp500_companies.items()}\n",
    "    for future in as_completed(future_to_company):\n",
    "        symbol = future_to_company[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "            print(f\"Processed: {symbol}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {symbol}: {str(e)}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Reorder columns\n",
    "df = df[['symbol', 'name', 'estimated_revenue_2025', 'latest_date', 'latest_market_cap', 'latest_enterprise_value']]\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = 'F:\\\\SP500_estimated_revenue_2025_market_cap_ev.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"Data saved to {csv_path}\")\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nData Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Print companies with missing data\n",
    "missing_data = df[(df['estimated_revenue_2025'].isnull()) | (df['latest_market_cap'].isnull()) | (df['latest_enterprise_value'].isnull())]\n",
    "if not missing_data.empty:\n",
    "    print(\"\\nCompanies with missing data:\")\n",
    "    for _, row in missing_data.iterrows():\n",
    "        print(f\"{row['symbol']} ({row['name']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: DECK\n",
      "Processed: FDS\n",
      "Processed: SW\n",
      "Processed: SMCI\n",
      "Processed: JBL\n",
      "Processed: LULU\n",
      "Processed: FICO\n",
      "Processed: NDSN\n",
      "Processed: PANW\n",
      "Processed: CRWD\n",
      "Processed: TECH\n",
      "Processed: CRL\n",
      "Processed: PTC\n",
      "Processed: CTLT\n",
      "Processed: LDOS\n",
      "Processed: FOX\n",
      "Processed: TRMB\n",
      "Processed: AMCR\n",
      "Processed: STE\n",
      "Processed: FOXA\n",
      "Processed: ATO\n",
      "Processed: LW\n",
      "Processed: JKHY\n",
      "Processed: KEYS\n",
      "Processed: BR\n",
      "Processed: TTWO\n",
      "Processed: AMD\n",
      "Processed: RMD\n",
      "Processed: RJF\n",
      "Processed: CPRT\n",
      "Processed: SNPS\n",
      "Processed: COO\n",
      "Processed: TDG\n",
      "Processed: ULTA\n",
      "Processed: KHC\n",
      "Processed: HPE\n",
      "Processed: HOLX\n",
      "Processed: NWS\n",
      "Processed: HSIC\n",
      "Processed: QRVO\n",
      "Processed: SWKS\n",
      "Processed: AVGO\n",
      "Processed: TSCO\n",
      "Processed: NWSA\n",
      "Processed: GRMN\n",
      "Processed: STX\n",
      "Processed: DG\n",
      "Processed: LRCX\n",
      "Processed: ACN\n",
      "Processed: TEL\n",
      "Processed: DLTR\n",
      "Processed: FFIV\n",
      "Processed: KMX\n",
      "Processed: V\n",
      "Processed: JCI\n",
      "Processed: LHX\n",
      "Processed: CRM\n",
      "Processed: ROST\n",
      "Processed: J\n",
      "Processed: WDC\n",
      "Processed: ORLY\n",
      "Processed: HRL\n",
      "Processed: SJM\n",
      "Processed: MCHP\n",
      "Processed: RL\n",
      "Processed: EL\n",
      "Processed: LEN\n",
      "Processed: TPR\n",
      "Processed: STZ\n",
      "Processed: TSN\n",
      "Processed: DHI\n",
      "Processed: GEN\n",
      "Processed: MKC\n",
      "Processed: EA\n",
      "Processed: COR\n",
      "Processed: NVDA\n",
      "Processed: CTAS\n",
      "Processed: INTU\n",
      "Processed: ROK\n",
      "Processed: A\n",
      "Processed: QCOM\n",
      "Processed: ADI\n",
      "Processed: BBY\n",
      "Processed: SBUX\n",
      "Processed: NTAP\n",
      "Processed: CCL\n",
      "Processed: BEN\n",
      "Processed: MCK\n",
      "Processed: KLAC\n",
      "Processed: CAH\n",
      "Processed: ADBE\n",
      "Processed: AZO\n",
      "Processed: MU\n",
      "Processed: AMAT\n",
      "Processed: DRI\n",
      "Processed: MSFT\n",
      "Processed: CSCO\n",
      "Processed: ADSK\n",
      "Processed: COST\n",
      "Processed: K\n",
      "Processed: HD\n",
      "Processed: ORCL\n",
      "Processed: SYY\n",
      "Processed: NKE\n",
      "Processed: MDT\n",
      "Processed: AVY\n",
      "Processed: PH\n",
      "Processed: LOW\n",
      "Processed: APD\n",
      "Processed: TJX\n",
      "Processed: BBWI\n",
      "Processed: WMT\n",
      "Processed: AAPL\n",
      "Processed: CAG\n",
      "Processed: BF.B\n",
      "Processed: SWK\n",
      "Processed: SNA\n",
      "Processed: FDX\n",
      "Processed: INTC\n",
      "Processed: WBA\n",
      "Processed: ADP\n",
      "Processed: TXT\n",
      "Processed: TGT\n",
      "Processed: DIS\n",
      "Processed: BDX\n",
      "Processed: CLX\n",
      "Processed: HPQ\n",
      "Processed: EMR\n",
      "Processed: CPB\n",
      "Processed: PG\n",
      "Processed: DE\n",
      "Processed: GIS\n",
      "Processed: KR\n",
      "Processed: PEP\n",
      "Data saved to F:\\specified_companies_estimated_revenue_market_cap_ev.csv\n",
      "\n",
      "Data Summary:\n",
      "       estimated_revenue  latest_market_cap  latest_enterprise_value\n",
      "count       1.320000e+02       1.320000e+02             1.320000e+02\n",
      "mean        4.328460e+10       1.244170e+11             1.326248e+11\n",
      "std         8.572596e+10       3.986735e+11             4.037737e+11\n",
      "min         1.246033e+09       7.848160e+09             9.096138e+09\n",
      "25%         6.813010e+09       1.643686e+10             2.036248e+10\n",
      "50%         1.560913e+10       3.125750e+10             3.545434e+10\n",
      "75%         3.744076e+10       7.445633e+10             8.393003e+10\n",
      "max         6.725037e+11       3.393961e+12             3.393961e+12\n",
      "\n",
      "Companies with missing data:\n",
      "SW\n",
      "BF.B\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datetime import datetime\n",
    "\n",
    "# Your API Key\n",
    "API_KEY = 'D7KXZhPjt6caA9dwwAliN6CP3Oofacu5'\n",
    "\n",
    "# List of companies you specified\n",
    "companies = [\n",
    "    \"SW\", \"DECK\", \"CRWD\", \"SMCI\", \"JBL\", \"LULU\", \"PANW\", \"FICO\", \"NDSN\", \"FDS\", \"TECH\", \"CRL\", \"PTC\", \"TRMB\", \"CTLT\", \n",
    "    \"STE\", \"LDOS\", \"AMCR\", \"FOX\", \"FOXA\", \"ATO\", \"LW\", \"JKHY\", \"KEYS\", \"CPRT\", \"BR\", \"TTWO\", \"RMD\", \"AMD\", \"RJF\", \n",
    "    \"SNPS\", \"COO\", \"TDG\", \"ULTA\", \"HOLX\", \"HPE\", \"NWS\", \"KHC\", \"QRVO\", \"HSIC\", \"SWKS\", \"AVGO\", \"TSCO\", \"NWSA\", \n",
    "    \"GRMN\", \"DG\", \"LRCX\", \"STX\", \"TEL\", \"ACN\", \"DLTR\", \"FFIV\", \"KMX\", \"JCI\", \"V\", \"ROST\", \"ORLY\", \"WDC\", \"HRL\", \n",
    "    \"SJM\", \"LHX\", \"CRM\", \"J\", \"MCHP\", \"RL\", \"EL\", \"LEN\", \"STZ\", \"TPR\", \"DHI\", \"TSN\", \"GEN\", \"MKC\", \"EA\", \"NVDA\", \n",
    "    \"COR\", \"CTAS\", \"INTU\", \"ROK\", \"A\", \"QCOM\", \"SBUX\", \"BBY\", \"ADI\", \"NTAP\", \"MCK\", \"CCL\", \"BEN\", \"KLAC\", \"ADBE\", \n",
    "    \"AZO\", \"CAH\", \"DRI\", \"MU\", \"AMAT\", \"MSFT\", \"CSCO\", \"ADSK\", \"COST\", \"K\", \"ORCL\", \"NKE\", \"AVY\", \"HD\", \"PH\", \"SYY\", \n",
    "    \"MDT\", \"TJX\", \"APD\", \"LOW\", \"BBWI\", \"CAG\", \"WMT\", \"BF.B\", \"AAPL\", \"SWK\", \"SNA\", \"FDX\", \"ADP\", \"WBA\", \"INTC\", \n",
    "    \"TXT\", \"TGT\", \"DIS\", \"BDX\", \"HPQ\", \"EMR\", \"CLX\", \"CPB\", \"DE\", \"GIS\", \"KR\", \"PG\", \"PEP\"\n",
    "]\n",
    "\n",
    "def get_company_data(symbol):\n",
    "    # Get analyst estimates\n",
    "    estimates_url = f'https://financialmodelingprep.com/api/v3/analyst-estimates/{symbol}?apikey={API_KEY}'\n",
    "    estimates_response = requests.get(estimates_url)\n",
    "    estimates_data = estimates_response.json()\n",
    "    \n",
    "    # Get latest market cap and enterprise value\n",
    "    ev_url = f'https://financialmodelingprep.com/api/v3/enterprise-value/{symbol}?limit=1&apikey={API_KEY}'\n",
    "    ev_response = requests.get(ev_url)\n",
    "    ev_data = ev_response.json()\n",
    "    \n",
    "    current_date = datetime.now()\n",
    "    future_estimates = [estimate for estimate in estimates_data if datetime.strptime(estimate['date'], '%Y-%m-%d') > current_date]\n",
    "    future_estimates.sort(key=lambda x: datetime.strptime(x['date'], '%Y-%m-%d'))\n",
    "    \n",
    "    estimated_revenue = None\n",
    "    estimate_date = None\n",
    "    if future_estimates:\n",
    "        estimated_revenue = future_estimates[0].get('estimatedRevenueAvg')\n",
    "        estimate_date = future_estimates[0].get('date')\n",
    "    \n",
    "    latest_data = ev_data[0] if ev_data else {}\n",
    "    \n",
    "    return {\n",
    "        'symbol': symbol,\n",
    "        'estimated_revenue': estimated_revenue,\n",
    "        'estimate_date': estimate_date,\n",
    "        'latest_date': latest_data.get('date'),\n",
    "        'latest_market_cap': latest_data.get('marketCapitalization'),\n",
    "        'latest_enterprise_value': latest_data.get('enterpriseValue')\n",
    "    }\n",
    "\n",
    "# Fetch data for all companies using ThreadPoolExecutor\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    future_to_company = {executor.submit(get_company_data, symbol): symbol for symbol in companies}\n",
    "    for future in as_completed(future_to_company):\n",
    "        symbol = future_to_company[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "            print(f\"Processed: {symbol}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {symbol}: {str(e)}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Reorder columns\n",
    "df = df[['symbol', 'estimated_revenue', 'estimate_date', 'latest_date', 'latest_market_cap', 'latest_enterprise_value']]\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = 'F:\\\\specified_companies_estimated_revenue_market_cap_ev.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"Data saved to {csv_path}\")\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nData Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Print companies with missing data\n",
    "missing_data = df[(df['estimated_revenue'].isnull()) | (df['latest_market_cap'].isnull()) | (df['latest_enterprise_value'].isnull())]\n",
    "if not missing_data.empty:\n",
    "    print(\"\\nCompanies with missing data:\")\n",
    "    for _, row in missing_data.iterrows():\n",
    "        print(f\"{row['symbol']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to F:\\merged_company_data.csv\n",
      "\n",
      "Merge Summary:\n",
      "Number of rows in file 1: 518\n",
      "Number of rows in file 2: 134\n",
      "Number of rows in merged file: 518\n",
      "Number of unique symbols in merged file: 503\n",
      "\n",
      "Symbols only in file 1: 370\n",
      "Symbols only in file 2: 0\n",
      "\n",
      "Some examples of symbols only in file 1: ['HLT', 'PSA', 'GM', 'CTRA', 'AMZN']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "file1_path = 'F:\\\\SP500_market_cap_ev_revenue_2023_2024.csv'\n",
    "file2_path = 'F:\\\\specified_companies_estimated_revenue_market_cap_ev.csv'\n",
    "output_path = 'F:\\\\merged_company_data.csv'\n",
    "\n",
    "# Read the CSV files\n",
    "df1 = pd.read_csv(file1_path)\n",
    "df2 = pd.read_csv(file2_path)\n",
    "\n",
    "# Merge the dataframes on the 'symbol' column\n",
    "merged_df = pd.merge(df1, df2, on='symbol', how='outer', suffixes=('_file1', '_file2'))\n",
    "\n",
    "# Identify columns that are duplicated (except 'symbol')\n",
    "duplicate_columns = [col for col in merged_df.columns if col.endswith('_file2') and col != 'symbol']\n",
    "\n",
    "# For each duplicate column, keep the non-null value\n",
    "for col in duplicate_columns:\n",
    "    base_col = col[:-6]  # Remove '_file2' suffix\n",
    "    merged_df[base_col] = merged_df[base_col + '_file1'].combine_first(merged_df[col])\n",
    "    merged_df.drop([base_col + '_file1', col], axis=1, inplace=True)\n",
    "\n",
    "# Sort the dataframe by symbol\n",
    "merged_df.sort_values('symbol', inplace=True)\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Merged data saved to {output_path}\")\n",
    "\n",
    "# Print summary of the merge\n",
    "print(\"\\nMerge Summary:\")\n",
    "print(f\"Number of rows in file 1: {len(df1)}\")\n",
    "print(f\"Number of rows in file 2: {len(df2)}\")\n",
    "print(f\"Number of rows in merged file: {len(merged_df)}\")\n",
    "print(f\"Number of unique symbols in merged file: {merged_df['symbol'].nunique()}\")\n",
    "\n",
    "# Check for any symbols that are in one file but not the other\n",
    "symbols_file1 = set(df1['symbol'])\n",
    "symbols_file2 = set(df2['symbol'])\n",
    "symbols_only_in_file1 = symbols_file1 - symbols_file2\n",
    "symbols_only_in_file2 = symbols_file2 - symbols_file1\n",
    "\n",
    "print(f\"\\nSymbols only in file 1: {len(symbols_only_in_file1)}\")\n",
    "print(f\"Symbols only in file 2: {len(symbols_only_in_file2)}\")\n",
    "\n",
    "if symbols_only_in_file1:\n",
    "    print(\"\\nSome examples of symbols only in file 1:\", list(symbols_only_in_file1)[:5])\n",
    "if symbols_only_in_file2:\n",
    "    print(\"\\nSome examples of symbols only in file 2:\", list(symbols_only_in_file2)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data returned for date 2024-01-04. Status code: 200\n",
      "No data returned for date 2024-01-06. Status code: 200\n",
      "No data returned for date 2024-01-08. Status code: 200\n",
      "No data returned for date 2024-01-01. Status code: 200\n",
      "No data returned for date 2024-01-09. Status code: 200\n",
      "No data returned for date 2024-01-10. Status code: 200\n",
      "No data returned for date 2024-01-02. Status code: 200\n",
      "No data returned for date 2024-01-07. Status code: 200\n",
      "No data returned for date 2024-01-03. Status code: 200\n",
      "No data returned for date 2024-01-05. Status code: 200\n",
      "No data returned for date 2024-01-13. Status code: 200\n",
      "No data returned for date 2024-01-12. Status code: 200\n",
      "No data returned for date 2024-01-15. Status code: 200\n",
      "No data returned for date 2024-01-17. Status code: 200\n",
      "No data returned for date 2024-01-19. Status code: 200\n",
      "No data returned for date 2024-01-11. Status code: 200\n",
      "No data returned for date 2024-01-14. Status code: 200\n",
      "No data returned for date 2024-01-18. Status code: 200\n",
      "No data returned for date 2024-01-20. Status code: 200\n",
      "No data returned for date 2024-01-16. Status code: 200\n",
      "No data returned for date 2024-01-22. Status code: 200\n",
      "No data returned for date 2024-01-24. Status code: 200\n",
      "No data returned for date 2024-01-21. Status code: 200\n",
      "No data returned for date 2024-01-23. Status code: 200\n",
      "No data returned for date 2024-01-27. Status code: 200\n",
      "No data returned for date 2024-01-28. Status code: 200\n",
      "No data returned for date 2024-01-25. Status code: 200\n",
      "No data returned for date 2024-01-29. Status code: 200\n",
      "No data returned for date 2024-01-26. Status code: 200\n",
      "No data returned for date 2024-01-30. Status code: 200\n",
      "No data returned for date 2024-02-01. Status code: 200\n",
      "No data returned for date 2024-01-31. Status code: 200\n",
      "No data returned for date 2024-02-02. Status code: 200\n",
      "No data returned for date 2024-02-03. Status code: 200\n",
      "No data returned for date 2024-02-06. Status code: 200\n",
      "No data returned for date 2024-02-08. Status code: 200\n",
      "No data returned for date 2024-02-07. Status code: 200\n",
      "No data returned for date 2024-02-04. Status code: 200\n",
      "No data returned for date 2024-02-05. Status code: 200\n",
      "No data returned for date 2024-02-09. Status code: 200\n",
      "No data returned for date 2024-02-10. Status code: 200\n",
      "No data returned for date 2024-02-11. Status code: 200\n",
      "No data returned for date 2024-02-12. Status code: 200\n",
      "No data returned for date 2024-02-13. Status code: 200\n",
      "No data returned for date 2024-02-14. Status code: 200\n",
      "No data returned for date 2024-02-17. Status code: 200\n",
      "No data returned for date 2024-02-16. Status code: 200\n",
      "No data returned for date 2024-02-15. Status code: 200\n",
      "No data returned for date 2024-02-19. Status code: 200\n",
      "No data returned for date 2024-02-18. Status code: 200\n",
      "No data returned for date 2024-02-20. Status code: 200\n",
      "No data returned for date 2024-02-21. Status code: 200\n",
      "No data returned for date 2024-02-22. Status code: 200\n",
      "No data returned for date 2024-02-24. Status code: 200\n",
      "No data returned for date 2024-02-25. Status code: 200\n",
      "No data returned for date 2024-02-26. Status code: 200\n",
      "No data returned for date 2024-02-29. Status code: 200\n",
      "No data returned for date 2024-02-27. Status code: 200\n",
      "No data returned for date 2024-02-28. Status code: 200\n",
      "No data returned for date 2024-02-23. Status code: 200\n",
      "No data returned for date 2024-03-01. Status code: 200\n",
      "No data returned for date 2024-03-02. Status code: 200\n",
      "No data returned for date 2024-03-03. Status code: 200\n",
      "No data returned for date 2024-03-04. Status code: 200\n",
      "No data returned for date 2024-03-05. Status code: 200\n",
      "No data returned for date 2024-03-10. Status code: 200\n",
      "No data returned for date 2024-03-08. Status code: 200\n",
      "No data returned for date 2024-03-09. Status code: 200\n",
      "No data returned for date 2024-03-07. Status code: 200\n",
      "No data returned for date 2024-03-06. Status code: 200\n",
      "No data returned for date 2024-03-11. Status code: 200\n",
      "No data returned for date 2024-03-12. Status code: 200\n",
      "No data returned for date 2024-03-13. Status code: 200\n",
      "No data returned for date 2024-03-14. Status code: 200\n",
      "No data returned for date 2024-03-15. Status code: 200\n",
      "No data returned for date 2024-03-16. Status code: 200\n",
      "No data returned for date 2024-03-19. Status code: 200\n",
      "No data returned for date 2024-03-20. Status code: 200\n",
      "No data returned for date 2024-03-18. Status code: 200\n",
      "No data returned for date 2024-03-17. Status code: 200\n",
      "No data returned for date 2024-03-21. Status code: 200\n",
      "No data returned for date 2024-03-22. Status code: 200\n",
      "No data returned for date 2024-03-23. Status code: 200\n",
      "No data returned for date 2024-03-24. Status code: 200\n",
      "No data returned for date 2024-03-25. Status code: 200\n",
      "No data returned for date 2024-03-27. Status code: 200\n",
      "No data returned for date 2024-03-26. Status code: 200\n",
      "No data returned for date 2024-03-28. Status code: 200\n",
      "No data returned for date 2024-03-29. Status code: 200\n",
      "No data returned for date 2024-03-30. Status code: 200\n",
      "No data returned for date 2024-03-31. Status code: 200\n",
      "No data returned for date 2024-04-01. Status code: 200\n",
      "No data returned for date 2024-04-02. Status code: 200\n",
      "No data returned for date 2024-04-03. Status code: 200\n",
      "No data returned for date 2024-04-04. Status code: 200\n",
      "No data returned for date 2024-04-05. Status code: 200\n",
      "No data returned for date 2024-04-06. Status code: 200\n",
      "No data returned for date 2024-04-07. Status code: 200\n",
      "No data returned for date 2024-04-09. Status code: 200\n",
      "No data returned for date 2024-04-08. Status code: 200\n",
      "No data returned for date 2024-04-10. Status code: 200\n",
      "No data returned for date 2024-04-11. Status code: 200\n",
      "No data returned for date 2024-04-12. Status code: 200\n",
      "No data returned for date 2024-04-13. Status code: 200\n",
      "No data returned for date 2024-04-14. Status code: 200\n",
      "No data returned for date 2024-04-15. Status code: 200\n",
      "No data returned for date 2024-04-16. Status code: 200\n",
      "No data returned for date 2024-04-17. Status code: 200\n",
      "No data returned for date 2024-04-18. Status code: 200\n",
      "No data returned for date 2024-04-19. Status code: 200\n",
      "No data returned for date 2024-04-20. Status code: 200\n",
      "No data returned for date 2024-04-21. Status code: 200\n",
      "No data returned for date 2024-04-22. Status code: 200\n",
      "No data returned for date 2024-04-24. Status code: 200\n",
      "No data returned for date 2024-04-23. Status code: 200\n",
      "No data returned for date 2024-04-25. Status code: 200\n",
      "No data returned for date 2024-04-26. Status code: 200\n",
      "No data returned for date 2024-04-27. Status code: 200\n",
      "No data returned for date 2024-04-28. Status code: 200\n",
      "No data returned for date 2024-04-29. Status code: 200\n",
      "No data returned for date 2024-04-30. Status code: 200\n",
      "No data returned for date 2024-05-01. Status code: 200\n",
      "No data returned for date 2024-05-02. Status code: 200\n",
      "No data returned for date 2024-05-03. Status code: 200\n",
      "No data returned for date 2024-05-04. Status code: 200\n",
      "No data returned for date 2024-05-05. Status code: 200\n",
      "No data returned for date 2024-05-06. Status code: 200\n",
      "No data returned for date 2024-05-07. Status code: 200\n",
      "No data returned for date 2024-05-08. Status code: 200\n",
      "No data returned for date 2024-05-09. Status code: 200\n",
      "No data returned for date 2024-05-10. Status code: 200\n",
      "No data returned for date 2024-05-11. Status code: 200\n",
      "No data returned for date 2024-05-12. Status code: 200\n",
      "No data returned for date 2024-05-13. Status code: 200\n",
      "No data returned for date 2024-05-14. Status code: 200\n",
      "No data returned for date 2024-05-15. Status code: 200\n",
      "No data returned for date 2024-05-17. Status code: 200\n",
      "No data returned for date 2024-05-16. Status code: 200\n",
      "No data returned for date 2024-05-18. Status code: 200\n",
      "No data returned for date 2024-05-19. Status code: 200\n",
      "No data returned for date 2024-05-20. Status code: 200\n",
      "No data returned for date 2024-05-21. Status code: 200\n",
      "No data returned for date 2024-05-22. Status code: 200\n",
      "No data returned for date 2024-05-23. Status code: 200\n",
      "No data returned for date 2024-05-25. Status code: 200\n",
      "No data returned for date 2024-05-24. Status code: 200\n",
      "No data returned for date 2024-05-26. Status code: 200\n",
      "No data returned for date 2024-05-27. Status code: 200\n",
      "No data returned for date 2024-05-28. Status code: 200\n",
      "No data returned for date 2024-05-29. Status code: 200\n",
      "No data returned for date 2024-05-30. Status code: 200\n",
      "No data returned for date 2024-05-31. Status code: 200\n",
      "No data returned for date 2024-06-01. Status code: 200No data returned for date 2024-06-02. Status code: 200\n",
      "\n",
      "No data returned for date 2024-06-03. Status code: 200\n",
      "No data returned for date 2024-06-04. Status code: 200\n",
      "No data returned for date 2024-06-07. Status code: 200\n",
      "No data returned for date 2024-06-05. Status code: 200\n",
      "No data returned for date 2024-06-06. Status code: 200\n",
      "No data returned for date 2024-06-08. Status code: 200\n",
      "No data returned for date 2024-06-09. Status code: 200\n",
      "No data returned for date 2024-06-10. Status code: 200\n",
      "No data returned for date 2024-06-12. Status code: 200\n",
      "No data returned for date 2024-06-11. Status code: 200\n",
      "No data returned for date 2024-06-13. Status code: 200\n",
      "No data returned for date 2024-06-14. Status code: 200\n",
      "No data returned for date 2024-06-16. Status code: 200\n",
      "No data returned for date 2024-06-15. Status code: 200\n",
      "No data returned for date 2024-06-17. Status code: 200\n",
      "No data returned for date 2024-06-19. Status code: 200\n",
      "No data returned for date 2024-06-18. Status code: 200\n",
      "No data returned for date 2024-06-20. Status code: 200\n",
      "No data returned for date 2024-06-21. Status code: 200\n",
      "No data returned for date 2024-06-23. Status code: 200\n",
      "No data returned for date 2024-06-22. Status code: 200\n",
      "No data returned for date 2024-06-25. Status code: 200\n",
      "No data returned for date 2024-06-24. Status code: 200\n",
      "No data returned for date 2024-06-26. Status code: 200\n",
      "No data returned for date 2024-06-27. Status code: 200\n",
      "No data returned for date 2024-06-28. Status code: 200\n",
      "No data returned for date 2024-06-29. Status code: 200\n",
      "No data returned for date 2024-06-30. Status code: 200\n",
      "No data returned for date 2024-07-01. Status code: 200\n",
      "No data returned for date 2024-07-02. Status code: 200\n",
      "No data returned for date 2024-07-03. Status code: 200\n",
      "No data returned for date 2024-07-04. Status code: 200\n",
      "No data returned for date 2024-07-07. Status code: 200\n",
      "No data returned for date 2024-07-06. Status code: 200\n",
      "No data returned for date 2024-07-05. Status code: 200\n",
      "No data returned for date 2024-07-08. Status code: 200\n",
      "No data returned for date 2024-07-09. Status code: 200\n",
      "No data returned for date 2024-07-10. Status code: 200\n",
      "No data returned for date 2024-07-11. Status code: 200\n",
      "No data returned for date 2024-07-12. Status code: 200\n",
      "No data returned for date 2024-07-13. Status code: 200\n",
      "No data returned for date 2024-07-14. Status code: 200\n",
      "No data returned for date 2024-07-15. Status code: 200\n",
      "No data returned for date 2024-07-16. Status code: 200\n",
      "No data returned for date 2024-07-17. Status code: 200\n",
      "No data returned for date 2024-07-18. Status code: 200\n",
      "No data returned for date 2024-07-19. Status code: 200\n",
      "No data returned for date 2024-07-20. Status code: 200\n",
      "No data returned for date 2024-07-21. Status code: 200\n",
      "No data returned for date 2024-07-22. Status code: 200\n",
      "No data returned for date 2024-07-23. Status code: 200\n",
      "No data returned for date 2024-07-24. Status code: 200\n",
      "No data returned for date 2024-07-25. Status code: 200\n",
      "No data returned for date 2024-07-26. Status code: 200\n",
      "No data returned for date 2024-07-27. Status code: 200\n",
      "No data returned for date 2024-07-28. Status code: 200\n",
      "No data returned for date 2024-07-30. Status code: 200\n",
      "No data returned for date 2024-07-29. Status code: 200\n",
      "No data returned for date 2024-07-31. Status code: 200\n",
      "No data returned for date 2024-08-01. Status code: 200\n",
      "No data returned for date 2024-08-02. Status code: 200\n",
      "No data returned for date 2024-08-03. Status code: 200\n",
      "No data returned for date 2024-08-04. Status code: 200\n",
      "No data returned for date 2024-08-05. Status code: 200\n",
      "No data returned for date 2024-08-06. Status code: 200\n",
      "No data returned for date 2024-08-07. Status code: 200\n",
      "No data returned for date 2024-08-08. Status code: 200\n",
      "No data returned for date 2024-08-09. Status code: 200\n",
      "No data returned for date 2024-08-10. Status code: 200\n",
      "No data returned for date 2024-08-11. Status code: 200\n",
      "No data returned for date 2024-08-12. Status code: 200\n",
      "No data was collected. Please check your API key and ensure the service is available.\n",
      "No data to save.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import os\n",
    "\n",
    "API_KEY = 'D7KXZhPjt6caA9dwwAliN6CP3Oofacu5'\n",
    "BASE_URL = \"https://financialmodelingprep.com/api/v4/historical/social-sentiment\"\n",
    "\n",
    "def get_sentiment_data(date):\n",
    "    params = {\n",
    "        'symbol': 'BTC',\n",
    "        'date': date.strftime('%Y-%m-%d'),\n",
    "        'apikey': API_KEY\n",
    "    }\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data:\n",
    "            return data[0]\n",
    "    print(f\"No data returned for date {date.strftime('%Y-%m-%d')}. Status code: {response.status_code}\")\n",
    "    return None\n",
    "\n",
    "def collect_sentiment_data():\n",
    "    start_date = datetime(2024, 1, 1)\n",
    "    end_date = datetime.now()\n",
    "    dates = [start_date + timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "    \n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        future_to_date = {executor.submit(get_sentiment_data, date): date for date in dates}\n",
    "        for future in as_completed(future_to_date):\n",
    "            data = future.result()\n",
    "            if data:\n",
    "                results.append(data)\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No data was collected. Please check your API key and ensure the service is available.\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values('date')\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sentiment_data = collect_sentiment_data()\n",
    "    if sentiment_data is not None:\n",
    "        print(sentiment_data)\n",
    "        \n",
    "        # Save to CSV in F:\\ drive\n",
    "        output_path = r'F:\\bitcoin_sentiment_data.csv'\n",
    "        sentiment_data.to_csv(output_path, index=False)\n",
    "        print(f\"Data saved to {output_path}\")\n",
    "    else:\n",
    "        print(\"No data to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total VGT holdings: 318\n",
      "Processed: MSFT\n",
      "Processed: AAPL\n",
      "Processed: NVDA\n",
      "Processed: QCOM\n",
      "Processed: AMD\n",
      "Processed: ORCL\n",
      "Processed: AVGO\n",
      "Processed: CRM\n",
      "Processed: ADBE\n",
      "Processed: ACN\n",
      "Processed: CSCO\n",
      "Processed: INTU\n",
      "Processed: MU\n",
      "Processed: INTC\n",
      "Processed: LRCX\n",
      "Processed: AMAT\n",
      "Processed: ADI\n",
      "Processed: IBM\n",
      "Processed: NOW\n",
      "Processed: TXN\n",
      "Processed: KLAC\n",
      "Processed: PANW\n",
      "Processed: ANET\n",
      "Processed: ROP\n",
      "Processed: APH\n",
      "Processed: SNPS\n",
      "Processed: CDNS\n",
      "Processed: MSI\n",
      "Processed: NXPI\n",
      "Processed: MRVL\n",
      "Processed: PLTR\n",
      "Processed: ADSK\n",
      "Processed: CTSH\n",
      "Processed: WDAY\n",
      "Processed: CRWD\n",
      "Processed: FICO\n",
      "Processed: TEL\n",
      "Processed: IT\n",
      "Processed: MPWR\n",
      "Processed: MCHP\n",
      "Processed: FTNT\n",
      "Processed: SNOW\n",
      "Processed: SMCI\n",
      "Processed: DDOG\n",
      "Processed: MSTR\n",
      "Processed: HPQ\n",
      "Processed: GLW\n",
      "Processed: ON\n",
      "Processed: DELL\n",
      "Processed: CDW\n",
      "Processed: TEAM\n",
      "Processed: NTAP\n",
      "Processed: HPE\n",
      "Processed: TYL\n",
      "Processed: WDC\n",
      "Processed: NET\n",
      "Processed: FSLR\n",
      "Processed: ANSS\n",
      "Processed: HUBS\n",
      "Processed: KEYS\n",
      "Processed: TER\n",
      "Processed: STX\n",
      "Processed: PTC\n",
      "Processed: ENTG\n",
      "Processed: VRSN\n",
      "Processed: ZBRA\n",
      "Processed: SWKS\n",
      "Processed: GDDY\n",
      "Processed: PSTG\n",
      "Processed: TDY\n",
      "Processed: NLOK\n",
      "Processed: MDB\n",
      "Processed: ENPH\n",
      "Processed: ZS\n",
      "Processed: FLEX\n",
      "Processed: APP\n",
      "Processed: AKAM\n",
      "Processed: MANH\n",
      "Processed: OKTA\n",
      "Processed: ZM\n",
      "Processed: GWRE\n",
      "Processed: JBL\n",
      "Processed: FFIV\n",
      "Processed: QRVO\n",
      "Processed: EPAM\n",
      "Processed: JNPR\n",
      "Processed: TRMB\n",
      "Processed: COHR\n",
      "Processed: OLED\n",
      "Processed: DT\n",
      "Processed: NTNX\n",
      "Processed: TWLO\n",
      "Processed: CRUS\n",
      "Processed: ESTC\n",
      "Processed: CGNX\n",
      "Processed: CVLT\n",
      "Processed: DOCU\n",
      "Processed: FN\n",
      "Processed: BSY\n",
      "Processed: ONTO\n",
      "Processed: SNX\n",
      "Processed: SPSC\n",
      "Processed: KD\n",
      "Processed: CIEN\n",
      "Processed: MKSI\n",
      "Processed: VRNS\n",
      "Processed: IOT\n",
      "Processed: ZETA\n",
      "Processed: SMAR\n",
      "Processed: NOVT\n",
      "Processed: LFUS\n",
      "Processed: NSIT\n",
      "Processed: PCOR\n",
      "Processed: BMI\n",
      "Processed: CRDO\n",
      "Processed: ARW\n",
      "Processed: ACIW\n",
      "Processed: S\n",
      "Processed: DBX\n",
      "Processed: HCP\n",
      "Processed: VNT\n",
      "Processed: MARA\n",
      "Processed: MTSI\n",
      "Processed: QLYS\n",
      "Processed: TENB\n",
      "Processed: AEIS\n",
      "Processed: LSCC\n",
      "Processed: SANM\n",
      "Processed: QTWO\n",
      "Processed: DXC\n",
      "Processed: AUR\n",
      "Processed: ACLS\n",
      "Processed: FORM\n",
      "Processed: AVT\n",
      "Processed: PI\n",
      "Processed: ITRI\n",
      "Processed: PLXS\n",
      "Processed: GTLB\n",
      "Processed: AZPN\n",
      "Processed: RMBS\n",
      "Processed: POWI\n",
      "Processed: DLB\n",
      "Processed: ALTR\n",
      "Processed: PRFT\n",
      "Processed: FROG\n",
      "Processed: BOX\n",
      "Processed: IDCC\n",
      "Processed: AGYS\n",
      "Processed: APPF\n",
      "Processed: BDC\n",
      "Processed: ASGN\n",
      "Processed: LITE\n",
      "Processed: BILL\n",
      "Processed: AI\n",
      "Processed: DIOD\n",
      "Processed: AMKR\n",
      "Processed: CFLT\n",
      "Processed: ALGM\n",
      "Processed: DV\n",
      "Processed: PEGA\n",
      "Processed: ALRM\n",
      "Processed: CALX\n",
      "Processed: SITM\n",
      "Processed: CWAN\n",
      "Processed: SLAB\n",
      "Processed: VSH\n",
      "Processed: PLUS\n",
      "Processed: RNG\n",
      "Processed: SQSP\n",
      "Processed: SYNA\n",
      "Processed: BLKB\n",
      "Processed: CR\n",
      "Processed: VECO\n",
      "Processed: TDC\n",
      "Processed: U\n",
      "Processed: PRGS\n",
      "Processed: VERX\n",
      "Processed: PATH\n",
      "Processed: VRNT\n",
      "Processed: CLSK\n",
      "Processed: WK\n",
      "Processed: BRZE\n",
      "Processed: KLIC\n",
      "Processed: RPD\n",
      "Processed: OSIS\n",
      "Processed: CCCS\n",
      "Processed: RIOT\n",
      "Processed: FIVN\n",
      "Processed: AMBA\n",
      "Processed: ENV\n",
      "Processed: NCNO\n",
      "Processed: NSSC\n",
      "Processed: ROG\n",
      "Processed: SMTC\n",
      "Processed: BL\n",
      "Processed: IPGP\n",
      "Processed: NCR\n",
      "Processed: SPT\n",
      "Processed: UCTT\n",
      "Processed: FRSH\n",
      "Processed: TTMI\n",
      "Processed: EXTR\n",
      "Processed: RAMP\n",
      "Processed: YOU\n",
      "Processed: MIR\n",
      "Processed: PD\n",
      "Processed: DOCN\n",
      "Processed: VIAV\n",
      "Processed: PAR\n",
      "Processed: BHE\n",
      "Processed: WOLF\n",
      "Processed: ALKT\n",
      "Processed: KN\n",
      "Processed: PLAB\n",
      "Processed: INTA\n",
      "Processed: HLIT\n",
      "Processed: COHU\n",
      "Processed: INFA\n",
      "Processed: KVYO\n",
      "Processed: CTS\n",
      "Processed: IONQ\n",
      "Processed: ARLO\n",
      "Processed: NTCT\n",
      "Processed: APPN\n",
      "Processed: PWSC\n",
      "Processed: SEDG\n",
      "Processed: SCSC\n",
      "Processed: SOUN\n",
      "Processed: ADEA\n",
      "Processed: VSAT\n",
      "Processed: XRX\n",
      "Processed: MTTR\n",
      "Processed: ASAN\n",
      "Processed: SGH\n",
      "Processed: INFN\n",
      "Processed: AVPT\n",
      "Processed: CXM\n",
      "Processed: HUT.TO\n",
      "Processed: ZUO\n",
      "Processed: ICHR\n",
      "Processed: MXL\n",
      "Processed: FSLY\n",
      "Processed: AOSL\n",
      "Processed: NABL\n",
      "Processed: PDFS\n",
      "Processed: PRO\n",
      "Processed: DGII\n",
      "Processed: ATEN\n",
      "Processed: INDI\n",
      "Processed: CIFR\n",
      "Processed: CNXN\n",
      "Processed: WULF\n",
      "Processed: ACMR\n",
      "Processed: BASE\n",
      "Processed: JAMF\n",
      "Processed: ETWO\n",
      "Processed: GDYN\n",
      "Processed: AMPL\n",
      "Processed: BELFB\n",
      "Processed: HCKT\n",
      "Processed: MITK\n",
      "Processed: YEXT\n",
      "Processed: KE\n",
      "Processed: CLFD\n",
      "Processed: DBD\n",
      "Processed: SWI\n",
      "Processed: BIGC\n",
      "Processed: COMM\n",
      "Processed: LASR\n",
      "Processed: MLNK\n",
      "Processed: ADTN\n",
      "Processed: AEHR\n",
      "Processed: OLO\n",
      "Processed: APLD\n",
      "Processed: BLND\n",
      "Processed: CEVA\n",
      "Processed: DMRC\n",
      "Processed: NTGR\n",
      "Processed: NVTS\n",
      "Processed: OSPN\n",
      "Processed: SEMR\n",
      "Processed: LWLG\n",
      "Processed: MEI\n",
      "Processed: VPG\n",
      "Processed: CCSI\n",
      "Processed: OUST\n",
      "Processed: CRSR\n",
      "Processed: EVLV\n",
      "Processed: TWKS\n",
      "Processed: AMSWA\n",
      "Processed: ENFN\n",
      "Processed: WEAV\n",
      "Processed: EGHT\n",
      "Processed: FARO\n",
      "Processed: RBBN\n",
      "Processed: SMRT\n",
      "Processed: UIS\n",
      "Processed: XPER\n",
      "Processed: BELFA\n",
      "Processed: DOMO\n",
      "Processed: NN\n",
      "Processed: APPS\n",
      "Processed: TCX\n",
      "Processed: TLS\n",
      "Processed: MVIS\n",
      "Processed: MX\n",
      "Processed: ONTF\n",
      "Processed: LAW\n",
      "Processed: MASS\n",
      "Processed: PMTS\n",
      "Processed: CRNC\n",
      "Processed: RMNI\n",
      "Processed: RXT\n",
      "Processed: AEVA\n",
      "Processed: EXFY\n",
      "Processed: LPSN\n",
      "Processed: SCWX\n",
      "Processed: VERI\n",
      "Data saved to F:\\VGT_holdings_market_cap_ev_revenue.csv\n",
      "\n",
      "Data Summary:\n",
      "       latest_market_cap  latest_enterprise_value  revenue_2023  revenue_2024\n",
      "count       3.180000e+02             3.180000e+02  3.170000e+02  8.800000e+01\n",
      "mean        4.373407e+10             4.570857e+10  6.734249e+09  9.148421e+09\n",
      "std         2.597785e+11             2.667180e+11  2.678805e+10  2.918762e+10\n",
      "min         6.680695e+07             1.304210e+08  0.000000e+00  6.621800e+07\n",
      "25%         1.364709e+09             1.531803e+09  4.314960e+08  6.480165e+08\n",
      "50%         3.919650e+09             4.559002e+09  9.287250e+08  1.299122e+09\n",
      "75%         1.381290e+10             1.588572e+10  3.523926e+09  4.572340e+09\n",
      "max         3.393961e+12             3.473498e+12  3.832850e+11  2.451220e+11\n",
      "\n",
      "Companies with missing data:\n",
      "AAPL (Apple Inc.)\n",
      "QCOM (QUALCOMM Incorporated)\n",
      "AMD (Advanced Micro Devices, Inc.)\n",
      "AVGO (Broadcom Inc.)\n",
      "ADBE (Adobe Inc.)\n",
      "ACN (Accenture plc)\n",
      "MU (Micron Technology, Inc.)\n",
      "INTC (Intel Corporation)\n",
      "AMAT (Applied Materials, Inc.)\n",
      "ADI (Analog Devices, Inc.)\n",
      "IBM (International Business Machines Corporation)\n",
      "NOW (ServiceNow, Inc.)\n",
      "TXN (Texas Instruments Incorporated)\n",
      "ANET (Arista Networks, Inc.)\n",
      "ROP (Roper Technologies, Inc.)\n",
      "APH (Amphenol Corporation)\n",
      "SNPS (Synopsys, Inc.)\n",
      "CDNS (Cadence Design Systems, Inc.)\n",
      "MSI (Motorola Solutions, Inc.)\n",
      "NXPI (NXP Semiconductors N.V.)\n",
      "PLTR (Palantir Technologies Inc.)\n",
      "CTSH (Cognizant Technology Solutions Corporation)\n",
      "FICO (Fair Isaac Corporation)\n",
      "TEL (TE Connectivity Ltd.)\n",
      "IT (Gartner, Inc.)\n",
      "MPWR (Monolithic Power Systems, Inc.)\n",
      "FTNT (Fortinet, Inc.)\n",
      "DDOG (Datadog, Inc.)\n",
      "MSTR (MicroStrategy Incorporated)\n",
      "HPQ (HP Inc.)\n",
      "GLW (Corning Incorporated)\n",
      "ON (ON Semiconductor Corporation)\n",
      "CDW (CDW Corporation)\n",
      "HPE (Hewlett Packard Enterprise Company)\n",
      "TYL (Tyler Technologies, Inc.)\n",
      "NET (Cloudflare, Inc.)\n",
      "FSLR (First Solar, Inc.)\n",
      "ANSS (ANSYS, Inc.)\n",
      "HUBS (HubSpot, Inc.)\n",
      "KEYS (Keysight Technologies, Inc.)\n",
      "TER (Teradyne, Inc.)\n",
      "PTC (PTC Inc.)\n",
      "ENTG (Entegris, Inc.)\n",
      "VRSN (VeriSign, Inc.)\n",
      "ZBRA (Zebra Technologies Corporation)\n",
      "SWKS (Skyworks Solutions, Inc.)\n",
      "GDDY (GoDaddy Inc.)\n",
      "TDY (Teledyne Technologies Incorporated)\n",
      "NLOK (NortonLifeLock Inc.)\n",
      "ENPH (Enphase Energy, Inc.)\n",
      "APP (AppLovin Corporation)\n",
      "AKAM (Akamai Technologies, Inc.)\n",
      "MANH (Manhattan Associates, Inc.)\n",
      "JBL (Jabil Inc.)\n",
      "FFIV (F5, Inc.)\n",
      "EPAM (EPAM Systems, Inc.)\n",
      "JNPR (Juniper Networks, Inc.)\n",
      "TRMB (Trimble Inc.)\n",
      "OLED (Universal Display Corporation)\n",
      "TWLO (Twilio Inc.)\n",
      "CGNX (Cognex Corporation)\n",
      "BSY (Bentley Systems, Incorporated)\n",
      "ONTO (Onto Innovation Inc.)\n",
      "SNX (TD SYNNEX Corporation)\n",
      "SPSC (SPS Commerce, Inc.)\n",
      "KD (Kyndryl Holdings, Inc.)\n",
      "CIEN (Ciena Corporation)\n",
      "MKSI (MKS Instruments, Inc.)\n",
      "VRNS (Varonis Systems, Inc.)\n",
      "ZETA (Zeta Global Holdings Corp.)\n",
      "NOVT (Novanta Inc.)\n",
      "LFUS (Littelfuse, Inc.)\n",
      "NSIT (Insight Enterprises, Inc.)\n",
      "PCOR (Procore Technologies, Inc.)\n",
      "BMI (Badger Meter, Inc.)\n",
      "ARW (Arrow Electronics, Inc.)\n",
      "ACIW (ACI Worldwide, Inc.)\n",
      "DBX (Dropbox, Inc.)\n",
      "VNT (Vontier Corporation)\n",
      "MARA (Marathon Digital Holdings, Inc.)\n",
      "MTSI (MACOM Technology Solutions Holdings, Inc.)\n",
      "QLYS (Qualys, Inc.)\n",
      "TENB (Tenable Holdings, Inc.)\n",
      "AEIS (Advanced Energy Industries, Inc.)\n",
      "LSCC (Lattice Semiconductor Corporation)\n",
      "SANM (Sanmina Corporation)\n",
      "QTWO (Q2 Holdings, Inc.)\n",
      "AUR (Aurora Innovation, Inc.)\n",
      "ACLS (Axcelis Technologies, Inc.)\n",
      "FORM (FormFactor, Inc.)\n",
      "PI (Impinj, Inc.)\n",
      "ITRI (Itron, Inc.)\n",
      "PLXS (Plexus Corp.)\n",
      "RMBS (Rambus Inc.)\n",
      "POWI (Power Integrations, Inc.)\n",
      "DLB (Dolby Laboratories, Inc.)\n",
      "ALTR (Altair Engineering Inc.)\n",
      "PRFT (Perficient, Inc.)\n",
      "FROG (JFrog Ltd.)\n",
      "IDCC (InterDigital, Inc.)\n",
      "APPF (AppFolio, Inc.)\n",
      "BDC (Belden Inc.)\n",
      "ASGN (ASGN Incorporated)\n",
      "DIOD (Diodes Incorporated)\n",
      "AMKR (Amkor Technology, Inc.)\n",
      "CFLT (Confluent, Inc.)\n",
      "DV (DoubleVerify Holdings, Inc.)\n",
      "PEGA (Pegasystems Inc.)\n",
      "ALRM (Alarm.com Holdings, Inc.)\n",
      "CALX (Calix, Inc.)\n",
      "SITM (SiTime Corporation)\n",
      "CWAN (Clearwater Analytics Holdings, Inc.)\n",
      "SLAB (Silicon Laboratories Inc.)\n",
      "VSH (Vishay Intertechnology, Inc.)\n",
      "RNG (RingCentral, Inc.)\n",
      "SQSP (Squarespace, Inc.)\n",
      "BLKB (Blackbaud, Inc.)\n",
      "CR (Crane Company)\n",
      "VECO (Veeco Instruments Inc.)\n",
      "TDC (Teradata Corporation)\n",
      "U (Unity Software Inc.)\n",
      "PRGS (Progress Software Corporation)\n",
      "VERX (Vertex, Inc.)\n",
      "CLSK (CleanSpark, Inc.)\n",
      "WK (Workiva Inc.)\n",
      "KLIC (Kulicke and Soffa Industries, Inc.)\n",
      "RPD (Rapid7, Inc.)\n",
      "CCCS (CCC Intelligent Solutions Holdings Inc.)\n",
      "RIOT (Riot Blockchain, Inc.)\n",
      "FIVN (Five9, Inc.)\n",
      "ENV (Envestnet, Inc.)\n",
      "ROG (Rogers Corporation)\n",
      "BL (BlackLine, Inc.)\n",
      "IPGP (IPG Photonics Corporation)\n",
      "NCR (NCR Corporation)\n",
      "SPT (Sprout Social, Inc.)\n",
      "UCTT (Ultra Clean Holdings, Inc.)\n",
      "FRSH (Freshworks Inc.)\n",
      "YOU (Clear Secure, Inc.)\n",
      "MIR (Mirion Technologies, Inc.)\n",
      "DOCN (DigitalOcean Holdings, Inc.)\n",
      "PAR (PAR Technology Corporation)\n",
      "BHE (Benchmark Electronics, Inc.)\n",
      "ALKT (Alkami Technology, Inc.)\n",
      "KN (Knowles Corporation)\n",
      "PLAB (Photronics, Inc.)\n",
      "HLIT (Harmonic Inc.)\n",
      "COHU (Cohu, Inc.)\n",
      "INFA (Informatica Inc.)\n",
      "KVYO (Klaviyo, Inc.)\n",
      "CTS (CTS Corporation)\n",
      "IONQ (IonQ, Inc.)\n",
      "ARLO (Arlo Technologies, Inc.)\n",
      "APPN (Appian Corporation)\n",
      "PWSC (PowerSchool Holdings, Inc.)\n",
      "SEDG (SolarEdge Technologies, Inc.)\n",
      "SOUN (SoundHound AI, Inc.)\n",
      "ADEA (Adeia Inc.)\n",
      "XRX (Xerox Holdings Corporation)\n",
      "MTTR (Matterport, Inc.)\n",
      "SGH (SMART Global Holdings, Inc.)\n",
      "INFN (Infinera Corporation)\n",
      "AVPT (AvePoint, Inc.)\n",
      "HUT.TO (Hut 8 Mining Corp.)\n",
      "ICHR (Ichor Holdings, Ltd.)\n",
      "MXL (MaxLinear, Inc.)\n",
      "FSLY (Fastly, Inc.)\n",
      "NABL (N-able, Inc.)\n",
      "PDFS (PDF Solutions, Inc.)\n",
      "PRO (PROS Holdings, Inc.)\n",
      "DGII (Digi International Inc.)\n",
      "ATEN (A10 Networks, Inc.)\n",
      "INDI (indie Semiconductor, Inc.)\n",
      "CIFR (Cipher Mining Inc.)\n",
      "CNXN (PC Connection, Inc.)\n",
      "WULF (TeraWulf Inc.)\n",
      "ACMR (ACM Research, Inc.)\n",
      "JAMF (Jamf Holding Corp.)\n",
      "GDYN (Grid Dynamics Holdings, Inc.)\n",
      "AMPL (Amplitude, Inc.)\n",
      "BELFB (Bel Fuse Inc.)\n",
      "HCKT (The Hackett Group, Inc.)\n",
      "MITK (Mitek Systems, Inc.)\n",
      "CLFD (Clearfield, Inc.)\n",
      "DBD (Diebold Nixdorf, Incorporated)\n",
      "SWI (SolarWinds Corporation)\n",
      "BIGC (BigCommerce Holdings, Inc.)\n",
      "COMM (CommScope Holding Company, Inc.)\n",
      "LASR (nLIGHT, Inc.)\n",
      "MLNK (MeridianLink, Inc.)\n",
      "ADTN (ADTRAN Holdings, Inc.)\n",
      "OLO (Olo Inc.)\n",
      "BLND (Blend Labs, Inc.)\n",
      "CEVA (CEVA, Inc.)\n",
      "DMRC (Digimarc Corporation)\n",
      "NTGR (NETGEAR, Inc.)\n",
      "NVTS (Navitas Semiconductor Corporation)\n",
      "OSPN (OneSpan Inc.)\n",
      "SEMR (Semrush Holdings, Inc.)\n",
      "LWLG (Lightwave Logic, Inc.)\n",
      "VPG (Vishay Precision Group, Inc.)\n",
      "CCSI (Consensus Cloud Solutions, Inc.)\n",
      "OUST (Ouster, Inc.)\n",
      "CRSR (Corsair Gaming, Inc.)\n",
      "EVLV (Evolv Technologies Holdings, Inc.)\n",
      "TWKS (Thoughtworks Holding, Inc.)\n",
      "ENFN (Enfusion, Inc.)\n",
      "WEAV (Weave Communications, Inc.)\n",
      "FARO (FARO Technologies, Inc.)\n",
      "RBBN (Ribbon Communications Inc.)\n",
      "SMRT (SmartRent, Inc.)\n",
      "UIS (Unisys Corporation)\n",
      "XPER (Xperi Holding Corporation)\n",
      "BELFA (Bel Fuse Inc.)\n",
      "NN (NextNav Inc.)\n",
      "TCX (Tucows Inc.)\n",
      "TLS (Telos Corporation)\n",
      "MVIS (MicroVision, Inc.)\n",
      "MX (Magnachip Semiconductor Corporation)\n",
      "ONTF (ON24, Inc.)\n",
      "LAW (CS Disco, Inc.)\n",
      "MASS (908 Devices Inc.)\n",
      "PMTS (CPI Card Group Inc.)\n",
      "CRNC (Cerence Inc.)\n",
      "RMNI (Rimini Street, Inc.)\n",
      "RXT (Rackspace Technology, Inc.)\n",
      "AEVA (Aeva Technologies, Inc.)\n",
      "EXFY (Expensify, Inc.)\n",
      "LPSN (LivePerson, Inc.)\n",
      "VERI (Veritone, Inc.)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Your API Key\n",
    "API_KEY = 'D7KXZhPjt6caA9dwwAliN6CP3Oofacu5'\n",
    "\n",
    "def get_etf_holdings(etf_symbol):\n",
    "    url = f'https://financialmodelingprep.com/api/v3/etf-holder/{etf_symbol}?apikey={API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return {holding['asset']: holding['weightPercentage'] for holding in data}\n",
    "\n",
    "def get_company_data(symbol):\n",
    "    # Get company profile for full name\n",
    "    profile_url = f'https://financialmodelingprep.com/api/v3/profile/{symbol}?apikey={API_KEY}'\n",
    "    profile_response = requests.get(profile_url)\n",
    "    profile_data = profile_response.json()\n",
    "    \n",
    "    # Get latest market cap and enterprise value\n",
    "    ev_url = f'https://financialmodelingprep.com/api/v3/enterprise-value/{symbol}?limit=1&apikey={API_KEY}'\n",
    "    ev_response = requests.get(ev_url)\n",
    "    ev_data = ev_response.json()\n",
    "    \n",
    "    # Get income statement for revenue\n",
    "    income_url = f'https://financialmodelingprep.com/api/v3/income-statement/{symbol}?limit=2&apikey={API_KEY}'\n",
    "    income_response = requests.get(income_url)\n",
    "    income_data = income_response.json()\n",
    "    \n",
    "    company_name = profile_data[0]['companyName'] if profile_data else 'N/A'\n",
    "    latest_data = ev_data[0] if ev_data else {}\n",
    "    \n",
    "    revenue_2023 = None\n",
    "    revenue_2024 = None\n",
    "    for statement in income_data:\n",
    "        if statement['date'].startswith('2023'):\n",
    "            revenue_2023 = statement['revenue']\n",
    "        elif statement['date'].startswith('2024'):\n",
    "            revenue_2024 = statement['revenue']\n",
    "    \n",
    "    return {\n",
    "        'symbol': symbol,\n",
    "        'name': company_name,\n",
    "        'latest_market_cap': latest_data.get('marketCapitalization'),\n",
    "        'latest_enterprise_value': latest_data.get('enterpriseValue'),\n",
    "        'revenue_2023': revenue_2023,\n",
    "        'revenue_2024': revenue_2024\n",
    "    }\n",
    "\n",
    "# Get VGT ETF holdings\n",
    "vgt_holdings = get_etf_holdings('VGT')\n",
    "print(f\"Total VGT holdings: {len(vgt_holdings)}\")\n",
    "\n",
    "# Fetch data for all companies using ThreadPoolExecutor\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    future_to_company = {executor.submit(get_company_data, symbol): symbol for symbol in vgt_holdings.keys()}\n",
    "    for future in as_completed(future_to_company):\n",
    "        symbol = future_to_company[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "            print(f\"Processed: {symbol}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {symbol}: {str(e)}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Reorder columns\n",
    "df = df[['symbol', 'name', 'latest_market_cap', 'latest_enterprise_value', 'revenue_2023', 'revenue_2024']]\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = 'F:\\\\VGT_holdings_market_cap_ev_revenue.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"Data saved to {csv_path}\")\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nData Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Print companies with missing data\n",
    "missing_data = df[(df['latest_market_cap'].isnull()) | (df['latest_enterprise_value'].isnull()) | (df['revenue_2023'].isnull()) | (df['revenue_2024'].isnull())]\n",
    "if not missing_data.empty:\n",
    "    print(\"\\nCompanies with missing data:\")\n",
    "    for _, row in missing_data.iterrows():\n",
    "        print(f\"{row['symbol']} ({row['name']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique holdings: 331\n",
      "Error processing : 0\n",
      "Processed: MITK\n",
      "Processed: AUR\n",
      "Processed: FIVN\n",
      "Processed: SPT\n",
      "Processed: FORM\n",
      "Processed: IOT\n",
      "Processed: BASE\n",
      "Processed: CXT\n",
      "Processed: UCTT\n",
      "Processed: WDAY\n",
      "Processed: ANSS\n",
      "Processed: MIR\n",
      "Processed: AVGO\n",
      "Processed: CEVA\n",
      "Processed: DBX\n",
      "Processed: LFUS\n",
      "Processed: GTLB\n",
      "Processed: IT\n",
      "Processed: NVDA\n",
      "Processed: EVLV\n",
      "Processed: MDB\n",
      "Processed: ALTR\n",
      "Processed: ASGN\n",
      "Processed: PLXS\n",
      "Processed: NSIT\n",
      "Processed: HLIT\n",
      "Processed: WULF\n",
      "Processed: GDDY\n",
      "Processed: BL\n",
      "Processed: APH\n",
      "Processed: SGH\n",
      "Processed: CSCO\n",
      "Processed: BDC\n",
      "Processed: DDOG\n",
      "Processed: LASR\n",
      "Processed: DBD\n",
      "Processed: BIGC\n",
      "Processed: KEYS\n",
      "Processed: GEN\n",
      "Processed: PSTG\n",
      "Processed: TEAM\n",
      "Processed: VSAT\n",
      "Processed: DMRC\n",
      "Processed: VECO\n",
      "Processed: PRGS\n",
      "Processed: NCR\n",
      "Processed: ZUO\n",
      "Processed: ADTN\n",
      "Processed: ADEA\n",
      "Processed: AMKR\n",
      "Processed: PLUS\n",
      "Processed: MANH\n",
      "Processed: FLEX\n",
      "Processed: CFLT\n",
      "Processed: HPE\n",
      "Processed: BHE\n",
      "Processed: CLSK\n",
      "Processed: PMTS\n",
      "Processed: VSH\n",
      "Processed: CORZ\n",
      "Processed: AEVA\n",
      "Processed: COHU\n",
      "Processed: DGII\n",
      "Processed: MCHP\n",
      "Processed: TWKS\n",
      "Processed: CLFD\n",
      "Processed: VRNS\n",
      "Processed: MTSI\n",
      "Processed: AOSL\n",
      "Processed: AEIS\n",
      "Processed: AMPL\n",
      "Processed: ATEN\n",
      "Processed: MKSI\n",
      "Processed: KVYO\n",
      "Processed: NCNO\n",
      "Processed: SNOW\n",
      "Processed: AAPL\n",
      "Processed: OLED\n",
      "Processed: ONTO\n",
      "Processed: BLKB\n",
      "Processed: INTU\n",
      "Processed: ACIW\n",
      "Processed: RPD\n",
      "Processed: ICHR\n",
      "Processed: QRVO\n",
      "Processed: FN\n",
      "Processed: EXFY\n",
      "Processed: HUT.TO\n",
      "Processed: PWSC\n",
      "Processed: NET\n",
      "Processed: ZM\n",
      "Processed: LPSN\n",
      "Processed: COMM\n",
      "Processed: RBBN\n",
      "Processed: CRNC\n",
      "Processed: ACLS\n",
      "Processed: SWKS\n",
      "Processed: GLW\n",
      "Processed: OSIS\n",
      "Processed: WOLF\n",
      "Processed: RXT\n",
      "Processed: NABL\n",
      "Processed: AMBA\n",
      "Processed: MSFT\n",
      "Processed: CGNX\n",
      "Processed: NLOK\n",
      "Processed: ALKT\n",
      "Processed: MASS\n",
      "Processed: MARA\n",
      "Processed: AMSWA\n",
      "Processed: VYX\n",
      "Processed: BLND\n",
      "Processed: SPSC\n",
      "Processed: ON\n",
      "Processed: APPS\n",
      "Processed: RIOT\n",
      "Processed: YOU\n",
      "Processed: APLD\n",
      "Processed: BRZE\n",
      "Processed: INFN\n",
      "Processed: FRSH\n",
      "Processed: EGHT\n",
      "Processed: AMAT\n",
      "Processed: ACMR\n",
      "Processed: DOMO\n",
      "Processed: ENTG\n",
      "Processed: UIS\n",
      "Processed: DIOD\n",
      "Processed: BOX\n",
      "Processed: PEGA\n",
      "Processed: MU\n",
      "Processed: NTCT\n",
      "Processed: VRSN\n",
      "Processed: ITRI\n",
      "Processed: GWRE\n",
      "Processed: SLAB\n",
      "Processed: NOW\n",
      "Processed: TYL\n",
      "Processed: BSY\n",
      "Processed: ETWO\n",
      "Processed: ENFN\n",
      "Processed: PRO\n",
      "Processed: MSTR\n",
      "Processed: SEMR\n",
      "Processed: IPGP\n",
      "Processed: CCCS\n",
      "Processed: NSSC\n",
      "Processed: VERI\n",
      "Processed: ANET\n",
      "Processed: PD\n",
      "Processed: XPER\n",
      "Processed: CTSH\n",
      "Processed: VRNT\n",
      "Processed: MVIS\n",
      "Processed: VPG\n",
      "Processed: TTMI\n",
      "Processed: SMCI\n",
      "Processed: CRDO\n",
      "Processed: CCSI\n",
      "Processed: SCSC\n",
      "Processed: TRMB\n",
      "Processed: TEL\n",
      "Processed: SMTC\n",
      "Processed: OSPN\n",
      "Processed: HUBS\n",
      "Processed: QCOM\n",
      "Processed: CVLT\n",
      "Processed: ESTC\n",
      "Processed: MTTR\n",
      "Processed: SITM\n",
      "Processed: ARLO\n",
      "Processed: ALRM\n",
      "Processed: SMAR\n",
      "Processed: YEXT\n",
      "Processed: AI\n",
      "Processed: CRUS\n",
      "Processed: JBL\n",
      "Processed: ALGM\n",
      "Processed: COHR\n",
      "Processed: MXL\n",
      "Processed: ASAN\n",
      "Processed: APP\n",
      "Processed: SNX\n",
      "Processed: ORCL\n",
      "Processed: CWAN\n",
      "Processed: SYNA\n",
      "Processed: DOCN\n",
      "Processed: INTC\n",
      "Processed: ZS\n",
      "Processed: RTYZ24\n",
      "Processed: AVT\n",
      "Processed: ONTF\n",
      "Processed: MRVL\n",
      "Processed: LITE\n",
      "Processed: GDYN\n",
      "Processed: PATH\n",
      "Processed: PI\n",
      "Processed: DELL\n",
      "Processed: ADSK\n",
      "Processed: ROP\n",
      "Processed: HCP\n",
      "Processed: BMI\n",
      "Processed: DT\n",
      "Processed: VNT\n",
      "Processed: INFA\n",
      "Processed: IBM\n",
      "Processed: AVPT\n",
      "Processed: AGYS\n",
      "Processed: RMBS\n",
      "Processed: JNPR\n",
      "Processed: LWLG\n",
      "Processed: CRWD\n",
      "Processed: AEHR\n",
      "Processed: TXN\n",
      "Processed: NVTS\n",
      "Processed: FARO\n",
      "Processed: NOVT\n",
      "Processed: AAOI\n",
      "Processed: OLO\n",
      "Processed: SQSP\n",
      "Processed: ACN\n",
      "Processed: INDI\n",
      "Processed: ENV\n",
      "Processed: CIEN\n",
      "Processed: NTGR\n",
      "Processed: DLB\n",
      "Processed: RBRK\n",
      "Processed: TDY\n",
      "Processed: DJCO\n",
      "Processed: AMD\n",
      "Processed: CALX\n",
      "Processed: WDC\n",
      "Processed: APPF\n",
      "Processed: ENPH\n",
      "Processed: CRM\n",
      "Processed: RNG\n",
      "Processed: DV\n",
      "Processed: MLNK\n",
      "Processed: MPWR\n",
      "Processed: LSCC\n",
      "Processed: DOCU\n",
      "Processed: CXM\n",
      "Processed: AZPN\n",
      "Processed: KE\n",
      "Processed: JAMF\n",
      "Processed: DXC\n",
      "Processed: DAKT\n",
      "Processed: MSI\n",
      "Processed: KN\n",
      "Processed: HUT\n",
      "Processed: FROG\n",
      "Processed: HPQ\n",
      "Processed: WK\n",
      "Processed: SANM\n",
      "Processed: CRSR\n",
      "Processed: BELFB\n",
      "Processed: PAR\n",
      "Processed: HCKT\n",
      "Processed: TLS\n",
      "Processed: ADI\n",
      "Processed: PLTR\n",
      "Processed: OUST\n",
      "Processed: INTA\n",
      "Processed: FSLY\n",
      "Processed: PGY\n",
      "Processed: BELFA\n",
      "Processed: SEDG\n",
      "Processed: IDCC\n",
      "Processed: CR\n",
      "Processed: CNXN\n",
      "Processed: BILL\n",
      "Processed: EPAM\n",
      "Processed: PANW\n",
      "Processed: QTWO\n",
      "Processed: EXTR\n",
      "Processed: PRFT\n",
      "Processed: NN\n",
      "Processed: TENB\n",
      "Processed: NTNX\n",
      "Processed: SWI\n",
      "Processed: TCX\n",
      "Processed: U\n",
      "Processed: PDFS\n",
      "Processed: CDW\n",
      "Processed: S\n",
      "Processed: TER\n",
      "Processed: APPN\n",
      "Processed: FICO\n",
      "Processed: XAKZ24\n",
      "Processed: SNPS\n",
      "Processed: RMNI\n",
      "Processed: VERX\n",
      "Processed: MEI\n",
      "Processed: SCWX\n",
      "Processed: FFIV\n",
      "Processed: TDC\n",
      "Processed: NTAP\n",
      "Processed: POWI\n",
      "Processed: FSLR\n",
      "Processed: ROG\n",
      "Processed: NXPI\n",
      "Processed: LRCX\n",
      "Processed: ZBRA\n",
      "Processed: FTNT\n",
      "Processed: AKAM\n",
      "Processed: XRX\n",
      "Processed: SOUN\n",
      "Processed: CTS\n",
      "Processed: ARW\n",
      "Processed: STX\n",
      "Processed: OKTA\n",
      "Processed: RAMP\n",
      "Processed: MX\n",
      "Processed: CDNS\n",
      "Processed: KD\n",
      "Processed: KLAC\n",
      "Processed: PCOR\n",
      "Processed: VIAV\n",
      "Processed: QLYS\n",
      "Processed: IONQ\n",
      "Processed: PTC\n",
      "Processed: ADBE\n",
      "Processed: SMRT\n",
      "Processed: ZETA\n",
      "Processed: LAW\n",
      "Processed: WEAV\n",
      "Processed: KLIC\n",
      "Processed: PLAB\n",
      "Processed: CIFR\n",
      "Processed: TWLO\n",
      "Data saved to F:\\VGT_FTEC_holdings_market_cap_ev_revenue.csv\n",
      "\n",
      "Data Summary:\n",
      "       latest_market_cap  latest_enterprise_value  revenue_2023  revenue_2024\n",
      "count       3.280000e+02             3.280000e+02  3.270000e+02  9.100000e+01\n",
      "mean        4.249478e+10             4.444686e+10  6.562024e+09  8.904604e+09\n",
      "std         2.558723e+11             2.627070e+11  2.639285e+10  2.872897e+10\n",
      "min         6.680695e+07             1.304210e+08  0.000000e+00  6.621800e+07\n",
      "25%         1.283886e+09             1.479077e+09  4.232575e+08  6.435290e+08\n",
      "50%         3.772903e+09             4.374605e+09  9.145300e+08  1.290172e+09\n",
      "75%         1.351797e+10             1.467491e+10  3.370022e+09  4.442914e+09\n",
      "max         3.393961e+12             3.473498e+12  3.832850e+11  2.451220e+11\n",
      "\n",
      "Companies with missing data:\n",
      "MITK (Mitek Systems, Inc.)\n",
      "AUR (Aurora Innovation, Inc.)\n",
      "FIVN (Five9, Inc.)\n",
      "SPT (Sprout Social, Inc.)\n",
      "FORM (FormFactor, Inc.)\n",
      "CXT (Crane NXT, Co.)\n",
      "UCTT (Ultra Clean Holdings, Inc.)\n",
      "ANSS (ANSYS, Inc.)\n",
      "MIR (Mirion Technologies, Inc.)\n",
      "AVGO (Broadcom Inc.)\n",
      "CEVA (CEVA, Inc.)\n",
      "DBX (Dropbox, Inc.)\n",
      "LFUS (Littelfuse, Inc.)\n",
      "IT (Gartner, Inc.)\n",
      "EVLV (Evolv Technologies Holdings, Inc.)\n",
      "ALTR (Altair Engineering Inc.)\n",
      "ASGN (ASGN Incorporated)\n",
      "PLXS (Plexus Corp.)\n",
      "NSIT (Insight Enterprises, Inc.)\n",
      "HLIT (Harmonic Inc.)\n",
      "WULF (TeraWulf Inc.)\n",
      "GDDY (GoDaddy Inc.)\n",
      "BL (BlackLine, Inc.)\n",
      "APH (Amphenol Corporation)\n",
      "SGH (SMART Global Holdings, Inc.)\n",
      "BDC (Belden Inc.)\n",
      "DDOG (Datadog, Inc.)\n",
      "LASR (nLIGHT, Inc.)\n",
      "DBD (Diebold Nixdorf, Incorporated)\n",
      "BIGC (BigCommerce Holdings, Inc.)\n",
      "KEYS (Keysight Technologies, Inc.)\n",
      "DMRC (Digimarc Corporation)\n",
      "VECO (Veeco Instruments Inc.)\n",
      "PRGS (Progress Software Corporation)\n",
      "NCR (NCR Corporation)\n",
      "ADTN (ADTRAN Holdings, Inc.)\n",
      "ADEA (Adeia Inc.)\n",
      "AMKR (Amkor Technology, Inc.)\n",
      "MANH (Manhattan Associates, Inc.)\n",
      "CFLT (Confluent, Inc.)\n",
      "HPE (Hewlett Packard Enterprise Company)\n",
      "BHE (Benchmark Electronics, Inc.)\n",
      "CLSK (CleanSpark, Inc.)\n",
      "PMTS (CPI Card Group Inc.)\n",
      "VSH (Vishay Intertechnology, Inc.)\n",
      "CORZ (Core Scientific, Inc.)\n",
      "AEVA (Aeva Technologies, Inc.)\n",
      "COHU (Cohu, Inc.)\n",
      "DGII (Digi International Inc.)\n",
      "TWKS (Thoughtworks Holding, Inc.)\n",
      "CLFD (Clearfield, Inc.)\n",
      "VRNS (Varonis Systems, Inc.)\n",
      "MTSI (MACOM Technology Solutions Holdings, Inc.)\n",
      "AEIS (Advanced Energy Industries, Inc.)\n",
      "AMPL (Amplitude, Inc.)\n",
      "ATEN (A10 Networks, Inc.)\n",
      "MKSI (MKS Instruments, Inc.)\n",
      "KVYO (Klaviyo, Inc.)\n",
      "AAPL (Apple Inc.)\n",
      "OLED (Universal Display Corporation)\n",
      "ONTO (Onto Innovation Inc.)\n",
      "BLKB (Blackbaud, Inc.)\n",
      "ACIW (ACI Worldwide, Inc.)\n",
      "RPD (Rapid7, Inc.)\n",
      "ICHR (Ichor Holdings, Ltd.)\n",
      "EXFY (Expensify, Inc.)\n",
      "HUT.TO (Hut 8 Mining Corp.)\n",
      "PWSC (PowerSchool Holdings, Inc.)\n",
      "NET (Cloudflare, Inc.)\n",
      "LPSN (LivePerson, Inc.)\n",
      "COMM (CommScope Holding Company, Inc.)\n",
      "RBBN (Ribbon Communications Inc.)\n",
      "CRNC (Cerence Inc.)\n",
      "ACLS (Axcelis Technologies, Inc.)\n",
      "SWKS (Skyworks Solutions, Inc.)\n",
      "GLW (Corning Incorporated)\n",
      "RXT (Rackspace Technology, Inc.)\n",
      "NABL (N-able, Inc.)\n",
      "CGNX (Cognex Corporation)\n",
      "NLOK (NortonLifeLock Inc.)\n",
      "ALKT (Alkami Technology, Inc.)\n",
      "MASS (908 Devices Inc.)\n",
      "MARA (Marathon Digital Holdings, Inc.)\n",
      "VYX (NCR Voyix Corporation)\n",
      "BLND (Blend Labs, Inc.)\n",
      "SPSC (SPS Commerce, Inc.)\n",
      "ON (ON Semiconductor Corporation)\n",
      "RIOT (Riot Blockchain, Inc.)\n",
      "YOU (Clear Secure, Inc.)\n",
      "INFN (Infinera Corporation)\n",
      "FRSH (Freshworks Inc.)\n",
      "AMAT (Applied Materials, Inc.)\n",
      "ACMR (ACM Research, Inc.)\n",
      "ENTG (Entegris, Inc.)\n",
      "UIS (Unisys Corporation)\n",
      "DIOD (Diodes Incorporated)\n",
      "PEGA (Pegasystems Inc.)\n",
      "MU (Micron Technology, Inc.)\n",
      "VRSN (VeriSign, Inc.)\n",
      "ITRI (Itron, Inc.)\n",
      "SLAB (Silicon Laboratories Inc.)\n",
      "NOW (ServiceNow, Inc.)\n",
      "TYL (Tyler Technologies, Inc.)\n",
      "BSY (Bentley Systems, Incorporated)\n",
      "ENFN (Enfusion, Inc.)\n",
      "PRO (PROS Holdings, Inc.)\n",
      "MSTR (MicroStrategy Incorporated)\n",
      "SEMR (Semrush Holdings, Inc.)\n",
      "IPGP (IPG Photonics Corporation)\n",
      "CCCS (CCC Intelligent Solutions Holdings Inc.)\n",
      "VERI (Veritone, Inc.)\n",
      "ANET (Arista Networks, Inc.)\n",
      "XPER (Xperi Holding Corporation)\n",
      "CTSH (Cognizant Technology Solutions Corporation)\n",
      "MVIS (MicroVision, Inc.)\n",
      "VPG (Vishay Precision Group, Inc.)\n",
      "CCSI (Consensus Cloud Solutions, Inc.)\n",
      "TRMB (Trimble Inc.)\n",
      "TEL (TE Connectivity Ltd.)\n",
      "OSPN (OneSpan Inc.)\n",
      "HUBS (HubSpot, Inc.)\n",
      "QCOM (QUALCOMM Incorporated)\n",
      "MTTR (Matterport, Inc.)\n",
      "SITM (SiTime Corporation)\n",
      "ARLO (Arlo Technologies, Inc.)\n",
      "ALRM (Alarm.com Holdings, Inc.)\n",
      "JBL (Jabil Inc.)\n",
      "MXL (MaxLinear, Inc.)\n",
      "APP (AppLovin Corporation)\n",
      "SNX (TD SYNNEX Corporation)\n",
      "CWAN (Clearwater Analytics Holdings, Inc.)\n",
      "DOCN (DigitalOcean Holdings, Inc.)\n",
      "INTC (Intel Corporation)\n",
      "RTYZ24 (N/A)\n",
      "ONTF (ON24, Inc.)\n",
      "GDYN (Grid Dynamics Holdings, Inc.)\n",
      "PI (Impinj, Inc.)\n",
      "ROP (Roper Technologies, Inc.)\n",
      "BMI (Badger Meter, Inc.)\n",
      "VNT (Vontier Corporation)\n",
      "INFA (Informatica Inc.)\n",
      "IBM (International Business Machines Corporation)\n",
      "AVPT (AvePoint, Inc.)\n",
      "RMBS (Rambus Inc.)\n",
      "JNPR (Juniper Networks, Inc.)\n",
      "LWLG (Lightwave Logic, Inc.)\n",
      "TXN (Texas Instruments Incorporated)\n",
      "NVTS (Navitas Semiconductor Corporation)\n",
      "FARO (FARO Technologies, Inc.)\n",
      "NOVT (Novanta Inc.)\n",
      "AAOI (Applied Optoelectronics, Inc.)\n",
      "OLO (Olo Inc.)\n",
      "SQSP (Squarespace, Inc.)\n",
      "ACN (Accenture plc)\n",
      "INDI (indie Semiconductor, Inc.)\n",
      "ENV (Envestnet, Inc.)\n",
      "CIEN (Ciena Corporation)\n",
      "NTGR (NETGEAR, Inc.)\n",
      "DLB (Dolby Laboratories, Inc.)\n",
      "TDY (Teledyne Technologies Incorporated)\n",
      "DJCO (Daily Journal Corporation)\n",
      "AMD (Advanced Micro Devices, Inc.)\n",
      "CALX (Calix, Inc.)\n",
      "APPF (AppFolio, Inc.)\n",
      "ENPH (Enphase Energy, Inc.)\n",
      "RNG (RingCentral, Inc.)\n",
      "DV (DoubleVerify Holdings, Inc.)\n",
      "MLNK (MeridianLink, Inc.)\n",
      "MPWR (Monolithic Power Systems, Inc.)\n",
      "LSCC (Lattice Semiconductor Corporation)\n",
      "JAMF (Jamf Holding Corp.)\n",
      "MSI (Motorola Solutions, Inc.)\n",
      "KN (Knowles Corporation)\n",
      "HUT (Hut 8 Mining Corp.)\n",
      "FROG (JFrog Ltd.)\n",
      "HPQ (HP Inc.)\n",
      "WK (Workiva Inc.)\n",
      "SANM (Sanmina Corporation)\n",
      "CRSR (Corsair Gaming, Inc.)\n",
      "BELFB (Bel Fuse Inc.)\n",
      "PAR (PAR Technology Corporation)\n",
      "HCKT (The Hackett Group, Inc.)\n",
      "TLS (Telos Corporation)\n",
      "ADI (Analog Devices, Inc.)\n",
      "PLTR (Palantir Technologies Inc.)\n",
      "OUST (Ouster, Inc.)\n",
      "FSLY (Fastly, Inc.)\n",
      "PGY (Pagaya Technologies Ltd.)\n",
      "BELFA (Bel Fuse Inc.)\n",
      "SEDG (SolarEdge Technologies, Inc.)\n",
      "IDCC (InterDigital, Inc.)\n",
      "CR (Crane Company)\n",
      "CNXN (PC Connection, Inc.)\n",
      "EPAM (EPAM Systems, Inc.)\n",
      "QTWO (Q2 Holdings, Inc.)\n",
      "PRFT (Perficient, Inc.)\n",
      "NN (NextNav Inc.)\n",
      "TENB (Tenable Holdings, Inc.)\n",
      "SWI (SolarWinds Corporation)\n",
      "TCX (Tucows Inc.)\n",
      "U (Unity Software Inc.)\n",
      "PDFS (PDF Solutions, Inc.)\n",
      "CDW (CDW Corporation)\n",
      "TER (Teradyne, Inc.)\n",
      "APPN (Appian Corporation)\n",
      "FICO (Fair Isaac Corporation)\n",
      "XAKZ24 (N/A)\n",
      "SNPS (Synopsys, Inc.)\n",
      "RMNI (Rimini Street, Inc.)\n",
      "VERX (Vertex, Inc.)\n",
      "FFIV (F5, Inc.)\n",
      "TDC (Teradata Corporation)\n",
      "POWI (Power Integrations, Inc.)\n",
      "FSLR (First Solar, Inc.)\n",
      "ROG (Rogers Corporation)\n",
      "NXPI (NXP Semiconductors N.V.)\n",
      "ZBRA (Zebra Technologies Corporation)\n",
      "FTNT (Fortinet, Inc.)\n",
      "AKAM (Akamai Technologies, Inc.)\n",
      "XRX (Xerox Holdings Corporation)\n",
      "SOUN (SoundHound AI, Inc.)\n",
      "CTS (CTS Corporation)\n",
      "ARW (Arrow Electronics, Inc.)\n",
      "MX (Magnachip Semiconductor Corporation)\n",
      "CDNS (Cadence Design Systems, Inc.)\n",
      "KD (Kyndryl Holdings, Inc.)\n",
      "PCOR (Procore Technologies, Inc.)\n",
      "QLYS (Qualys, Inc.)\n",
      "IONQ (IonQ, Inc.)\n",
      "PTC (PTC Inc.)\n",
      "ADBE (Adobe Inc.)\n",
      "SMRT (SmartRent, Inc.)\n",
      "ZETA (Zeta Global Holdings Corp.)\n",
      "LAW (CS Disco, Inc.)\n",
      "WEAV (Weave Communications, Inc.)\n",
      "KLIC (Kulicke and Soffa Industries, Inc.)\n",
      "PLAB (Photronics, Inc.)\n",
      "CIFR (Cipher Mining Inc.)\n",
      "TWLO (Twilio Inc.)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Your API Key\n",
    "API_KEY = 'D7KXZhPjt6caA9dwwAliN6CP3Oofacu5'\n",
    "\n",
    "def get_etf_holdings(etf_symbol):\n",
    "    url = f'https://financialmodelingprep.com/api/v3/etf-holder/{etf_symbol}?apikey={API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return {holding['asset']: holding['weightPercentage'] for holding in data}\n",
    "\n",
    "def get_company_data(symbol):\n",
    "    # Get company profile for full name\n",
    "    profile_url = f'https://financialmodelingprep.com/api/v3/profile/{symbol}?apikey={API_KEY}'\n",
    "    profile_response = requests.get(profile_url)\n",
    "    profile_data = profile_response.json()\n",
    "    \n",
    "    # Get latest market cap and enterprise value\n",
    "    ev_url = f'https://financialmodelingprep.com/api/v3/enterprise-value/{symbol}?limit=1&apikey={API_KEY}'\n",
    "    ev_response = requests.get(ev_url)\n",
    "    ev_data = ev_response.json()\n",
    "    \n",
    "    # Get income statement for revenue\n",
    "    income_url = f'https://financialmodelingprep.com/api/v3/income-statement/{symbol}?limit=2&apikey={API_KEY}'\n",
    "    income_response = requests.get(income_url)\n",
    "    income_data = income_response.json()\n",
    "    \n",
    "    company_name = profile_data[0]['companyName'] if profile_data else 'N/A'\n",
    "    latest_data = ev_data[0] if ev_data else {}\n",
    "    \n",
    "    revenue_2023 = None\n",
    "    revenue_2024 = None\n",
    "    for statement in income_data:\n",
    "        if statement['date'].startswith('2023'):\n",
    "            revenue_2023 = statement['revenue']\n",
    "        elif statement['date'].startswith('2024'):\n",
    "            revenue_2024 = statement['revenue']\n",
    "    \n",
    "    return {\n",
    "        'symbol': symbol,\n",
    "        'name': company_name,\n",
    "        'latest_market_cap': latest_data.get('marketCapitalization'),\n",
    "        'latest_enterprise_value': latest_data.get('enterpriseValue'),\n",
    "        'revenue_2023': revenue_2023,\n",
    "        'revenue_2024': revenue_2024\n",
    "    }\n",
    "\n",
    "# Get holdings for both ETFs\n",
    "vgt_holdings = get_etf_holdings('VGT')\n",
    "ftec_holdings = get_etf_holdings('FTEC')\n",
    "\n",
    "# Combine unique holdings\n",
    "all_holdings = set(vgt_holdings.keys()).union(set(ftec_holdings.keys()))\n",
    "print(f\"Total unique holdings: {len(all_holdings)}\")\n",
    "\n",
    "# Fetch data for all companies using ThreadPoolExecutor\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    future_to_company = {executor.submit(get_company_data, symbol): symbol for symbol in all_holdings}\n",
    "    for future in as_completed(future_to_company):\n",
    "        symbol = future_to_company[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "            print(f\"Processed: {symbol}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {symbol}: {str(e)}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Add columns for ETF inclusion\n",
    "df['in_VGT'] = df['symbol'].isin(vgt_holdings)\n",
    "df['in_FTEC'] = df['symbol'].isin(ftec_holdings)\n",
    "\n",
    "# Reorder columns\n",
    "df = df[['symbol', 'name', 'latest_market_cap', 'latest_enterprise_value', 'revenue_2023', 'revenue_2024', 'in_VGT', 'in_FTEC']]\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = 'F:\\\\VGT_FTEC_holdings_market_cap_ev_revenue.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"Data saved to {csv_path}\")\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nData Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Print companies with missing data\n",
    "missing_data = df[(df['latest_market_cap'].isnull()) | (df['latest_enterprise_value'].isnull()) | (df['revenue_2023'].isnull()) | (df['revenue_2024'].isnull())]\n",
    "if not missing_data.empty:\n",
    "    print(\"\\nCompanies with missing data:\")\n",
    "    for _, row in missing_data.iterrows():\n",
    "        print(f\"{row['symbol']} ({row['name']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    symbol                     name  latest_market_cap  \\\n",
      "473   MSFT    Microsoft Corporation       3.390000e+12   \n",
      "3     AAPL               Apple Inc.       2.700000e+12   \n",
      "317   GOOG  Alphabet Inc. (Class C)       1.764280e+12   \n",
      "318  GOOGL  Alphabet Inc. (Class A)       1.764280e+12   \n",
      "51    AMZN                   Amazon       1.565590e+12   \n",
      "\n",
      "     latest_enterprise_value  revenue_2023 Market Cap Category Presence  \\\n",
      "473             3.470000e+12  2.120000e+11           Large Cap     Both   \n",
      "3               2.790000e+12  3.830000e+11           Large Cap     Both   \n",
      "317             1.768740e+12  3.073940e+11           Large Cap  S&P 500   \n",
      "318             1.768740e+12  3.073940e+11           Large Cap  S&P 500   \n",
      "51              1.627310e+12  5.747850e+11           Large Cap  S&P 500   \n",
      "\n",
      "     in_ETF  in_SP500  \n",
      "473    True      True  \n",
      "3      True      True  \n",
      "317   False      True  \n",
      "318   False      True  \n",
      "51    False      True  \n",
      "\n",
      "Total companies: 990\n",
      "Large Cap: 355\n",
      "Mid Cap: 295\n",
      "Small Cap: 110\n",
      "Unknown: 230\n",
      "\n",
      "In ETF: 554\n",
      "In S&P 500: 728\n",
      "In Both: 292\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the CSV files from the F:\\ drive\n",
    "sp500_df = pd.read_csv(r'F:\\SP500_market_cap_ev_revenue_2023_2024.csv')\n",
    "etf_df = pd.read_csv(r'F:\\VGT_FTEC_holdings_market_cap_ev_revenue.csv')\n",
    "\n",
    "# Rename columns for consistency\n",
    "sp500_df = sp500_df.rename(columns={'annual_revenue_2023': 'revenue_2023'})\n",
    "\n",
    "# Merge dataframes\n",
    "merged_df = pd.merge(etf_df, sp500_df[['symbol', 'name', 'latest_market_cap', 'latest_enterprise_value', 'revenue_2023']], \n",
    "                     on='symbol', how='outer', suffixes=('_etf', '_sp500'))\n",
    "\n",
    "# Use ETF data where available, otherwise use S&P 500 data\n",
    "for col in ['name', 'latest_market_cap', 'latest_enterprise_value', 'revenue_2023']:\n",
    "    merged_df[col] = merged_df[f'{col}_etf'].combine_first(merged_df[f'{col}_sp500'])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "merged_df = merged_df.drop(columns=[col for col in merged_df.columns if col.endswith(('_etf', '_sp500'))])\n",
    "\n",
    "# Categorize market cap\n",
    "def categorize_market_cap(cap):\n",
    "    if pd.isna(cap):\n",
    "        return 'Unknown'\n",
    "    elif cap >= 20_000_000_000:\n",
    "        return 'Large Cap'\n",
    "    elif cap >= 2_000_000_000:\n",
    "        return 'Mid Cap'\n",
    "    else:\n",
    "        return 'Small Cap'\n",
    "\n",
    "merged_df['Market Cap Category'] = merged_df['latest_market_cap'].apply(categorize_market_cap)\n",
    "\n",
    "# Add indicators for presence in ETF and/or S&P 500\n",
    "merged_df['in_ETF'] = merged_df['symbol'].isin(etf_df['symbol'])\n",
    "merged_df['in_SP500'] = merged_df['symbol'].isin(sp500_df['symbol'])\n",
    "merged_df['Presence'] = np.where(merged_df['in_ETF'] & merged_df['in_SP500'], 'Both', \n",
    "                                 np.where(merged_df['in_ETF'], 'ETF', 'S&P 500'))\n",
    "\n",
    "# Reorder columns\n",
    "column_order = ['symbol', 'name', 'latest_market_cap', 'latest_enterprise_value', 'revenue_2023', \n",
    "                'Market Cap Category', 'Presence', 'in_ETF', 'in_SP500']\n",
    "merged_df = merged_df[column_order]\n",
    "\n",
    "# Sort by market cap (descending)\n",
    "merged_df = merged_df.sort_values('latest_market_cap', ascending=False)\n",
    "\n",
    "# Save to CSV in the F:\\ drive\n",
    "merged_df.to_csv(r'F:\\merged_etf_sp500_data.csv', index=False)\n",
    "\n",
    "print(merged_df.head())\n",
    "print(f\"\\nTotal companies: {len(merged_df)}\")\n",
    "print(f\"Large Cap: {(merged_df['Market Cap Category'] == 'Large Cap').sum()}\")\n",
    "print(f\"Mid Cap: {(merged_df['Market Cap Category'] == 'Mid Cap').sum()}\")\n",
    "print(f\"Small Cap: {(merged_df['Market Cap Category'] == 'Small Cap').sum()}\")\n",
    "print(f\"Unknown: {(merged_df['Market Cap Category'] == 'Unknown').sum()}\")\n",
    "print(f\"\\nIn ETF: {merged_df['in_ETF'].sum()}\")\n",
    "print(f\"In S&P 500: {merged_df['in_SP500'].sum()}\")\n",
    "print(f\"In Both: {((merged_df['in_ETF'] & merged_df['in_SP500'])).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    symbol                     name  latest_market_cap  \\\n",
      "102   MSFT    Microsoft Corporation       3.390000e+12   \n",
      "75    AAPL               Apple Inc.       2.700000e+12   \n",
      "345   AAPL               Apple Inc.       2.695570e+12   \n",
      "354   MSFT                Microsoft       2.535660e+12   \n",
      "351   GOOG  Alphabet Inc. (Class C)       1.764280e+12   \n",
      "\n",
      "     latest_enterprise_value  revenue_2023 Market Cap Category Source  \n",
      "102             3.470000e+12  2.120000e+11           Large_ETF    ETF  \n",
      "75              2.790000e+12  3.830000e+11           Large_ETF    ETF  \n",
      "345             2.787960e+12  3.832850e+11            Large_SP  SP500  \n",
      "354             2.560920e+12  2.119150e+11            Large_SP  SP500  \n",
      "351             1.768740e+12  3.073940e+11            Large_SP  SP500  \n",
      "\n",
      "Total rows: 862\n",
      "Unique companies: 765\n",
      "Large_SP: 342\n",
      "Mid_SP: 157\n",
      "Mid_ETF: 156\n",
      "Small_ETF: 110\n",
      "Large_ETF: 61\n",
      "Unknown_SP: 19\n",
      "Unknown_ETF: 17\n",
      "\n",
      "ETF companies: 344\n",
      "S&P 500 companies: 518\n",
      "Companies in both: 96\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the CSV files from the F:\\ drive\n",
    "sp500_df = pd.read_csv(r'F:\\SP500_market_cap_ev_revenue_2023_2024.csv')\n",
    "etf_df = pd.read_csv(r'F:\\VGT_FTEC_holdings_market_cap_ev_revenue.csv')\n",
    "\n",
    "# Rename columns for consistency\n",
    "sp500_df = sp500_df.rename(columns={'annual_revenue_2023': 'revenue_2023'})\n",
    "\n",
    "# Function to categorize market cap\n",
    "def categorize_market_cap(cap, source):\n",
    "    if pd.isna(cap):\n",
    "        return f'Unknown_{source}'\n",
    "    elif cap >= 20_000_000_000:\n",
    "        return f'Large_{source}'\n",
    "    elif cap >= 2_000_000_000:\n",
    "        return f'Mid_{source}'\n",
    "    else:\n",
    "        return f'Small_{source}'\n",
    "\n",
    "# Categorize ETF companies\n",
    "etf_df['Market Cap Category'] = etf_df['latest_market_cap'].apply(lambda x: categorize_market_cap(x, 'ETF'))\n",
    "etf_df['Source'] = 'ETF'\n",
    "\n",
    "# Categorize S&P 500 companies\n",
    "sp500_df['Market Cap Category'] = sp500_df['latest_market_cap'].apply(lambda x: categorize_market_cap(x, 'SP'))\n",
    "sp500_df['Source'] = 'SP500'\n",
    "\n",
    "# Combine dataframes\n",
    "merged_df = pd.concat([etf_df, sp500_df], ignore_index=True)\n",
    "\n",
    "# Reorder columns\n",
    "column_order = ['symbol', 'name', 'latest_market_cap', 'latest_enterprise_value', 'revenue_2023', \n",
    "                'Market Cap Category', 'Source']\n",
    "merged_df = merged_df[column_order]\n",
    "\n",
    "# Sort by market cap (descending)\n",
    "merged_df = merged_df.sort_values('latest_market_cap', ascending=False)\n",
    "\n",
    "# Save to CSV in the F:\\ drive\n",
    "merged_df.to_csv(r'F:\\merged_etf_sp500_data11.csv', index=False)\n",
    "\n",
    "print(merged_df.head())\n",
    "print(f\"\\nTotal rows: {len(merged_df)}\")\n",
    "print(f\"Unique companies: {merged_df['symbol'].nunique()}\")\n",
    "\n",
    "# Count categories\n",
    "categories = merged_df['Market Cap Category'].value_counts()\n",
    "for category, count in categories.items():\n",
    "    print(f\"{category}: {count}\")\n",
    "\n",
    "print(f\"\\nETF companies: {(merged_df['Source'] == 'ETF').sum()}\")\n",
    "print(f\"S&P 500 companies: {(merged_df['Source'] == 'SP500').sum()}\")\n",
    "print(f\"Companies in both: {merged_df['symbol'].duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    symbol                     name  latest_market_cap  \\\n",
      "102   MSFT    Microsoft Corporation       3.390000e+12   \n",
      "75    AAPL               Apple Inc.       2.700000e+12   \n",
      "345   AAPL               Apple Inc.       2.695570e+12   \n",
      "354   MSFT                Microsoft       2.535660e+12   \n",
      "351   GOOG  Alphabet Inc. (Class C)       1.764280e+12   \n",
      "\n",
      "     latest_enterprise_value  revenue_2023 Market Cap Category Source  \n",
      "102             3.470000e+12  2.120000e+11           Large_ETF    ETF  \n",
      "75              2.790000e+12  3.830000e+11           Large_ETF    ETF  \n",
      "345             2.787960e+12  3.832850e+11            Large_SP  SP500  \n",
      "354             2.560920e+12  2.119150e+11            Large_SP  SP500  \n",
      "351             1.768740e+12  3.073940e+11            Large_SP  SP500  \n",
      "\n",
      "Total rows: 862\n",
      "Unique companies: 765\n",
      "Large_SP: 342\n",
      "Mid_SP: 157\n",
      "Mid_ETF: 156\n",
      "Small_ETF: 110\n",
      "Large_ETF: 61\n",
      "Unknown_SP: 19\n",
      "Unknown_ETF: 17\n",
      "\n",
      "ETF companies: 344\n",
      "S&P 500 companies: 518\n",
      "Companies in both: 96\n",
      "\n",
      "Missing categories:\n",
      "Small_SP\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the CSV files from the F:\\ drive\n",
    "sp500_df = pd.read_csv(r'F:\\SP500_market_cap_ev_revenue_2023_2024.csv')\n",
    "etf_df = pd.read_csv(r'F:\\VGT_FTEC_holdings_market_cap_ev_revenue.csv')\n",
    "\n",
    "# Rename columns for consistency\n",
    "sp500_df = sp500_df.rename(columns={'annual_revenue_2023': 'revenue_2023'})\n",
    "\n",
    "# Function to categorize market cap\n",
    "def categorize_market_cap(cap, source):\n",
    "    if pd.isna(cap):\n",
    "        return f'Unknown_{source}'\n",
    "    elif cap >= 20_000_000_000:\n",
    "        return f'Large_{source}'\n",
    "    elif cap >= 2_000_000_000:\n",
    "        return f'Mid_{source}'\n",
    "    else:\n",
    "        return f'Small_{source}'\n",
    "\n",
    "# Categorize ETF companies\n",
    "etf_df['Market Cap Category'] = etf_df['latest_market_cap'].apply(lambda x: categorize_market_cap(x, 'ETF'))\n",
    "etf_df['Source'] = 'ETF'\n",
    "\n",
    "# Categorize S&P 500 companies\n",
    "sp500_df['Market Cap Category'] = sp500_df['latest_market_cap'].apply(lambda x: categorize_market_cap(x, 'SP'))\n",
    "sp500_df['Source'] = 'SP500'\n",
    "\n",
    "# Combine dataframes\n",
    "merged_df = pd.concat([etf_df, sp500_df], ignore_index=True)\n",
    "\n",
    "# Reorder columns\n",
    "column_order = ['symbol', 'name', 'latest_market_cap', 'latest_enterprise_value', 'revenue_2023', \n",
    "                'Market Cap Category', 'Source']\n",
    "merged_df = merged_df[column_order]\n",
    "\n",
    "# Sort by market cap (descending)\n",
    "merged_df = merged_df.sort_values('latest_market_cap', ascending=False)\n",
    "\n",
    "# Save to CSV in the F:\\ drive\n",
    "merged_df.to_csv(r'F:\\merged_etf_sp500_data12.csv', index=False)\n",
    "\n",
    "print(merged_df.head())\n",
    "print(f\"\\nTotal rows: {len(merged_df)}\")\n",
    "print(f\"Unique companies: {merged_df['symbol'].nunique()}\")\n",
    "\n",
    "# Count categories\n",
    "categories = merged_df['Market Cap Category'].value_counts()\n",
    "for category, count in categories.items():\n",
    "    print(f\"{category}: {count}\")\n",
    "\n",
    "print(f\"\\nETF companies: {(merged_df['Source'] == 'ETF').sum()}\")\n",
    "print(f\"S&P 500 companies: {(merged_df['Source'] == 'SP500').sum()}\")\n",
    "print(f\"Companies in both: {merged_df['symbol'].duplicated().sum()}\")\n",
    "\n",
    "# Check for missing categories\n",
    "all_categories = ['Large_ETF', 'Mid_ETF', 'Small_ETF', 'Large_SP', 'Mid_SP', 'Small_SP', 'Unknown_ETF', 'Unknown_SP']\n",
    "missing_categories = set(all_categories) - set(categories.index)\n",
    "if missing_categories:\n",
    "    print(\"\\nMissing categories:\")\n",
    "    for category in missing_categories:\n",
    "        print(category)\n",
    "else:\n",
    "    print(\"\\nAll expected categories are present.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S&P 500 Data Info:\n",
      "count    4.990000e+02\n",
      "mean     8.617749e+10\n",
      "std      2.338470e+11\n",
      "min      6.588500e+09\n",
      "25%      1.754555e+10\n",
      "50%      3.397528e+10\n",
      "75%      7.092513e+10\n",
      "max      2.700000e+12\n",
      "Name: latest_market_cap, dtype: float64\n",
      "Number of S&P 500 companies with market cap < 2 billion: 0\n",
      "\n",
      "S&P 500 Categories:\n",
      "Market Cap Category\n",
      "Large_SP      342\n",
      "Mid_SP        157\n",
      "Unknown_SP      4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Merged Data Info:\n",
      "    symbol                     name  latest_market_cap  \\\n",
      "102   MSFT    Microsoft Corporation       3.390000e+12   \n",
      "75    AAPL               Apple Inc.       2.700000e+12   \n",
      "330   AAPL               Apple Inc.       2.700000e+12   \n",
      "339   MSFT                Microsoft       2.540000e+12   \n",
      "335  GOOGL  Alphabet Inc. (Class A)       1.760000e+12   \n",
      "\n",
      "     latest_enterprise_value  revenue_2023 Market Cap Category Source  \n",
      "102             3.470000e+12  2.120000e+11           Large_ETF    ETF  \n",
      "75              2.790000e+12  3.830000e+11           Large_ETF    ETF  \n",
      "330             2.790000e+12  3.830000e+11            Large_SP  SP500  \n",
      "339             2.560000e+12  2.120000e+11            Large_SP  SP500  \n",
      "335             1.770000e+12  3.070000e+11            Large_SP  SP500  \n",
      "\n",
      "Total rows: 832\n",
      "Unique companies: 765\n",
      "Large_SP: 342\n",
      "Mid_SP: 157\n",
      "Mid_ETF: 156\n",
      "Small_ETF: 110\n",
      "Large_ETF: 61\n",
      "Unknown_SP: 4\n",
      "Unknown_ETF: 2\n",
      "\n",
      "ETF companies: 329\n",
      "S&P 500 companies: 503\n",
      "Companies in both: 67\n",
      "\n",
      "Missing categories:\n",
      "Small_SP\n",
      "\n",
      "S&P 500 companies with lowest market caps:\n",
      "    symbol                            name  latest_market_cap\n",
      "274    MHK               Mohawk Industries       6.588500e+09\n",
      "393    HAS                          Hasbro       7.087128e+09\n",
      "402   CTLT                        Catalent       7.848160e+09\n",
      "400    FMC                 FMC Corporation       7.885033e+09\n",
      "414   GNRC                         Generac       7.917896e+09\n",
      "371    IVZ                         Invesco       8.113632e+09\n",
      "395    PNW                   Pinnacle West       8.149673e+09\n",
      "228    BWA                      BorgWarner       8.345880e+09\n",
      "474    FRT                  Federal Realty       8.379305e+09\n",
      "311   NCLH  Norwegian Cruise Line Holdings       8.505476e+09\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the CSV files from the F:\\ drive\n",
    "sp500_df = pd.read_csv(r'F:\\SP500_market_cap_ev_revenue_2023_2024.csv')\n",
    "etf_df = pd.read_csv(r'F:\\VGT_FTEC_holdings_market_cap_ev_revenue.csv')\n",
    "\n",
    "# Rename columns for consistency\n",
    "sp500_df = sp500_df.rename(columns={'annual_revenue_2023': 'revenue_2023'})\n",
    "\n",
    "# Print info about S&P 500 data\n",
    "print(\"S&P 500 Data Info:\")\n",
    "print(sp500_df['latest_market_cap'].describe())\n",
    "print(f\"Number of S&P 500 companies with market cap < 2 billion: {(sp500_df['latest_market_cap'] < 2_000_000_000).sum()}\")\n",
    "\n",
    "# Function to categorize market cap\n",
    "def categorize_market_cap(cap, source):\n",
    "    if pd.isna(cap):\n",
    "        return f'Unknown_{source}'\n",
    "    elif cap >= 20_000_000_000:\n",
    "        return f'Large_{source}'\n",
    "    elif cap >= 2_000_000_000:\n",
    "        return f'Mid_{source}'\n",
    "    else:\n",
    "        return f'Small_{source}'\n",
    "\n",
    "# Categorize ETF companies\n",
    "etf_df['Market Cap Category'] = etf_df['latest_market_cap'].apply(lambda x: categorize_market_cap(x, 'ETF'))\n",
    "etf_df['Source'] = 'ETF'\n",
    "\n",
    "# Categorize S&P 500 companies\n",
    "sp500_df['Market Cap Category'] = sp500_df['latest_market_cap'].apply(lambda x: categorize_market_cap(x, 'SP'))\n",
    "sp500_df['Source'] = 'SP500'\n",
    "\n",
    "# Print S&P 500 categories\n",
    "print(\"\\nS&P 500 Categories:\")\n",
    "print(sp500_df['Market Cap Category'].value_counts())\n",
    "\n",
    "# Combine dataframes\n",
    "merged_df = pd.concat([etf_df, sp500_df], ignore_index=True)\n",
    "\n",
    "# Reorder columns\n",
    "column_order = ['symbol', 'name', 'latest_market_cap', 'latest_enterprise_value', 'revenue_2023', \n",
    "                'Market Cap Category', 'Source']\n",
    "merged_df = merged_df[column_order]\n",
    "\n",
    "# Sort by market cap (descending)\n",
    "merged_df = merged_df.sort_values('latest_market_cap', ascending=False)\n",
    "\n",
    "# Save to CSV in the F:\\ drive\n",
    "merged_df.to_csv(r'F:\\merged_etf_sp500_data13.csv', index=False)\n",
    "\n",
    "print(\"\\nMerged Data Info:\")\n",
    "print(merged_df.head())\n",
    "print(f\"\\nTotal rows: {len(merged_df)}\")\n",
    "print(f\"Unique companies: {merged_df['symbol'].nunique()}\")\n",
    "\n",
    "# Count categories\n",
    "categories = merged_df['Market Cap Category'].value_counts()\n",
    "for category, count in categories.items():\n",
    "    print(f\"{category}: {count}\")\n",
    "\n",
    "print(f\"\\nETF companies: {(merged_df['Source'] == 'ETF').sum()}\")\n",
    "print(f\"S&P 500 companies: {(merged_df['Source'] == 'SP500').sum()}\")\n",
    "print(f\"Companies in both: {merged_df['symbol'].duplicated().sum()}\")\n",
    "\n",
    "# Check for missing categories\n",
    "all_categories = ['Large_ETF', 'Mid_ETF', 'Small_ETF', 'Large_SP', 'Mid_SP', 'Small_SP', 'Unknown_ETF', 'Unknown_SP']\n",
    "missing_categories = set(all_categories) - set(categories.index)\n",
    "if missing_categories:\n",
    "    print(\"\\nMissing categories:\")\n",
    "    for category in missing_categories:\n",
    "        print(category)\n",
    "else:\n",
    "    print(\"\\nAll expected categories are present.\")\n",
    "\n",
    "# If Small_SP is missing, print out S&P 500 companies with lowest market caps\n",
    "if 'Small_SP' in missing_categories:\n",
    "    print(\"\\nS&P 500 companies with lowest market caps:\")\n",
    "    print(sp500_df.nsmallest(10, 'latest_market_cap')[['symbol', 'name', 'latest_market_cap']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged Data Info:\n",
      "    symbol                   name  latest_market_cap  latest_enterprise_value  \\\n",
      "700   MSFT  Microsoft Corporation       3.393961e+12             3.473498e+12   \n",
      "102   MSFT  Microsoft Corporation       3.390000e+12             3.470000e+12   \n",
      "75    AAPL             Apple Inc.       2.700000e+12             2.790000e+12   \n",
      "738   AAPL             Apple Inc.       2.695570e+12             2.789535e+12   \n",
      "504  GOOGL          Alphabet Inc.       1.764285e+12             1.768741e+12   \n",
      "\n",
      "     revenue_2023 Market Cap Category Source  \n",
      "700  2.119150e+11            Large_SP  SP500  \n",
      "102  2.120000e+11           Large_ETF    ETF  \n",
      "75   3.830000e+11           Large_ETF    ETF  \n",
      "738  3.832850e+11            Large_SP  SP500  \n",
      "504  3.073940e+11            Large_SP  SP500  \n",
      "\n",
      "Total rows: 832\n",
      "Unique companies: 765\n",
      "Large_SP: 346\n",
      "Small_ETF: 229\n",
      "Mid_SP: 134\n",
      "Large_ETF: 61\n",
      "Mid_ETF: 37\n",
      "Small_SP: 23\n",
      "Unknown_ETF: 2\n",
      "\n",
      "ETF companies: 329\n",
      "S&P 500 companies: 503\n",
      "Companies in both: 67\n",
      "\n",
      "Missing categories:\n",
      "Unknown_SP\n",
      "\n",
      "Unknown_SP companies:\n",
      "Empty DataFrame\n",
      "Columns: [symbol, name, latest_market_cap]\n",
      "Index: []\n",
      "\n",
      "20 smallest S&P 500 companies:\n",
      "    symbol                                 name  latest_market_cap  \\\n",
      "336   DECK          Deckers Outdoor Corporation       4.012075e+09   \n",
      "507    MHK              Mohawk Industries, Inc.       6.588500e+09   \n",
      "730    HAS                         Hasbro, Inc.       7.087128e+09   \n",
      "579    DOC          Healthpeak Properties, Inc.       7.280650e+09   \n",
      "371   MTCH                    Match Group, Inc.       7.867286e+09   \n",
      "555    FMC                      FMC Corporation       7.885033e+09   \n",
      "379   GNRC                Generac Holdings Inc.       7.917896e+09   \n",
      "574    IVZ                         Invesco Ltd.       8.113632e+09   \n",
      "651    PNW    Pinnacle West Capital Corporation       8.149673e+09   \n",
      "531    BWA                      BorgWarner Inc.       8.345880e+09   \n",
      "479    FRT      Federal Realty Investment Trust       8.379305e+09   \n",
      "437   NCLH  Norwegian Cruise Line Holdings Ltd.       8.505476e+09   \n",
      "493    AAL         American Airlines Group Inc.       8.980629e+09   \n",
      "589    AIZ                       Assurant, Inc.       9.006656e+09   \n",
      "695   PARA                     Paramount Global       9.388800e+09   \n",
      "389    BIO           Bio-Rad Laboratories, Inc.       9.431294e+09   \n",
      "598   JNPR               Juniper Networks, Inc.       9.433600e+09   \n",
      "575    DVA                          DaVita Inc.       9.511160e+09   \n",
      "542   FFIV                             F5, Inc.       9.653736e+09   \n",
      "611    TPR                       Tapestry, Inc.       9.807468e+09   \n",
      "\n",
      "    Market Cap Category  \n",
      "336            Small_SP  \n",
      "507            Small_SP  \n",
      "730            Small_SP  \n",
      "579            Small_SP  \n",
      "371            Small_SP  \n",
      "555            Small_SP  \n",
      "379            Small_SP  \n",
      "574            Small_SP  \n",
      "651            Small_SP  \n",
      "531            Small_SP  \n",
      "479            Small_SP  \n",
      "437            Small_SP  \n",
      "493            Small_SP  \n",
      "589            Small_SP  \n",
      "695            Small_SP  \n",
      "389            Small_SP  \n",
      "598            Small_SP  \n",
      "575            Small_SP  \n",
      "542            Small_SP  \n",
      "611            Small_SP  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the CSV files from the F:\\ drive\n",
    "sp500_df = pd.read_csv(r'F:\\SP500_market_cap_ev_revenue_2023_2024(4).csv')\n",
    "etf_df = pd.read_csv(r'F:\\VGT_FTEC_holdings_market_cap_ev_revenue.csv')\n",
    "\n",
    "# Rename columns for consistency\n",
    "sp500_df = sp500_df.rename(columns={'annual_revenue_2023': 'revenue_2023'})\n",
    "\n",
    "# Function to categorize market cap with adjusted thresholds\n",
    "def categorize_market_cap(cap, source):\n",
    "    if pd.isna(cap):\n",
    "        return f'Unknown_{source}'\n",
    "    elif cap >= 20_000_000_000:\n",
    "        return f'Large_{source}'\n",
    "    elif cap >= 10_000_000_000:  # Adjusted threshold\n",
    "        return f'Mid_{source}'\n",
    "    else:\n",
    "        return f'Small_{source}'\n",
    "\n",
    "# Categorize ETF companies\n",
    "etf_df['Market Cap Category'] = etf_df['latest_market_cap'].apply(lambda x: categorize_market_cap(x, 'ETF'))\n",
    "etf_df['Source'] = 'ETF'\n",
    "\n",
    "# Categorize S&P 500 companies\n",
    "sp500_df['Market Cap Category'] = sp500_df['latest_market_cap'].apply(lambda x: categorize_market_cap(x, 'SP'))\n",
    "sp500_df['Source'] = 'SP500'\n",
    "\n",
    "# Combine dataframes\n",
    "merged_df = pd.concat([etf_df, sp500_df], ignore_index=True)\n",
    "\n",
    "# Reorder columns\n",
    "column_order = ['symbol', 'name', 'latest_market_cap', 'latest_enterprise_value', 'revenue_2023', \n",
    "                'Market Cap Category', 'Source']\n",
    "merged_df = merged_df[column_order]\n",
    "\n",
    "# Sort by market cap (descending)\n",
    "merged_df = merged_df.sort_values('latest_market_cap', ascending=False)\n",
    "\n",
    "# Save to CSV in the F:\\ drive\n",
    "merged_df.to_csv(r'F:\\merged_etf_sp500_data_adjusted.csv', index=False)\n",
    "\n",
    "print(\"\\nMerged Data Info:\")\n",
    "print(merged_df.head())\n",
    "print(f\"\\nTotal rows: {len(merged_df)}\")\n",
    "print(f\"Unique companies: {merged_df['symbol'].nunique()}\")\n",
    "\n",
    "# Count categories\n",
    "categories = merged_df['Market Cap Category'].value_counts()\n",
    "for category, count in categories.items():\n",
    "    print(f\"{category}: {count}\")\n",
    "\n",
    "print(f\"\\nETF companies: {(merged_df['Source'] == 'ETF').sum()}\")\n",
    "print(f\"S&P 500 companies: {(merged_df['Source'] == 'SP500').sum()}\")\n",
    "print(f\"Companies in both: {merged_df['symbol'].duplicated().sum()}\")\n",
    "\n",
    "# Check for missing categories\n",
    "all_categories = ['Large_ETF', 'Mid_ETF', 'Small_ETF', 'Large_SP', 'Mid_SP', 'Small_SP', 'Unknown_ETF', 'Unknown_SP']\n",
    "missing_categories = set(all_categories) - set(categories.index)\n",
    "if missing_categories:\n",
    "    print(\"\\nMissing categories:\")\n",
    "    for category in missing_categories:\n",
    "        print(category)\n",
    "else:\n",
    "    print(\"\\nAll expected categories are present.\")\n",
    "\n",
    "# Print info about Unknown_SP companies\n",
    "unknown_sp = merged_df[(merged_df['Source'] == 'SP500') & (merged_df['Market Cap Category'] == 'Unknown_SP')]\n",
    "print(\"\\nUnknown_SP companies:\")\n",
    "print(unknown_sp[['symbol', 'name', 'latest_market_cap']])\n",
    "\n",
    "# Print info about smallest S&P 500 companies\n",
    "smallest_sp500 = merged_df[merged_df['Source'] == 'SP500'].nsmallest(20, 'latest_market_cap')\n",
    "print(\"\\n20 smallest S&P 500 companies:\")\n",
    "print(smallest_sp500[['symbol', 'name', 'latest_market_cap', 'Market Cap Category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Your API Key\n",
    "API_KEY = 'D7KXZhPjt6caA9dwwAliN6CP3Oofacu5'\n",
    "\n",
    "def get_sp500_companies():\n",
    "    url = f'https://financialmodelingprep.com/api/v3/sp500_constituent?apikey={API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return [company['symbol'] for company in data]\n",
    "\n",
    "def get_company_data(symbol):\n",
    "    # Get company profile for full name\n",
    "    profile_url = f'https://financialmodelingprep.com/api/v3/profile/{symbol}?apikey={API_KEY}'\n",
    "    profile_response = requests.get(profile_url)\n",
    "    profile_data = profile_response.json()\n",
    "    \n",
    "    # Get latest market cap and enterprise value\n",
    "    ev_url = f'https://financialmodelingprep.com/api/v3/enterprise-value/{symbol}?limit=1&apikey={API_KEY}'\n",
    "    ev_response = requests.get(ev_url)\n",
    "    ev_data = ev_response.json()\n",
    "    \n",
    "    # Get income statement for revenue\n",
    "    income_url = f'https://financialmodelingprep.com/api/v3/income-statement/{symbol}?limit=2&apikey={API_KEY}'\n",
    "    income_response = requests.get(income_url)\n",
    "    income_data = income_response.json()\n",
    "    \n",
    "    company_name = profile_data[0]['companyName'] if profile_data else 'N/A'\n",
    "    latest_data = ev_data[0] if ev_data else {}\n",
    "    \n",
    "    revenue_2023 = None\n",
    "    revenue_2024 = None\n",
    "    for statement in income_data:\n",
    "        if statement['date'].startswith('2023'):\n",
    "            revenue_2023 = statement['revenue']\n",
    "        elif statement['date'].startswith('2024'):\n",
    "            revenue_2024 = statement['revenue']\n",
    "    \n",
    "    return {\n",
    "        'symbol': symbol,\n",
    "        'name': company_name,\n",
    "        'latest_market_cap': latest_data.get('marketCapitalization'),\n",
    "        'latest_enterprise_value': latest_data.get('enterpriseValue'),\n",
    "        'revenue_2023': revenue_2023,\n",
    "        'revenue_2024': revenue_2024\n",
    "    }\n",
    "\n",
    "# Get S&P 500 companies\n",
    "sp500_companies = get_sp500_companies()\n",
    "print(f\"Total S&P 500 companies: {len(sp500_companies)}\")\n",
    "\n",
    "# Fetch data for all companies using ThreadPoolExecutor\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    future_to_company = {executor.submit(get_company_data, symbol): symbol for symbol in sp500_companies}\n",
    "    for future in as_completed(future_to_company):\n",
    "        symbol = future_to_company[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "            print(f\"Processed: {symbol}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {symbol}: {str(e)}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Reorder columns\n",
    "df = df[['symbol', 'name', 'latest_market_cap', 'latest_enterprise_value', 'revenue_2023', 'revenue_2024']]\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = 'F:\\\\SP500_market_cap_ev_revenue_2023_2024(4).csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"Data saved to {csv_path}\")\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nData Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Print companies with missing data\n",
    "missing_data = df[(df['latest_market_cap'].isnull()) | (df['latest_enterprise_value'].isnull()) | (df['revenue_2023'].isnull()) | (df['revenue_2024'].isnull())]\n",
    "if not missing_data.empty:\n",
    "    print(\"\\nCompanies with missing data:\")\n",
    "    for _, row in missing_data.iterrows():\n",
    "        print(f\"{row['symbol']} ({row['name']})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
